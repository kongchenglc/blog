<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Learning Notes - Lich&#039;s Blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Lich&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lich&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Lich&#039;s Blog"><meta property="og:url" content="https://kongchenglc.github.io/blog"><meta property="og:site_name" content="Lich&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kongchenglc.github.io/blog/img/og_image.png"><meta property="article:author" content="Lich"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://kongchenglc.github.io/blog/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kongchenglc.github.io/blog"},"headline":"Lich's Blog","image":["https://kongchenglc.github.io/blog/img/og_image.png"],"author":{"@type":"Person","name":"Lich"},"publisher":{"@type":"Organization","name":"Lich's Blog","logo":{"@type":"ImageObject","url":{"text":"Lich's Blog"}}},"description":""}</script><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/">Lich&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/blog/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Learning Notes</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-02T15:50:57.000Z" title="2/2/2025, 3:50:57 PM">2025-02-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.025Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2025/02/02/Machine-Learning-5/">About Machine Learning ( Part 5: Support Vector Machine )</a></p><div class="content"><h1 id="Support-Vector-Machine-SVM"><a href="#Support-Vector-Machine-SVM" class="headerlink" title="Support Vector Machine (SVM)"></a>Support Vector Machine (SVM)</h1><p>Support Vector Machines (SVM) are one of the most powerful supervised learning algorithms used for classification and regression tasks.</p>
<h2 id="The-Hyperplane"><a href="#The-Hyperplane" class="headerlink" title="The Hyperplane"></a>The Hyperplane</h2><p>In a binary classification problem, the goal of SVM is to find a <strong>hyperplane</strong> that best separates two classes. Given a training dataset:</p>
<p>$$<br>D &#x3D; { (\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \dots, (\mathbf{x}_n, y_n) }, \quad \mathbf{x}_i \in \mathbb{R}^d, \quad y_i \in {-1, +1}<br>$$</p>
<ul>
<li>$\mathbf{x}_i$: $d$-dimensional feature vector (e.g., pixel values in an image).</li>
<li>$y_i$: Class label ($+1$ for “cat”, $-1$ for “dog”).</li>
</ul>
<h2 id="The-Hyperplane-1"><a href="#The-Hyperplane-1" class="headerlink" title="The Hyperplane"></a>The Hyperplane</h2><p>A hyperplane in $\mathbb{R}^d$ is defined as:</p>
<p>$$<br>\mathbf{w} \cdot \mathbf{x} + b &#x3D; 0, \quad \mathbf{x} \in \mathbb{R}^d<br>$$</p>
<ul>
<li>$\mathbf{w}$: <strong>Weight vector</strong> (normal to the hyperplane).</li>
<li>$b$: <strong>Bias term</strong> (shifts the hyperplane away from the origin).</li>
<li>$\mathbf{x}$: Any point in the feature space.</li>
</ul>
<h3 id="Example-2D-Hyperplane"><a href="#Example-2D-Hyperplane" class="headerlink" title="Example: 2D Hyperplane"></a>Example: 2D Hyperplane</h3><p>Consider a 2D hyperplane $2x_1 + 3x_2 - 12 &#x3D; 0$:</p>
<ul>
<li><strong>Normal Vector</strong>: $\mathbf{w} &#x3D; [2, 3]$.</li>
<li><strong>Bias</strong>: $b &#x3D; -12$.</li>
</ul>
<p><em>The weight vector $\mathbf{w}$ is perpendicular to the hyperplane.</em></p>
<p><img src="/blog/./img/ML5-2.png" alt="2x+3y-12=0"></p>
<h2 id="Margin-Maximization"><a href="#Margin-Maximization" class="headerlink" title="Margin Maximization"></a>Margin Maximization</h2><p>The distance from a sample $\mathbf{x}_i$ to the hyperplane is:</p>
<p>$$<br>\text{Distance} &#x3D; \frac{|\mathbf{w} \cdot \mathbf{x}_i + b|}{|\mathbf{w}|}.<br>$$</p>
<p>SVM seeks the hyperplane that <strong>maximizes the minimum margin</strong> between classes:</p>
<p>$$<br>\max_{\mathbf{w}, b} ( \frac{2}{|\mathbf{w}|} ) \quad \text{subject to} \quad y_i(\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1, , \forall i.<br>$$</p>
<p>This is equivalent to minimizing $|\mathbf{w}|^2$, a convex optimization problem solvable via quadratic programming.</p>
<h1 id="Optimize"><a href="#Optimize" class="headerlink" title="Optimize"></a>Optimize</h1><h2 id="Linear-Separation-with-Hard-Margin"><a href="#Linear-Separation-with-Hard-Margin" class="headerlink" title="Linear Separation with Hard Margin"></a>Linear Separation with Hard Margin</h2><p>When data is perfectly linearly separable, SVM seeks the hyperplane with maximum margin:</p>
<p>$$<br>\min_{\mathbf{w}, b} \frac{1}{2}|\mathbf{w}|^2 \quad \text{subject to} \quad y_i(\mathbf{w}^T\mathbf{x}_i + b) \geq 1, , \forall i<br>$$</p>
<p><strong>Geometric Interpretation</strong>:<br>The margin width is $\frac{2}{|\mathbf{w}|}$. Maximizing margin &#x3D; minimizing $|\mathbf{w}|$.</p>
<p><strong>The Limitation</strong>:</p>
<p>Fails catastrophically when:</p>
<ul>
<li>Data has noise&#x2F;outliers</li>
<li>Classes are inherently non-separable</li>
</ul>
<h2 id="Soft-Margin-SVM"><a href="#Soft-Margin-SVM" class="headerlink" title="Soft Margin SVM"></a>Soft Margin SVM</h2><p>Allow controlled violations using slack variables $\xi_i$:</p>
<p>$$<br>\begin{aligned}<br>\min_{\mathbf{w}, b, \xi} &amp;\quad \frac{1}{2}|\mathbf{w}|^2 + C\sum_{i&#x3D;1}^n \xi_i \<br>\text{s.t.} &amp;\quad y_i(\mathbf{w}^T\mathbf{x}_i + b) \geq 1 - \xi_i \<br>&amp;\quad \xi_i \geq 0, \quad \forall i<br>\end{aligned}<br>$$</p>
<ul>
<li><strong>$C$</strong>: Penalty weight (Large $C$ ≈ Hard Margin)</li>
<li><strong>$\xi_i$</strong>: How much the $i$-th sample violates the margin</li>
</ul>
<h3 id="Lagrangian-Formulation"><a href="#Lagrangian-Formulation" class="headerlink" title="Lagrangian Formulation"></a>Lagrangian Formulation</h3><p>Convert constraints into the objective function:</p>

$$
\mathcal{L} = \frac{1}{2}\|\mathbf{w}\|^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n \alpha_i[y_i(\mathbf{w}^T\mathbf{x}_i + b) - 1 + \xi_i] - \sum_{i=1}^n \mu_i\xi_i
$$


<h4 id="Key-Derivations"><a href="#Key-Derivations" class="headerlink" title="Key Derivations:"></a>Key Derivations:</h4><ol>
<li><p><strong>Primal Variables</strong></p>
<ul>
<li>$\frac{\partial \mathcal{L}}{\partial \mathbf{w}} &#x3D; 0 \Rightarrow \mathbf{w} &#x3D; \sum \alpha_i y_i \mathbf{x}_i$</li>
<li>$\frac{\partial \mathcal{L}}{\partial b} &#x3D; 0 \Rightarrow \sum \alpha_i y_i &#x3D; 0$</li>
<li>$\frac{\partial \mathcal{L}}{\partial \xi_i} &#x3D; 0 \Rightarrow \alpha_i + \mu_i &#x3D; C$</li>
</ul>
</li>
<li><p><strong>Dual Problem</strong><br>Substitute back to get:</p>
</li>
</ol>
<p>$$<br>\max_{\alpha} \sum_{i&#x3D;1}^n \alpha_i - \frac{1}{2}\sum_{i,j} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^T \mathbf{x}_j \<br>\text{s.t.} \quad 0 \leq \alpha_i \leq C, \quad \sum \alpha_i y_i &#x3D; 0<br>$$</p>
<h3 id="Interpretation-of-alpha-i"><a href="#Interpretation-of-alpha-i" class="headerlink" title="Interpretation of $\alpha_i$"></a>Interpretation of $\alpha_i$</h3><table>
<thead>
<tr>
<th>$\alpha_i$ Range</th>
<th>Sample Status</th>
<th>$\xi_i$ Value</th>
</tr>
</thead>
<tbody><tr>
<td>$&#x3D;0$</td>
<td>Outside margin</td>
<td>0</td>
</tr>
<tr>
<td>$(0, C)$</td>
<td>On margin</td>
<td>0</td>
</tr>
<tr>
<td>$&#x3D;C$</td>
<td>Inside margin</td>
<td>$&gt;0$</td>
</tr>
</tbody></table>
<p><strong>Decision Function</strong>:</p>
<p>$$<br>f(\mathbf{x}) &#x3D; \text{sign}( \sum_{\alpha_i &gt; 0} \alpha_i y_i \mathbf{x}_i^T \mathbf{x} + b)<br>$$</p>
<h2 id="Nonlinear-Classification-with-Kernel-Trick"><a href="#Nonlinear-Classification-with-Kernel-Trick" class="headerlink" title="Nonlinear Classification with Kernel Trick"></a>Nonlinear Classification with Kernel Trick</h2><h3 id="The-Fundamental-Idea"><a href="#The-Fundamental-Idea" class="headerlink" title="The Fundamental Idea"></a>The Fundamental Idea</h3><p><strong>Problem</strong>: Many datasets require nonlinear boundaries.<br><strong>Solution</strong>: Map data to higher dimension $\phi(\mathbf{x})$ where linear separation becomes possible.</p>
<p><strong>Example Transformation</strong>:<br>For $\mathbf{x} &#x3D; [x_1, x_2]$, use $\phi(\mathbf{x}) &#x3D; [x_1, x_2, x_1^2 + x_2^2]$</p>
<h3 id="The-Computational-Challenge"><a href="#The-Computational-Challenge" class="headerlink" title="The Computational Challenge"></a>The Computational Challenge</h3><p>Direct computation of $\phi(\mathbf{x}_i)^T \phi(\mathbf{x}_j)$ in high dimensions is intractable.</p>
<p><strong>Key Insight</strong>: Many ML algorithms (like SVM) only need inner products, not explicit coordinates.</p>
<h3 id="Kernel-Functions-to-the-Rescue"><a href="#Kernel-Functions-to-the-Rescue" class="headerlink" title="Kernel Functions to the Rescue"></a>Kernel Functions to the Rescue</h3><p>Replace $\phi(\mathbf{x}_i)^T \phi(\mathbf{x}_j)$ with kernel $K(\mathbf{x}_i, \mathbf{x}_j)$:</p>
<p><strong>Updated Dual Problem</strong>:</p>
<p>$$<br>\max_{\alpha} \sum_{i&#x3D;1}^n \alpha_i - \frac{1}{2}\sum_{i,j} \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i, \mathbf{x}_j)<br>$$</p>
<h4 id="Common-Kernels"><a href="#Common-Kernels" class="headerlink" title="Common Kernels:"></a>Common Kernels:</h4><table>
<thead>
<tr>
<th>Kernel</th>
<th>Formula</th>
<th>Characteristics</th>
</tr>
</thead>
<tbody><tr>
<td>Linear</td>
<td>$K(\mathbf{x}, \mathbf{z}) &#x3D; \mathbf{x}^T\mathbf{z}$</td>
<td>No transformation</td>
</tr>
<tr>
<td>Polynomial</td>
<td>$(\mathbf{x}^T\mathbf{z} + c)^d$</td>
<td>Captures polynomial interactions</td>
</tr>
<tr>
<td>RBF</td>
<td>$\exp(-\gamma |\mathbf{x}-\mathbf{z}|^2)$</td>
<td>Infinite-dimensional mapping</td>
</tr>
<tr>
<td>Sigmoid</td>
<td>$\tanh(\alpha \mathbf{x}^T\mathbf{z} + c)$</td>
<td>Mimics neural networks</td>
</tr>
</tbody></table>
<h3 id="3-4-Why-Kernels-Work-Mercer’s-Theorem"><a href="#3-4-Why-Kernels-Work-Mercer’s-Theorem" class="headerlink" title="3.4 Why Kernels Work: Mercer’s Theorem"></a>3.4 Why Kernels Work: Mercer’s Theorem</h3><p>A valid kernel must:</p>
<ol>
<li>Be symmetric: $K(\mathbf{x}, \mathbf{z}) &#x3D; K(\mathbf{z}, \mathbf{x})$</li>
<li>Produce positive semi-definite Gram matrix</li>
</ol>
<p><strong>Practical Check</strong>: If SVM training converges, your kernel is valid.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-21T15:50:57.000Z" title="1/21/2025, 3:50:57 PM">2025-01-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2025/01/21/Machine-Learning-4/">About Machine Learning ( Part 4: Decision Tree )</a></p><div class="content"><p>A Decision Tree is a supervised learning algorithm used for both classification and regression tasks. It organizes data into a tree-like structure, where each internal node represents a decision based on a feature, and each leaf node provides a prediction. Decision trees are simple, interpretable, and capable of handling both categorical and numerical data.</p>
<h1 id="Classification-Tree"><a href="#Classification-Tree" class="headerlink" title="Classification Tree"></a>Classification Tree</h1><p>A <strong>Classification Tree</strong> is a decision tree used for classifying data into distinct categories or classes. The main objective of a classification tree is to predict the category or class to which a given input belongs based on various features.</p>
<p><img src="/blog/./img/ML4-1.png"></p>
<h2 id="How-Does-a-Classification-Tree-Work"><a href="#How-Does-a-Classification-Tree-Work" class="headerlink" title="How Does a Classification Tree Work?"></a>How Does a Classification Tree Work?</h2><p>The tree is constructed in the following steps:</p>
<ol>
<li><strong>Select the best feature</strong>: The first step is to choose the feature that best splits the data. This is usually done by calculating the <strong>Entropy</strong>, such as Information Gain, or Gini Index.</li>
<li><strong>Split the data</strong>: The chosen feature is used to split the dataset into two or more subsets. The splitting process continues recursively until the stopping criteria are met (e.g., maximum depth reached or all data in a node belong to the same class).</li>
<li><strong>Predict the class</strong>: The leaf nodes represent the predicted class labels, which are determined based on the majority class in that node.</li>
</ol>
<h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h2><p><strong>Entropy</strong> measures the disorder or uncertainty in a dataset. It quantifies the impurity of a dataset. If the dataset is perfectly pure (i.e., all samples belong to the same class), <strong>the entropy is 0</strong>. If the dataset has an equal distribution of all possible classes, the entropy reaches its maximum value.</p>
<p>The formula for entropy $H(S)$ of a set $S$ is:</p>
<p>$$<br>H(S) &#x3D; - \sum_{x \in S} p(x) \log_2 p(x)<br>$$</p>
<p>Where:</p>
<ul>
<li>$S$ is the dataset.</li>
<li>$p(x)$ is the proportion of instances in $S$ that belong to class $x$.</li>
</ul>
<p>For binary classification (i.e., two classes, say “Yes” and “No”), the entropy simplifies to:</p>
<p>$$<br>H(S) &#x3D; - p(+) \log_2 p(+) - p(-) \log_2 p(-)<br>$$</p>
<p>Where:</p>
<ul>
<li>$p(+)$ is the proportion of “Yes” labels in the dataset.</li>
<li>$p(-)$ is the proportion of “No” labels in the dataset.</li>
</ul>
<p>Interpretation of Entropy:</p>
<ul>
<li>If the entire dataset belongs to one class (e.g., all “Yes” or all “No”), then the entropy is 0 because there is no uncertainty.</li>
<li>If the dataset has an equal distribution of both classes (e.g., $p(+) &#x3D; p(-) &#x3D; 0.5$), the entropy is 1 because there is maximum uncertainty.</li>
</ul>
<p>For example, in the case of a <strong>Tennis Playing</strong> dataset, if the target variable (whether a person will play tennis or not) is evenly split between “Yes” and “No”, the entropy will be:</p>
<p>$$<br>H(S) &#x3D; - 0.5 \log_2 0.5 - 0.5 \log_2 0.5 &#x3D; 1<br>$$</p>
<p>This means the data is maximally <strong>uncertain</strong> (a 50&#x2F;50 chance of playing or not playing).</p>
<p><img src="/blog/./img/ML4-2.png" alt="https://en.wikipedia.org/wiki/Binary_entropy_function"></p>
<h2 id="Information-Gain"><a href="#Information-Gain" class="headerlink" title="Information Gain"></a>Information Gain</h2><p><strong>Information Gain (IG)</strong> measures how well an attribute (or feature) separates the dataset into distinct classes. It is based on the difference in <strong>entropy</strong> before and after the split. The goal is to reduce uncertainty or disorder in the data as much as possible by selecting the attribute.</p>
<p>The formula for <strong>Information Gain</strong> when splitting a dataset $S$ based on an attribute $A$ is:</p>
<p>$$<br>IG(S, A) &#x3D; H(S) - \sum_{v \in V(A)} \frac{|S_v|}{|S|} H(S_v)<br>$$</p>
<p>Where:</p>
<ul>
<li>$H(S)$ is the entropy of the dataset $S$ before the split.</li>
<li>$H(S_v)$ is the entropy of the subset $S_v$.</li>
<li>$V(A)$ is the set of all possible values for attribute $A$.</li>
<li>$\frac{|S_v|}{|S|}$ is the proportion of the data in subset $S_v$ relative to the entire dataset $S$. ( Weighted )</li>
</ul>
<p>The higher the information gain, the better the attribute is at reducing uncertainty and distinguishing between different classes. A high information gain indicates that the attribute is good at separating the data into pure subsets.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/kongchenglc/Machine-Learning-Examples/blob/master/decision-tree1.py">Code Demo</a></p>
<h2 id="Gini-Index"><a href="#Gini-Index" class="headerlink" title="Gini Index"></a>Gini Index</h2><p><strong>Gini Index</strong> is another measure used to evaluate the quality of a split in a decision tree. It measures the impurity or disorder of a dataset, with a lower Gini index indicating a purer dataset.</p>
<p>The <strong>Gini index</strong> for a dataset ( S ) is calculated as:</p>
<p>$$<br>Gini(S) &#x3D; 1 - \sum_{i&#x3D;1}^{C} p_i^2<br>$$</p>
<p>Where:</p>
<ul>
<li>( C ) is the number of classes in the target variable.</li>
<li>( p_i ) is the proportion of the samples in the dataset ( S ) that belong to class ( i ).</li>
</ul>
<p>Interpretation:</p>
<ul>
<li>If all the data points belong to a single class, the Gini index is 0, indicating a pure node.</li>
<li>If the data points are evenly distributed among all classes, the Gini index is maximized (impure node). For binary classification, the maximum value is 0.5.</li>
</ul>
<h2 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h2><p><strong>Overfitting</strong> occurs when a decision tree becomes too complex, capturing noise in the data instead of general patterns. It performs well on training data but poorly on new data.</p>
<blockquote>
<p>Given a hypothesis space $H$, a hypothesis $h \in H$ is said to overfit the training data if there exists some alternative hypothesis $h’ \in H$, such that $h$ has a smaller error than $h’$ over the training examples, but $h’$ has a smaller error than $h$ over the entire distribution of instances.<br>– Tom Mitchell</p>
</blockquote>
<p><strong>Causes:</strong> Noisy data or insufficient data can lead to overfitting.</p>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Stop growing</strong> the tree once it reaches a certain depth.</li>
<li><strong>Prune</strong> the tree by removing branches with little importance.</li>
</ol>
<h2 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h2><p>Pruning reduces tree complexity by removing unnecessary nodes.</p>
<p><strong>Process</strong>:</p>
<ol>
<li>Turn a node into a leaf with the most common value in that subset.</li>
<li>Test the accuracy of the pruned tree.</li>
<li>If accuracy improves, keep the change; if not, restore the node.</li>
</ol>
<p><strong>Data Splits</strong>:</p>
<ul>
<li><strong>Training set</strong> for building the tree.</li>
<li><strong>Testing set</strong> for evaluating performance.</li>
<li><strong>Pruning set</strong> for pruning decisions.</li>
</ul>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Simplifies the model.</li>
<li>Reduces overfitting and improves generalization.</li>
<li>Results in better test data performance.</li>
</ul>
<h1 id="Regression-Tree"><a href="#Regression-Tree" class="headerlink" title="Regression Tree"></a>Regression Tree</h1><p>A <strong>Regression Tree</strong> is a type of decision tree used for predicting continuous target variables. Unlike classification trees that predict discrete labels, regression trees predict numerical values. Here’s how the process works:</p>
<ol>
<li><p><strong>Choosing Features and Split Values</strong></p>
<ul>
<li>The goal is to find the best feature and threshold to split the data. This is done by minimizing the variance or mean squared error (MSE) within each subset after the split.</li>
<li>For example, given a feature $X$ and target $Y$, we want to find a threshold $t$ to split the data into two subsets: $X \leq t$ and $X &gt; t$. The split that minimizes the variance within each subset is chosen.</li>
</ul>
</li>
<li><p><strong>Splitting the Data</strong></p>
<ul>
<li>Once the best feature and threshold are identified, the data is split into two subsets based on this threshold.</li>
<li>This is a recursive process, where each subset is further split until a stopping condition (e.g., maximum depth or minimum sample size) is met.</li>
</ul>
</li>
<li><p><strong>Recursive Splitting</strong></p>
<ul>
<li>At each node, the algorithm continues splitting based on the feature that minimizes the variance.</li>
<li>For example, a tree might first split the data based on $X &#x3D; 5$, then further split the subset $X &gt; 5$ based on $X &#x3D; 7$.</li>
</ul>
</li>
<li><p><strong>Leaf Nodes and Predictions</strong></p>
<ul>
<li>When the tree reaches the stopping condition, each leaf node represents a final prediction, which is the mean target value of the data points in that node.</li>
<li>For instance, if a leaf node contains values $Y &#x3D; 10, 12, 14$, the prediction for that leaf would be the average $12$.</li>
</ul>
</li>
<li><p><strong>Prediction for New Data</strong></p>
<ul>
<li>For new data, the tree traverses from the root to a leaf node, where the predicted value is the mean of the target values in that leaf.</li>
</ul>
</li>
</ol>
<h1 id="Bagging-vs-Boosting"><a href="#Bagging-vs-Boosting" class="headerlink" title="Bagging vs Boosting"></a>Bagging vs Boosting</h1><p>In machine learning, <strong>Bagging</strong> and <strong>Boosting</strong> are two popular ensemble techniques used to improve the performance of models. These methods <strong>combine the predictions of multiple base learners to form a stronger model</strong>, but they approach this goal in different ways.</p>
<h2 id="Bagging-Bootstrap-Aggregating"><a href="#Bagging-Bootstrap-Aggregating" class="headerlink" title="Bagging (Bootstrap Aggregating)"></a>Bagging (Bootstrap Aggregating)</h2><p><strong>Bagging</strong> is an ensemble technique that reduces variance by training multiple base learners independently on different subsets of the data and then combining their predictions.</p>
<h3 id="1-How-Bagging-Works"><a href="#1-How-Bagging-Works" class="headerlink" title="1. How Bagging Works"></a>1. <strong>How Bagging Works</strong></h3><ol>
<li><strong>Data Sampling</strong>: Multiple subsets of the training data are created by random sampling with replacement (bootstrap sampling).</li>
<li><strong>Train Multiple Models</strong>: Each subset is used to train a separate model, typically the same type of model (e.g., decision trees).</li>
<li><strong>Combine Predictions</strong>: For classification problems, the final prediction is the class that receives the most votes from all base learners (majority voting). For regression problems, the final prediction is the average of all base learner predictions.</li>
</ol>
<h3 id="2-Advantages"><a href="#2-Advantages" class="headerlink" title="2. Advantages"></a>2. <strong>Advantages</strong></h3><ul>
<li>Reduces overfitting, particularly with high-variance models (e.g., decision trees).</li>
<li>Works well with unstable base learners.</li>
</ul>
<h3 id="3-Disadvantages"><a href="#3-Disadvantages" class="headerlink" title="3. Disadvantages"></a>3. <strong>Disadvantages</strong></h3><ul>
<li>Doesn’t perform as well when base learners are weak or the model complexity is too high.</li>
</ul>
<h3 id="4-Example-Algorithm"><a href="#4-Example-Algorithm" class="headerlink" title="4. Example Algorithm"></a>4. <strong>Example Algorithm</strong></h3><ul>
<li><strong>Random Forest</strong>: A popular implementation of Bagging, where base learners are decision trees trained on random subsets of features.</li>
</ul>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p><strong>Boosting</strong> is an ensemble technique that improves weak learners by iteratively training them on the data and adjusting the weights to focus on the mistakes of previous models.</p>
<h3 id="1-How-Boosting-Works"><a href="#1-How-Boosting-Works" class="headerlink" title="1. How Boosting Works"></a>1. <strong>How Boosting Works</strong></h3><ol>
<li><strong>Train the First Model</strong>: Train a base learner on the training data.</li>
<li><strong>Calculate Error</strong>: Calculate the errors made by the first model.</li>
<li><strong>Adjust Weights</strong>: Increase the weights of the misclassified data points, so that the next model will focus more on them.</li>
<li><strong>Train Subsequent Models</strong>: Train the next model using the updated weights.</li>
<li><strong>Combine Predictions</strong>: The final prediction is a weighted average (regression) or a weighted vote (classification) of all base learners.</li>
</ol>
<h3 id="2-Advantages-1"><a href="#2-Advantages-1" class="headerlink" title="2. Advantages"></a>2. <strong>Advantages</strong></h3><ul>
<li>Reduces bias, improving model accuracy by focusing on hard-to-predict examples.</li>
<li>Works well with weak learners that have high bias.</li>
</ul>
<h3 id="3-Disadvantages-1"><a href="#3-Disadvantages-1" class="headerlink" title="3. Disadvantages"></a>3. <strong>Disadvantages</strong></h3><ul>
<li>Can overfit if data is noisy or contains outliers.</li>
<li>Computationally expensive since models are trained sequentially.</li>
</ul>
<h3 id="4-Example-Algorithms"><a href="#4-Example-Algorithms" class="headerlink" title="4. Example Algorithms"></a>4. <strong>Example Algorithms</strong></h3><ul>
<li><strong>AdaBoost</strong>: A widely used Boosting algorithm that adjusts sample weights based on misclassifications.</li>
<li><strong>Gradient Boosting</strong>: An improved version of Boosting that optimizes the model using gradient descent.</li>
<li><strong>XGBoost</strong>: A highly efficient implementation of Gradient Boosting, popular in machine learning competitions.</li>
</ul>
<p><img src="/blog/./img/ML4-3.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-16T18:50:05.000Z" title="1/16/2025, 6:50:05 PM">2025-01-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2025/01/16/Machine-Learning-3/">About Machine Learning ( Part 3: Logistic Regression )</a></p><div class="content"><h2 id="Classification-Problem"><a href="#Classification-Problem" class="headerlink" title="Classification Problem"></a>Classification Problem</h2><p>In machine learning, when we are predicting a discrete label, such as determining whether an email is spam or not, we are dealing with a classification problem. Logistic regression is commonly used for <strong>binary classification</strong> tasks, where the goal is to predict one of two classes, typically represented as 0 or 1.</p>
<p>The logistic function (also called the <strong>sigmoid function</strong>) is the core of logistic regression, as it maps input features to probabilities between 0 and 1. These probabilities represent the likelihood of the sample belonging to a particular class.</p>
<p>The logistic function is defined as:</p>
<p>$$<br>\sigma(z) &#x3D; \frac{1}{1 + e^{-z}}<br>$$</p>
<p>Where $z &#x3D; \omega_0 + \mathbf{\omega}^T \mathbf{x}$, the linear combination of the input features $\mathbf{x}$ and the model’s parameters $\mathbf{\omega}$.</p>
<h2 id="Model-Representation"><a href="#Model-Representation" class="headerlink" title="Model Representation"></a>Model Representation</h2><p>In logistic regression, we aim to predict the probability that an observation $\mathbf{x}$ belongs to class 1. The predicted probability is given by the following equation:</p>
<p>$$<br>p(C &#x3D; 1|\mathbf{x}) &#x3D; \sigma(\omega_0 + \mathbf{\omega}^T \mathbf{x}) &#x3D; \frac{1}{1 + e^{-(\omega_0 + \mathbf{\omega}^T \mathbf{x})}}<br>$$</p>
<p>where:</p>
<ul>
<li>$p(C &#x3D; 1|\mathbf{x})$: The probability that the class label $C$ is 1, given the input features $\mathbf{x}$.</li>
<li>$\omega_0$: The <strong>bias</strong> term, which helps adjust the output independently of the input features.</li>
<li>$\mathbf{\omega}$: The <strong>weight vector</strong> that contains the coefficients for each feature.</li>
<li>$\mathbf{\omega}^T \mathbf{x}$: The <strong>dot product</strong> between the weight vector $\mathbf{\omega}$ and the feature vector $\mathbf{x}$, representing the weighted sum of the input features.</li>
</ul>
<h2 id="Decision-Boundary"><a href="#Decision-Boundary" class="headerlink" title="Decision Boundary"></a>Decision Boundary</h2><p>In binary classification, the <strong>decision boundary</strong> is the point where the model predicts equal probabilities for both classes, meaning the probability of being in class 0 is 0.5 and the probability of being in class 1 is also 0.5. This boundary helps separate the two classes.</p>
<p>We calculate this boundary by setting the predicted probability equal to 0.5:</p>
<p>$$<br>p(C &#x3D; 1|\mathbf{x}) &#x3D; 0.5<br>$$</p>
<p><img src="/blog/./img/ML3-1.png"></p>
<p>This happens when the output of the logistic function equals 0.5. Solving for the decision boundary, we get:</p>
<p>$$<br>\sigma(\omega_0 + \mathbf{\omega}^T \mathbf{x}) &#x3D; 0.5<br>$$</p>
<p>This implies:</p>
<p>$$<br>\omega_0 + \mathbf{\omega}^T \mathbf{x} &#x3D; 0<br>$$</p>
<p>This equation represents the decision boundary where the model will predict a 50% chance of the sample belonging to either class. Points on this boundary are classified as uncertain.</p>
<h2 id="Maximum-Likelihood-Estimation-MLE"><a href="#Maximum-Likelihood-Estimation-MLE" class="headerlink" title="Maximum Likelihood Estimation (MLE)"></a>Maximum Likelihood Estimation (MLE)</h2><p>In logistic regression, the goal is to find the parameters $\mathbf{\omega} &#x3D; (\omega_0, \omega_1, …, \omega_d)$ that maximize the likelihood of observing the training data. The likelihood function $L(\mathbf{\omega})$ is the probability of the observed labels given the feature vectors.</p>
<p>If We assume that the data is independent and<br>identically distributed (IDD). The likelihood function will be:</p>
<p>$$<br>L(\mathbf{\omega}) &#x3D; \prod_{i&#x3D;1}^{N} p(t_i | \mathbf{x}_i; \mathbf{\omega})<br>$$</p>
<p>Where:</p>
<ul>
<li>$N$: The number of training samples.</li>
<li>$t_i$: The actual label for the $i$-th sample.</li>
<li>$\mathbf{x}_i$: The feature vector for the $i$-th sample.</li>
<li>$p(t_i | \mathbf{x}_i; \mathbf{\omega})$: The probability of observing label $t_i$ given the features $\mathbf{x}_i$ and parameters $\mathbf{\omega}$.</li>
</ul>
<p>Maximizing this likelihood function helps us find the optimal values for the model’s parameters.</p>
<h2 id="Log-Likelihood-Function"><a href="#Log-Likelihood-Function" class="headerlink" title="Log-Likelihood Function"></a>Log-Likelihood Function</h2><p>However, when we have many samples ($N$ is large) and each probability $p(t_i | \mathbf{x}_i; \mathbf{\omega})$ is a value less than 1, the product of these probabilities becomes very small. This leads to a problem called <strong>Numerical Underflow</strong>, where the computer cannot handle such small numbers.</p>
<p>So, maximizing the likelihood function directly is difficult due to the product of probabilities. Instead, we take the <strong>log-likelihood</strong>, which simplifies the optimization by turning the product into a sum:</p>
<p>$$<br>\ln(L(\mathbf{\omega})) &#x3D; \sum_{i&#x3D;1}^{N} \left[ t_i \ln(p(t_i &#x3D; 1|\mathbf{x}_i; \mathbf{\omega})) + (1 - t_i) \ln(1 - p(t_i &#x3D; 1|\mathbf{x}_i; \mathbf{\omega})) \right]<br>$$</p>
<p>This form assumes a <strong>binary classification</strong> scenario, where each label $t_i$ can only be either 0 or 1. In such a case:</p>
<ul>
<li>If $t_i &#x3D; 1$, we calculate the log of the predicted probability for class 1: $\ln(p(t_i &#x3D; 1|\mathbf{x}_i; \mathbf{\omega}))$.</li>
<li>If $t_i &#x3D; 0$, we calculate the log of the probability of class 0, which is $1 - p(t_i &#x3D; 1|\mathbf{x}_i; \mathbf{\omega})$: $\ln(1 - p(t_i &#x3D; 1|\mathbf{x}_i; \mathbf{\omega}))$.</li>
</ul>
<p>This reflects the basic assumption of binary classification in logistic regression, where the goal is to predict the probability of an input sample belonging to class 1 (or class 0, which is just the complement of class 1).</p>
<h2 id="Gradient-Descent-for-Optimization"><a href="#Gradient-Descent-for-Optimization" class="headerlink" title="Gradient Descent for Optimization"></a>Gradient Descent for Optimization</h2><p>We use <strong>gradient descent</strong> to maximize the log-likelihood function. Gradient descent involves computing the gradient of the log-likelihood with respect to the parameters $\mathbf{\omega}$, and then updating the parameters in the direction that increases the log-likelihood.</p>
<p>The gradient of the log-likelihood function with respect to each parameter $\omega_d$ is:</p>

$$
\frac{\partial \ln(L(\mathbf{\omega}))}{\partial \omega_d} = \sum_{i=1}^{N} ( t_i - p(C = 1 \mid \mathbf{x}_i; \mathbf{\omega})) x_{i,d}
$$


<p>Where:</p>
<ul>
<li>$x_{i,d}$ is the $d$-th feature of the $i$-th sample.</li>
<li>$p(C &#x3D; 1|\mathbf{x}_i; \mathbf{\omega})$ is the predicted probability of class 1 for the $i$-th sample.</li>
<li>$t_i$ is the <strong>true label</strong> of the $i$-th sample, where $t_i &#x3D; 1$ if the sample belongs to class 1 (positive class), and $t_i &#x3D; 0$ if it belongs to class 0 (negative class).</li>
</ul>
<p>Explanation:</p>
<ul>
<li>The term $(t_i - p(C &#x3D; 1|\mathbf{x}_i; \mathbf{\omega}))$ represents the <strong>error</strong> between the true label and the predicted probability for the $i$-th sample.</li>
<li>The product of this error and the corresponding feature $x_{i,d}$ allows us to adjust the weight $\omega_d$ based on how the feature $x_{i,d}$ contributes to the error.</li>
</ul>
<p>By summing over all $N$ samples, the gradient is computed for each parameter $\omega_d$. Using the gradient, we update the parameters $\mathbf{\omega}$ using the following rule:</p>
<p>$$<br>\omega_d \leftarrow \omega_d - \lambda \frac{\partial \ln(L(\mathbf{\omega}))}{\partial \omega_d}<br>$$</p>
<p>Where:</p>
<ul>
<li>$\lambda$ is the learning rate, which controls the step size during optimization.</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/kongchenglc/Machine-Learning-Examples/blob/master/logistic-regression3.py">Demo Code</a></p>
<h2 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h2><!-- ![](../img/ML3-2.png) -->

<p>The confusion matrix is a table that summarizes the performance of a classifier on a set of test data for which the true values are known.</p>
<table>
<thead>
<tr>
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Actual Positive</strong></td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr>
<td><strong>Actual Negative</strong></td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody></table>
<ul>
<li><strong>True Positive (TP):</strong> Correctly predicted positive instances.</li>
<li><strong>True Negative (TN):</strong> Correctly predicted negative instances.</li>
<li><strong>False Positive (FP):</strong> Negative instances incorrectly predicted as positive.</li>
<li><strong>False Negative (FN):</strong> Positive instances incorrectly predicted as negative.</li>
</ul>
<h3 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h3><p>Accuracy measures the proportion of correctly classified instances (both positive and negative) out of all predictions.</p>
<p><strong>Formula:</strong></p>
<p>$$<br>\text{Accuracy} &#x3D; \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}<br>$$</p>
<p><strong>When to use Accuracy:</strong></p>
<ul>
<li>When the dataset is balanced, meaning the number of positive and negative instances is roughly equal.</li>
</ul>
<hr>
<h3 id="Precision-Positive-Predictive-Value"><a href="#Precision-Positive-Predictive-Value" class="headerlink" title="Precision (Positive Predictive Value)"></a>Precision (Positive Predictive Value)</h3><p>Precision quantifies the proportion of positive predictions that are correct.</p>
<p><strong>Formula:</strong></p>
<p>$$<br>\text{Precision} &#x3D; \frac{\text{TP}}{\text{TP} + \text{FP}}<br>$$</p>
<p><strong>Use case for Precision:</strong></p>
<ul>
<li>When false positives have a high cost (e.g., flagging legitimate emails as spam).</li>
</ul>
<hr>
<h3 id="Recall-Sensitivity-or-True-Positive-Rate"><a href="#Recall-Sensitivity-or-True-Positive-Rate" class="headerlink" title="Recall (Sensitivity or True Positive Rate)"></a>Recall (Sensitivity or True Positive Rate)</h3><p>Recall measures the proportion of actual positives that are correctly identified.</p>
<p><strong>Formula:</strong></p>
<p>$$<br>\text{Recall} &#x3D; \frac{\text{TP}}{\text{TP} + \text{FN}}<br>$$</p>
<p><strong>Use case for Recall:</strong></p>
<ul>
<li>When false negatives have a high cost (e.g., failing to detect a disease in medical testing).</li>
</ul>
<hr>
<h3 id="F1-Score-Harmonic-Mean-of-Precision-and-Recall"><a href="#F1-Score-Harmonic-Mean-of-Precision-and-Recall" class="headerlink" title="F1-Score (Harmonic Mean of Precision and Recall)"></a>F1-Score (Harmonic Mean of Precision and Recall)</h3><p>The F1-Score combines Precision and Recall into a single metric, especially useful when you need to balance the trade-off between the two.</p>
<p><strong>Formula:</strong></p>
<p>$$<br>F_1 &#x3D; 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}<br>$$</p>
<p><strong>Why use F1-Score?</strong></p>
<ul>
<li>It is beneficial when dealing with imbalanced datasets, as it considers both false positives and false negatives.</li>
</ul>
<hr>
<h3 id="Key-Insights"><a href="#Key-Insights" class="headerlink" title="Key Insights"></a>Key Insights</h3><ul>
<li><strong>Accuracy</strong> works well on balanced datasets but may be misleading when classes are imbalanced.</li>
<li><strong>Precision</strong> is crucial when false positives are costly.</li>
<li><strong>Recall</strong> is critical when false negatives are costly.</li>
<li><strong>F1-Score</strong> provides a balanced measure when both Precision and Recall are important.</li>
</ul>
<p>By carefully analyzing the confusion matrix and the derived metrics, you can fine-tune your model for optimal performance, depending on the specific requirements of your application.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-07T16:41:21.000Z" title="1/7/2025, 4:41:21 PM">2025-01-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2025/01/07/Machine-Learning-2/">About Machine Learning ( Part 2: Linear Regression )</a></p><div class="content"><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>In prediction tasks, we often use independent features to predict a dependent variable. If we have a dataset:</p>
<p>$$<br>{ x_d^{(i)}, t^{(i)} }<br>$$</p>
<p>where:</p>
<ul>
<li>$x_d^{(i)}$: The $d$-th feature of the $i$-th instance in the dataset.</li>
<li>$t^{(i)}$: The target value (dependent variable) for the $i$-th instance.</li>
<li>$i &#x3D; 1, \dots, N$: $i$ indexes the instances, and $N$ is the total number of instances in the dataset. ( Here $i$ is not power )</li>
<li>$d &#x3D; 1, \dots, D$: $d$ indexes the features, and $D$ is the total number of independent features.</li>
</ul>
<p>Each feature in the dataset can be expressed as:</p>
<p>$$<br>x_d^{(i)}<br>$$</p>
<p>For simplicity, the following focuses on a <strong>single feature</strong> $x$, meaning $D &#x3D; 1$.</p>
<h2 id="Polynomial"><a href="#Polynomial" class="headerlink" title="Polynomial"></a>Polynomial</h2><p>This is a <strong>curve fitting</strong> problem, where we aim to fit a polynomial function to model the relationship between the independent variable $x$ and the dependent variable $t$.</p>
<p>A polynomial model is expressed as:</p>
<p>$$<br>h(x, \omega) &#x3D; \omega_0 + \omega_1 x + \omega_2 x^2 + \cdots + \omega_M x^M<br>$$</p>
<ul>
<li>$h(x, \omega)$: The predicted output (dependent variable) for a given input $x$.</li>
<li>$\omega_0, \omega_1, \dots, \omega_M$: The coefficients (parameters) of the polynomial.</li>
<li>$M$: The order of the polynomial, which represents the highest power of $x$ used in the model.</li>
</ul>
<p>This expanded form explicitly shows all terms of the polynomial up to order $M$.</p>
<p>It can also be written in a more compact form using summation:</p>
<p>$$<br>h(x, \omega) &#x3D; \omega_0 + \sum_{j&#x3D;1}^{M} \omega_j x^j<br>$$</p>
<p>Here:</p>
<ul>
<li>The summation $\sum_{j&#x3D;1}^{M} \omega_j x^j$ compactly represents all terms from $j &#x3D; 1$ (first-order) to $j &#x3D; M$ (highest-order).</li>
<li>$\omega_0$: The constant term (bias), which is excluded from the summation since it is independent of $x$.</li>
</ul>
<h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><p>For a straight line, the model is a linear function of the form:</p>
<p>$$<br>f(x, \omega) &#x3D; \omega_0 + \omega_1 x<br>$$</p>
<p>Where:</p>
<ul>
<li>$M &#x3D; 1$, indicating that the polynomial is of degree 1 (a straight line).</li>
<li>$f(x, \omega) &#x3D; \omega_0 + \omega_1 x$ is the equation of the line.</li>
<li>$\omega_1$ represents the slope of the line, and $\omega_0$ represents the y-intercept in the equation.</li>
</ul>
<p>We can use optimization to minimize the overall error. The cost function $J(\omega)$ is defined as:</p>
<p>$$<br>J(\omega) &#x3D; \frac{1}{2} \sum_{n&#x3D;1}^{N} \left(t_n - f(x_n, \omega)\right)^2<br>$$</p>
<p>Where:</p>
<ul>
<li>$J(\omega)$ is the cost function that we aim to minimize ( MSE ).</li>
<li>$t_n$ is the target value (actual value) for the $n$-th data point.</li>
<li>$f(x_n, \omega)$ is the predicted value from the model for the $n$-th data point.</li>
<li>$N$ is the total number of data points in the dataset.</li>
</ul>
<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>Gradient Descent is an optimization algorithm used to minimize the cost function. The idea is to adjust the parameters ($\omega_0$, $\omega_1$, etc.) in the direction of the <strong>negative gradient</strong> of the cost function to reduce the error. The general update rule is:</p>
<p>$$<br>\omega \leftarrow \omega - \lambda \nabla J(\omega)<br>$$</p>
<p>Here:</p>
<ul>
<li>$\omega$ represents the model parameters (e.g., $\omega_0, \omega_1$).</li>
<li>$\lambda$ is the learning rate, controlling the step size in each update.</li>
<li>$\nabla J(\omega)$ is the gradient of the cost function with respect to $\omega$.</li>
</ul>
<hr>
<p>The cost function for linear regression is:</p>
<p>$$<br>J(\omega) &#x3D; \frac{1}{2} \sum_{n&#x3D;1}^N \left( (\omega_0 + \omega_1 x_n) - t_n \right)^2<br>$$</p>
<p>We compute the partial derivatives of $J(\omega)$ with respect to each parameter:</p>
<ol>
<li><p><strong>Gradient with respect to $\omega_0$</strong>:</p>
<p>$$<br>\frac{\partial J(\omega)}{\partial \omega_0} &#x3D; \sum_{n&#x3D;1}^N \left( (\omega_0 + \omega_1 x_n) - t_n \right)<br>$$</p>
</li>
<li><p><strong>Gradient with respect to $\omega_1$</strong>:<br>$$<br>\frac{\partial J(\omega)}{\partial \omega_1} &#x3D; \sum_{n&#x3D;1}^N \left( (\omega_0 + \omega_1 x_n) - t_n \right) x_n<br>$$</p>
</li>
</ol>
<hr>
<p>Using the gradients, the parameters are updated as follows:</p>
<ol>
<li><p><strong>For $\omega_0$</strong>:</p>
<p>$$<br>\omega_0 \leftarrow \omega_0 - \lambda \sum_{n&#x3D;1}^N \left( (\omega_0 + \omega_1 x_n) - t_n \right)<br>$$</p>
</li>
<li><p><strong>For $\omega_1$</strong>:<br>$$<br>\omega_1 \leftarrow \omega_1 - \lambda \sum_{n&#x3D;1}^N \left( (\omega_0 + \omega_1 x_n) - t_n \right) x_n<br>$$</p>
</li>
</ol>
<hr>
<ol>
<li>Initialize $\omega_0$ and $\omega_1$ with some random values (e.g., $0$).</li>
<li>Compute the gradients $\frac{\partial J(\omega)}{\partial \omega_0}$ and $\frac{\partial J(\omega)}{\partial \omega_1}$.</li>
<li>Update $\omega_0$ and $\omega_1$ using the update rules.</li>
<li>Repeat the process until:<ul>
<li>The cost function $J(\omega)$ converges to a minimum, or</li>
<li>The number of iterations reaches a predefined limit.</li>
</ul>
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://github.com/kongchenglc/Machine-Learning-Examples/blob/master/linear-regression1.py">Demo Code</a></p>
<p><img src="/blog/./img/ML2-1.png"></p>
<h2 id="Linear-Regression-with-Multiple-Features"><a href="#Linear-Regression-with-Multiple-Features" class="headerlink" title="Linear Regression with Multiple Features"></a>Linear Regression with Multiple Features</h2><p>The model can be written as:</p>
<p>$$<br>\hat{y} &#x3D; \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \dots + \theta_D x_D<br>$$</p>
<p>Where:</p>
<ul>
<li>$D$ is the number of attributes (features) in the dataset.</li>
<li>$x_1, x_2, \dots, x_D$ are the features of the data.</li>
<li>$\theta_0$ is the intercept (bias term).</li>
<li>$\theta_1, \theta_2, \dots, \theta_D$ are the weights (coefficients) corresponding to each feature.</li>
</ul>
<p>This equation can also be expressed in <strong>matrix form</strong> for computational efficiency.</p>
<hr>
<p>In matrix form, the prediction $\hat{y}$ is expressed as:</p>
<p>$$<br>\hat{y} &#x3D; X \theta<br>$$</p>
<p>Where:</p>
<ul>
<li>$X$ is the design matrix of size $N \times (D+1)$, where:<ul>
<li>$N$ is the number of instances (data points).</li>
<li>The first column of $X$ is all ones, representing the bias term ($\theta_0$).</li>
<li>The remaining columns correspond to the feature values.</li>
</ul>
</li>
</ul>
<p>For example, $X$ can look like this:</p>
<p>$$<br>X &#x3D;<br>\begin{bmatrix}<br>1 &amp; x_1^{(1)} &amp; x_2^{(1)} &amp; \dots &amp; x_D^{(1)} \newline<br>1 &amp; x_1^{(2)} &amp; x_2^{(2)} &amp; \dots &amp; x_D^{(2)} \newline<br>\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \newline<br>1 &amp; x_1^{(N)} &amp; x_2^{(N)} &amp; \dots &amp; x_D^{(N)}<br>\end{bmatrix}<br>$$</p>
<ul>
<li>$\theta$ is the vector of coefficients:<br>$$<br>\theta &#x3D;<br>\begin{bmatrix}<br>\theta_0 \newline<br>\theta_1 \newline<br>\theta_2 \newline<br>\vdots \newline<br>\theta_D<br>\end{bmatrix}<br>$$</li>
</ul>
<hr>
<p>To find the optimal values of $\theta$, we minimize the cost function, which is typically the <strong>Mean Squared Error (MSE)</strong>:</p>
<p>$$<br>J(\theta) &#x3D; \frac{1}{2N} \sum_{i&#x3D;1}^N \left( \hat{y}^{(i)} - t^{(i)} \right)^2<br>$$</p>
<p>In matrix form, this is written as:</p>
<p>$$<br>J(\theta) &#x3D; \frac{1}{2N} | X \theta - t |^2<br>$$</p>
<p>Where $t$ is the vector of true target values:</p>
<p>$$<br>t &#x3D;<br>\begin{bmatrix}<br>t^{(1)} \newline<br>t^{(2)} \newline<br>\vdots \newline<br>t^{(N)}<br>\end{bmatrix}<br>$$</p>
<hr>
<p>By setting the gradient of $J(\theta)$ with respect to $\theta$ to zero, we derive the <strong>closed-form solution</strong>:<br>$$<br>\hat{\theta} &#x3D; (X^T X)^{-1} X^T t<br>$$</p>
<p>Where:</p>
<ul>
<li>$X^T$ is the transpose of the design matrix.</li>
<li>$(X^T X)^{-1}$ is the inverse of the matrix product $X^T X$.</li>
</ul>
<h2 id="Higher-Order-Polynomials"><a href="#Higher-Order-Polynomials" class="headerlink" title="Higher Order Polynomials"></a>Higher Order Polynomials</h2><p>In polynomial regression, we model the relationship between the input variable $x$ and output $f(x, \omega)$ using a higher degree polynomial:</p>
<p>$$<br>f(x, \omega) &#x3D; \omega_0 + \omega_1 x + \omega_2 x^2 + \dots + \omega_M x^M &#x3D; \sum_{j&#x3D;0}^{M} \omega_j x^j<br>$$</p>
<ul>
<li><strong>$x$</strong> is the input feature, and <strong>$\omega_j$</strong> are the coefficients.</li>
<li><strong>$M$</strong> is the degree of the polynomial, which determines the complexity of the model.</li>
</ul>
<p>Choosing $M$ (Degree of Polynomial):</p>
<ul>
<li><strong>Small $M$</strong>: Captures simple relationships; less prone to overfitting.</li>
<li><strong>Large $M$</strong>: Can overfit the data by capturing noise.</li>
<li><strong>Selection</strong>: Cross-validation is used to determine the best $M$ to balance fit and generalization.</li>
</ul>
<p><img src="/blog/./img/ML2-2.png"></p>
<h2 id="Overfitting-Regularization"><a href="#Overfitting-Regularization" class="headerlink" title="Overfitting &amp; Regularization"></a>Overfitting &amp; Regularization</h2><p>In linear regression, <strong>overfitting</strong> occurs when the model becomes too complex and starts to fit noise in the training data. To prevent overfitting, we use <strong>regularization</strong> to penalize large coefficients and simplify the model.</p>
<p>The regularized cost function is:</p>
<p>$$<br>E(\omega) &#x3D; \frac{1}{2} \sum_{n&#x3D;1}^{N} (f(x_n, \omega) - t_n)^2 + \frac{\lambda}{2} |\omega|^2<br>$$</p>
<p>Where:</p>
<ul>
<li><strong>$f(x_n, \omega)$</strong> is the model’s prediction for the $n$-th data point.</li>
<li><strong>$t_n$</strong> is the true target for the $n$-th data point.</li>
<li><strong>$\lambda$</strong> is the regularization parameter that controls the strength of the penalty.</li>
<li><strong>$|\omega|^2$</strong> is the squared <strong>L2 norm</strong> of the weights, i.e., the sum of the squares of the coefficients.</li>
</ul>
<p>The <strong>$\lambda$</strong> parameter allows you to control the trade-off between fitting the data well and keeping the model simple.</p>
<p><img src="/blog/./img/ML2-3.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-01-06T11:29:21.000Z" title="1/6/2025, 11:29:21 AM">2025-01-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2025/01/06/Machine-Learning-1/">About Machine Learning ( Part 1: Gradient Descent )</a></p><div class="content"><h1 id="Data-Science"><a href="#Data-Science" class="headerlink" title="Data Science"></a>Data Science</h1><h2 id="Target-Variable"><a href="#Target-Variable" class="headerlink" title="Target Variable"></a>Target Variable</h2><p>The target variable is the variable the model aims to predict or explain. It’s also called the dependent variable or label.</p>
<h2 id="Attributes"><a href="#Attributes" class="headerlink" title="Attributes"></a>Attributes</h2><p>Attributes are the features or variables that describe each instance in a dataset. They are also known as features, columns, or independent variables.</p>
<h2 id="Instances"><a href="#Instances" class="headerlink" title="Instances"></a>Instances</h2><p>Instances represent individual samples or data points in a dataset. They are also referred to as samples, rows, or observations.</p>
<h1 id="Design-of-Experiments"><a href="#Design-of-Experiments" class="headerlink" title="Design of Experiments"></a>Design of Experiments</h1><h2 id="Strategy-of-Experiments"><a href="#Strategy-of-Experiments" class="headerlink" title="Strategy of Experiments"></a>Strategy of Experiments</h2><ol>
<li>Best Guess Appraoch</li>
<li>One-Factor-at-a-time: Standard practice but not efficient; Does not consider interactions.</li>
<li>Factorial Design: Considers Interactions; Is more efficient.</li>
</ol>
<h2 id="Principles"><a href="#Principles" class="headerlink" title="Principles"></a>Principles</h2><ol>
<li>Randomization: Conducting experiments in a random order to mitigate systematic bias.</li>
<li>Replication: Repeat experiments to estimate error and improve precision. (* not the same as measurement error)</li>
<li>Blocking: Include experimental factors to mitigate variance from nuisance factors.</li>
</ol>
<h2 id="Public-Data-Repositories"><a href="#Public-Data-Repositories" class="headerlink" title="Public Data Repositories"></a>Public Data Repositories</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.frdr-dfdr.ca/repo/">Federated Research Data Repository</a></li>
<li><a target="_blank" rel="noopener" href="https://archive.ics.uci.edu/ml/datasets.php">UCI Machine learning Repository</a></li>
</ul>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><p>Making the best or most effective use of a situation or resource. In terms of mathematics, we call this reducing a <strong>Cost Function</strong> (a.k.the <strong>objective function</strong>)</p>
<blockquote>
<p>J(θ) &#x3D;?</p>
</blockquote>
<p>We can use optimization to minimize the overall error ( linear model ):</p>
<p>$$<br>J(m, b) &#x3D; \sum_{i&#x3D;0}^{N} [x_i - (mx_i + b)]<br>$$</p>
<p>A solution is referred to global or local maximum or minimum. Mean Squared Error:</p>
<p>$$<br>\text{MSE} &#x3D; \frac{1}{n} \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2<br>$$</p>
<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><ol>
<li>Guess the initial values of the problem parameters (x, y)</li>
<li>Calculate the value of the objective function</li>
<li>Determine the Gradient of the function</li>
<li>Change the parameters of the objective function slightly in the direction of the gradient</li>
<li>Repeat until the error is close to zero or some terminating condition is met.</li>
</ol>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><a target="_blank" rel="noopener" href="https://github.com/kongchenglc/Machine-Learning-Examples">https://github.com/kongchenglc/Machine-Learning-Examples</a></p>
<p><img src="/blog/./img/ML1-2.png"></p>
<h3 id="Problems-with-Gradient-Descent"><a href="#Problems-with-Gradient-Descent" class="headerlink" title="Problems with Gradient Descent"></a>Problems with Gradient Descent</h3><ul>
<li>High dimensional Data is challenging</li>
<li>Only good for Strictly Convex Objective Functions</li>
<li>Requires a lot of memory occupancy</li>
</ul>
<h2 id="Alternatives-to-Gradient-Descent"><a href="#Alternatives-to-Gradient-Descent" class="headerlink" title="Alternatives to Gradient Descent"></a>Alternatives to Gradient Descent</h2><p>A solution is referred to global or local maximum or minimum ( <strong>Non linear methods… Non convex</strong> )</p>
<h3 id="1-Simulated-Annealing"><a href="#1-Simulated-Annealing" class="headerlink" title="1. Simulated Annealing"></a>1. Simulated Annealing</h3><h4 id="Key-Features-of-Simulated-Annealing"><a href="#Key-Features-of-Simulated-Annealing" class="headerlink" title="Key Features of Simulated Annealing:"></a>Key Features of Simulated Annealing:</h4><ol>
<li><p><strong>Global Search Capability</strong>:</p>
<ul>
<li>Simulated Annealing can escape local optima due to its ability to accept worse solutions $\Delta f \geq 0$ at high temperatures.</li>
<li>As the temperature decreases, the algorithm becomes more “greedy,” eventually converging to a global or near-global optimum.</li>
</ul>
</li>
<li><p><strong>Probabilistic Acceptance Rule</strong>:</p>
<ul>
<li>The acceptance of worse solutions is governed by the probability function $ P &#x3D; e^{-\Delta f &#x2F; T} $.</li>
<li>This allows the algorithm to explore the solution space freely during the initial stages, avoiding premature convergence.</li>
</ul>
</li>
<li><p><strong>Wide Applicability</strong>:</p>
<ul>
<li>Simulated Annealing does not rely on specific properties of the objective function, such as differentiability or continuity.</li>
<li>It is suitable for both discrete and continuous optimization problems.</li>
</ul>
</li>
</ol>
<h4 id="Advantages-and-Disadvantages-of-Simulated-Annealing"><a href="#Advantages-and-Disadvantages-of-Simulated-Annealing" class="headerlink" title="Advantages and Disadvantages of Simulated Annealing:"></a>Advantages and Disadvantages of Simulated Annealing:</h4><p><strong>Advantages</strong>:</p>
<ul>
<li>Simple to implement and widely applicable.</li>
<li>Capable of avoiding local optima.</li>
<li>Does not require the objective function to be differentiable or continuous.</li>
</ul>
<p><strong>Disadvantages</strong>:</p>
<ul>
<li>Computationally intensive, especially for large-scale problems, as it may require many iterations.</li>
<li>Convergence is slow, and performance heavily depends on parameters like initial temperature and cooling rate.</li>
<li>In some cases, it may fail to find the true global optimum, instead settling on a near-optimal solution.</li>
</ul>
<p><img src="/blog/./img/ML1-3.png"></p>
<h3 id="2-Particle-Swarm-Optimization"><a href="#2-Particle-Swarm-Optimization" class="headerlink" title="2. Particle Swarm Optimization"></a>2. Particle Swarm Optimization</h3><h4 id="Main-Features"><a href="#Main-Features" class="headerlink" title="Main Features:"></a><strong>Main Features:</strong></h4><ul>
<li><p><strong>Inspired by Nature</strong>: It simulates the social behavior of birds flocking or fish schooling, where each particle adjusts its position based on personal and collective experience.</p>
</li>
<li><p><strong>Velocity and Position Updates</strong>: Each particle updates its position based on its best solution and the best solution found by the group.</p>
</li>
<li><p><strong>Population-Based</strong>: PSO uses a group of particles (potential solutions) to explore the solution space.</p>
</li>
</ul>
<h4 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages:"></a><strong>Advantages:</strong></h4><ul>
<li><strong>Simple and Easy to Implement</strong>: PSO has fewer parameters compared to other algorithms like Genetic Algorithms.</li>
<li><strong>Global Search</strong>: PSO can escape local optima, helping it find a better global optimum.</li>
<li><strong>No Gradient Needed</strong>: It does not require derivative information, making it suitable for complex, non-differentiable problems.</li>
<li><strong>Flexible</strong>: It can be applied to both continuous and discrete optimization problems.</li>
</ul>
<h4 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages:"></a><strong>Disadvantages:</strong></h4><ul>
<li><strong>Slow Convergence</strong>: PSO can take a long time to converge, especially for complex problems.</li>
<li><strong>Parameter Sensitivity</strong>: The performance heavily depends on the selection of parameters like inertia weight and acceleration coefficients.</li>
<li><strong>Premature Convergence</strong>: In some cases, PSO may converge prematurely to a suboptimal solution.</li>
</ul>
<p>PSO is widely used in optimization problems where derivative information is unavailable or expensive to compute, with the trade-off being a potential slower convergence or suboptimal solutions in complex scenarios.</p>
<p><img src="/blog/./img/ML1-4.gif"></p>
<h3 id="3-Genetic-Algorithms"><a href="#3-Genetic-Algorithms" class="headerlink" title="3. Genetic Algorithms"></a>3. Genetic Algorithms</h3><p><strong>Key Features:</strong></p>
<ol>
<li><strong>Population-Based Search</strong>: GA maintains a population of potential solutions, enhancing its ability to explore the solution space globally.</li>
<li><strong>Incorporates Evolutionary Concepts</strong>: Inspired by natural selection, it uses operators like selection, crossover, and mutation.</li>
<li><strong>Global Search Capability</strong>: Can escape local optima by introducing randomness through crossover and mutation.</li>
<li><strong>Fitness Evaluation</strong>: Solutions are evaluated using a fitness function, which guides the evolution toward optimal solutions.</li>
<li><strong>Flexible Objective Function</strong>: GA works on a wide range of optimization problems without requiring derivative information.</li>
</ol>
<p><strong>Advantages:</strong></p>
<ol>
<li><strong>Global Optimization</strong>: Effective at finding global or near-global optima, especially in non-convex problems with multiple local optima.</li>
<li><strong>Flexible and Robust</strong>: Can handle complex, non-linear, and multi-modal objective functions.</li>
<li><strong>No Requirement for Gradient Information</strong>: Suitable for optimization problems where derivatives are unavailable or undefined.</li>
<li><strong>Adaptability</strong>: Easily adaptable to various problem domains, including discrete and continuous optimization.</li>
<li><strong>Diverse Exploration</strong>: Maintains a diverse population, reducing the risk of premature convergence.</li>
</ol>
<p><strong>Disadvantages:</strong></p>
<ol>
<li><strong>High Computational Cost</strong>: Requires significant computational resources, especially for large populations or complex fitness evaluations.</li>
<li><strong>Parameter Sensitivity</strong>: Performance heavily depends on proper tuning of parameters like mutation rate, crossover rate, and population size.</li>
<li><strong>No Guarantee of Global Optimality</strong>: May converge to a suboptimal solution, particularly if not run for enough generations or with improper settings.</li>
<li><strong>Randomness Dependency</strong>: Relies on stochastic processes, leading to non-deterministic results.</li>
<li><strong>Slow Convergence</strong>: Compared to deterministic methods, GA can be slower, especially for problems with a clear gradient or simpler structure.</li>
</ol>
<p><img src="/blog/./img/ML1-5.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-12-04T23:05:04.000Z" title="12/4/2024, 11:05:04 PM">2024-12-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2024/12/04/About-Project-Management-Part-4/">About Project Management ( Part 4 )</a></p><div class="content"><h1 id="Outsourcing"><a href="#Outsourcing" class="headerlink" title="Outsourcing"></a>Outsourcing</h1><h2 id="Outsourcing-Project-Work"><a href="#Outsourcing-Project-Work" class="headerlink" title="Outsourcing Project Work"></a>Outsourcing Project Work</h2><h3 id="Advantages-of-Outsourcing"><a href="#Advantages-of-Outsourcing" class="headerlink" title="Advantages of Outsourcing"></a>Advantages of Outsourcing</h3><ul>
<li><strong>Cost reduction</strong>: Outsourcing can lead to significant cost savings, as it allows companies to leverage lower labor costs in other countries.</li>
<li><strong>Focus on Core Competencies</strong>: Outsourcing non-core activities allows companies to focus on their primary business functions.</li>
<li><strong>Access to Expertise</strong>: Outsourcing to specialized service providers can provide access to expertise that may not be readily available within the organization.</li>
<li><strong>Scalability</strong>: Outsourcing can facilitate scalability, as service providers can quickly increase or decrease resources as needed.</li>
<li><strong>Risk Management</strong>: Outsourcing can help manage risks associated with new or untested technologies or markets.</li>
</ul></div><a class="article-more button is-small is-size-7" href="/blog/2024/12/04/About-Project-Management-Part-4/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-11-14T12:30:45.000Z" title="11/14/2024, 12:30:45 PM">2024-11-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2024/11/14/About-Project-Management-Part-3/">About Project Management ( Part 3 )</a></p><div class="content"><h1 id="Managing-Risk"><a href="#Managing-Risk" class="headerlink" title="Managing Risk"></a>Managing Risk</h1><h2 id="Risk-Management-Process"><a href="#Risk-Management-Process" class="headerlink" title="Risk Management Process"></a>Risk Management Process</h2><p>Risk Defined:</p>
<ul>
<li>An uncertain event or condition that if it occurs, has a <strong>positive or negative effect</strong> on project objectives.</li>
<li><strong>No</strong> amount of planning can overcome or control risk.</li>
</ul>
<p>Risk Management Defined:</p>
<p>An attempt to recognize and manage potential and unforeseen trouble spots that may occur when the project is implemented.</p>
<ul>
<li><strong>What</strong> can go wrong (risk <strong>event</strong>)</li>
<li><strong>How to minimize</strong> the risk event’s <strong>impact</strong> (consequences)</li>
<li>What can be done <strong>before</strong> an event occurs (anticipation)</li>
<li>What to do when an event occurs (<strong>contingency plans</strong>)</li>
</ul>
<p>Benefits of Risk Management</p>
<ul>
<li>A <strong>proactive</strong> rather than <strong>reactive</strong> approach</li>
<li>Reduces surprises and negative consequences</li>
<li>Prepares the project manager to take appropriate action</li>
<li>Provides better control over the future</li>
<li>Improves chances of reaching project objectives on time, within budget, and of meeting required performance.</li>
</ul></div><a class="article-more button is-small is-size-7" href="/blog/2024/11/14/About-Project-Management-Part-3/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-24T19:11:18.000Z" title="10/24/2024, 7:11:18 PM">2024-10-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.024Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2024/10/24/About-Project-Management-Part-2/">About Project Management ( Part 2 )</a></p><div class="content"><h1 id="Cost-and-Time-Estimation"><a href="#Cost-and-Time-Estimation" class="headerlink" title="Cost and Time Estimation"></a>Cost and Time Estimation</h1><p>Is a trade-off, balancing the benefits of better accuracy against the costs of secured increased accuracy.</p>
<h2 id="Types-of-Estimates"><a href="#Types-of-Estimates" class="headerlink" title="Types of Estimates"></a>Types of Estimates</h2><h3 id="Top-down-macro-estimates"><a href="#Top-down-macro-estimates" class="headerlink" title="Top-down (macro) estimates"></a>Top-down (macro) estimates</h3><ul>
<li>Analogy</li>
<li>Group consensus</li>
<li>Mathematical relationships</li>
</ul>
<h3 id="Bottom-up-micro-estimates"><a href="#Bottom-up-micro-estimates" class="headerlink" title="Bottom-up (micro) estimates"></a>Bottom-up (micro) estimates</h3><ul>
<li>based on estimates of elements found in the <strong>work breakdown structure</strong></li>
</ul>
<h2 id="Why-Estimating-Time-and-Cost-Is-Important"><a href="#Why-Estimating-Time-and-Cost-Is-Important" class="headerlink" title="Why Estimating Time and Cost Is Important"></a>Why Estimating Time and Cost Is Important</h2><ul>
<li>To support good decisions.</li>
<li>To schedule work.</li>
<li>To determine how long the project should take and its cost.</li>
<li>To determine whether the project is worth doing.</li>
<li>To develop cash flow needs.</li>
<li>To determine how well the project is progressing.</li>
</ul></div><a class="article-more button is-small is-size-7" href="/blog/2024/10/24/About-Project-Management-Part-2/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-10-24T12:30:25.000Z" title="10/24/2024, 12:30:25 PM">2024-10-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-02T22:52:24.023Z" title="2/2/2025, 10:52:24 PM">2025-02-02</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/blog/2024/10/24/About-Project-Management-Part-1/">About Project Management ( Part 1 )</a></p><div class="content"><h1 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h1><h2 id="What-Is-a-Project"><a href="#What-Is-a-Project" class="headerlink" title="What Is a Project?"></a>What Is a Project?</h2><p>Project Defined (according to PMI):</p>
<ul>
<li>A temporary endeavor undertaken to create a unique product, service, or result.</li>
</ul>
<p>Major Characteristics of a Project:</p>
<ul>
<li>Has an established objective.</li>
<li>Has a defined lifespan with a beginning and an end.</li>
<li>Involves several departments and professionals.</li>
<li>Involves doing something never done before.</li>
<li>Has specific time, cost, and performance<br>requirements.</li>
</ul></div><a class="article-more button is-small is-size-7" href="/blog/2024/10/24/About-Project-Management-Part-1/#more">Read more</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/blog/img/avatar.jpeg" alt="Lich"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lich</p><p class="is-size-6 is-block">Software Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Canada</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">16</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/kongchenglc" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Defunct Chinese Blog" href="https://kongchenglc.github.io/blog/"><i class="fa-solid fa-link"></i></a></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/">Lich&#039;s Blog</a><p class="is-size-7"><span>&copy; 2025 Lich</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2024</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/blog/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/blog/js/pjax.js"></script><!--!--><script data-pjax src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>