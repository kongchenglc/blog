<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>About Machine Learning ( Part 7: Artificial Neural Network ) - Lich&#039;s Blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="Lich&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lich&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Bayes’ theorem$$P(y|X) &amp;#x3D; \frac{P(X|y) P(y)}{P(X)}$$ where:  $P(y|X)$: Posterior probability of class $y$ given input $X$. $P(X|y)$: Likelihood of seeing $X$ if the class is $y$. $P(y)$: Prior pro"><meta property="og:type" content="blog"><meta property="og:title" content="About Machine Learning ( Part 7: Artificial Neural Network )"><meta property="og:url" content="https://kongchenglc.github.io/blog/2025/02/06/Machine-Learning-7/"><meta property="og:site_name" content="Lich&#039;s Blog"><meta property="og:description" content="Bayes’ theorem$$P(y|X) &amp;#x3D; \frac{P(X|y) P(y)}{P(X)}$$ where:  $P(y|X)$: Posterior probability of class $y$ given input $X$. $P(X|y)$: Likelihood of seeing $X$ if the class is $y$. $P(y)$: Prior pro"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kongchenglc.github.io/blog/img/ML7-1.png"><meta property="og:image" content="https://kongchenglc.github.io/blog/img/ML7-2.png"><meta property="article:published_time" content="2025-02-06T21:43:39.000Z"><meta property="article:modified_time" content="2025-02-16T02:45:33.363Z"><meta property="article:author" content="Lich"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Artificial Neural Network (ANN)"><meta property="article:tag" content="Bayes’ Theorem"><meta property="article:tag" content="Delta Rule"><meta property="article:tag" content="Backpropagation"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://kongchenglc.github.io/blog/img/ML7-1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kongchenglc.github.io/blog/2025/02/06/Machine-Learning-7/"},"headline":"About Machine Learning ( Part 7: Artificial Neural Network )","image":["https://kongchenglc.github.io/blog/img/ML7-1.png","https://kongchenglc.github.io/blog/img/ML7-2.png"],"datePublished":"2025-02-06T21:43:39.000Z","dateModified":"2025-02-16T02:45:33.363Z","author":{"@type":"Person","name":"Lich"},"publisher":{"@type":"Organization","name":"Lich's Blog","logo":{"@type":"ImageObject","url":{"text":"Lich's Blog"}}},"description":"Bayes’ theorem$$P(y|X) &#x3D; \\frac{P(X|y) P(y)}{P(X)}$$ where:  $P(y|X)$: Posterior probability of class $y$ given input $X$. $P(X|y)$: Likelihood of seeing $X$ if the class is $y$. $P(y)$: Prior pro"}</script><link rel="canonical" href="https://kongchenglc.github.io/blog/2025/02/06/Machine-Learning-7/"><link rel="icon" href="/blog/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/">Lich&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-02-06T21:43:39.000Z" title="2/6/2025, 9:43:39 PM">2025-02-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-02-16T02:45:33.363Z" title="2/16/2025, 2:45:33 AM">2025-02-16</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Learning-Notes/">Learning Notes</a></span></div></div><h1 class="title is-3 is-size-4-mobile">About Machine Learning ( Part 7: Artificial Neural Network )</h1><div class="content"><h1 id="Bayes’-theorem"><a href="#Bayes’-theorem" class="headerlink" title="Bayes’ theorem"></a>Bayes’ theorem</h1><p>$$<br>P(y|X) &#x3D; \frac{P(X|y) P(y)}{P(X)}<br>$$</p>
<p>where:</p>
<ul>
<li>$P(y|X)$: Posterior probability of class $y$ given input $X$.</li>
<li>$P(X|y)$: Likelihood of seeing $X$ if the class is $y$.</li>
<li>$P(y)$: Prior probability of class $y$.</li>
<li>$P(X)$: Total probability of $X$ (normalization factor).</li>
</ul>
<h2 id="Bayes-Network-Bayesian-Network-BN"><a href="#Bayes-Network-Bayesian-Network-BN" class="headerlink" title="Bayes Network (Bayesian Network, BN)"></a>Bayes Network (Bayesian Network, BN)</h2><p>A <strong>Bayesian network (BN)</strong> is a <strong>graphical model</strong> representing probabilistic dependencies between variables. It consists of:</p>
<ul>
<li><strong>Nodes:</strong> Represent variables (e.g., symptoms, diseases).</li>
<li><strong>Edges:</strong> Represent conditional dependencies.</li>
</ul>
<p><img src="/blog/./img/ML7-1.png"></p>
<h2 id="Bayesian-Inference-in-BN"><a href="#Bayesian-Inference-in-BN" class="headerlink" title="Bayesian Inference in BN"></a>Bayesian Inference in BN</h2><p>Using Bayes’ rule, we can infer probabilities, such as:</p>
<p>$$<br>P(F|T, C) &#x3D; \frac{P(T, C | F) P(F)}{P(T, C)}<br>$$</p>
<p>Bayesian networks are widely used in <strong>medical diagnosis, fraud detection, and AI decision-making</strong>.</p>
<h1 id="Artificial-Neural-Network-ANN"><a href="#Artificial-Neural-Network-ANN" class="headerlink" title="Artificial Neural Network (ANN)"></a>Artificial Neural Network (ANN)</h1><h2 id="The-Perceptron"><a href="#The-Perceptron" class="headerlink" title="The Perceptron"></a>The Perceptron</h2><p>A <strong>perceptron</strong> is a simple artificial neuron that performs binary classification. It computes a weighted sum of inputs and applies an activation function:</p>
<p>$$<br>y &#x3D; \begin{cases}<br>1, &amp; \text{if } w \cdot X + b &gt; 0 \newline<br>0, &amp; \text{otherwise}<br>\end{cases}<br>$$</p>
<p>where:</p>
<ul>
<li>$X$ is the input vector.</li>
<li>$w$ is the weight vector.</li>
<li>$b$ is the bias term.</li>
</ul>
<h2 id="Learning-in-Perceptrons"><a href="#Learning-in-Perceptrons" class="headerlink" title="Learning in Perceptrons"></a>Learning in Perceptrons</h2><p>The perceptron updates its weights using a simple rule:</p>
<p>$$<br>w \leftarrow w + \Delta w<br>$$</p>
<p>where:</p>
<p>$$<br>\Delta w &#x3D; \eta (y_{\text{true}} - y_{\text{pred}}) X<br>$$</p>
<ul>
<li>$\eta$ is the learning rate.</li>
<li>The perceptron <strong>adjusts weights</strong> only when it makes an error.</li>
</ul>
<p><strong>Limitations of the Perceptron</strong>:</p>
<ul>
<li>Can only solve <strong>linearly separable problems</strong> (e.g., AND, OR gates).</li>
<li><strong>Fails for XOR problems</strong>, motivating more advanced learning rules.</li>
<li>So <strong>activation funtion</strong> are usually used.</li>
</ul>
<h2 id="Delta-Rule"><a href="#Delta-Rule" class="headerlink" title="Delta Rule"></a>Delta Rule</h2><p>The <strong>Delta Rule</strong> is a gradient descent learning rule used in <strong>single-layer perceptrons</strong> and neural networks to minimize error and update weights. The main idea behind this rule is to adjust the weights based on the <strong>gradient of the error</strong> to minimize the loss function (often the Mean Squared Error, MSE). The Delta Rule is a specific case of the <strong>Gradient Descent</strong> method.</p>
<p>Assume the output of a perceptron is calculated by the following formula:</p>
<p>$$<br>y &#x3D; f(w_1 x_1 + w_2 x_2 + \dots + w_n x_n + b)<br>$$</p>
<p>Where:</p>
<ul>
<li>$x_i$ is the input value,</li>
<li>$w_i$ is the corresponding weight,</li>
<li>$b$ is the bias,</li>
<li>$f(\cdot)$ is the activation function (usually a linear or Sigmoid function),</li>
<li>$y$ is the output,</li>
<li>$t$ is the target label (the true value),</li>
<li>$e &#x3D; t - y$ is the error (difference between predicted and true output).</li>
</ul>
<p>The <strong>Delta Rule</strong> updates the weights as follows:</p>
<p>$$<br>\Delta w_i &#x3D; \eta (t - y) x_i<br>$$</p>
<p>Where:</p>
<ul>
<li>$\eta$ is the <strong>learning rate</strong> that controls the step size of the updates,</li>
<li>$(t - y)$ is the error,</li>
<li>$x_i$ is the input used to adjust the corresponding weight.</li>
</ul>
<p>The weight update rule becomes:</p>
<p>$$<br>w_i \leftarrow w_i + \Delta w_i<br>$$</p>
<h3 id="Derivation-of-the-Delta-Rule"><a href="#Derivation-of-the-Delta-Rule" class="headerlink" title="Derivation of the Delta Rule"></a>Derivation of the Delta Rule</h3><h4 id="The-Error-Function-Mean-Squared-Error"><a href="#The-Error-Function-Mean-Squared-Error" class="headerlink" title="The Error Function (Mean Squared Error)"></a>The Error Function (Mean Squared Error)</h4><p>To understand how the Delta Rule works, we first need to define the error function. The <strong>Mean Squared Error (MSE)</strong> is commonly used as the error metric in neural networks, especially for regression tasks. It measures the difference between the target output $t$ and the predicted output $y$:</p>
<p>$$<br>E &#x3D; \frac{1}{2} (t - y)^2<br>$$</p>
<p>Where:</p>
<ul>
<li>$t$ is the target value (the true label),</li>
<li>$y$ is the predicted output from the neural network.</li>
</ul>
<p>The reason we use a factor of $\frac{1}{2}$ is to simplify the derivative when we apply the chain rule during weight updates.</p>
<h4 id="The-Goal-Weight-Update"><a href="#The-Goal-Weight-Update" class="headerlink" title="The Goal: Weight Update"></a>The Goal: Weight Update</h4><p>The goal of the Delta Rule is to update the weights so that the error $E$ is minimized. We do this by adjusting the weights in the direction that reduces the error. To achieve this, we compute the gradient (partial derivative) of the error function with respect to the weights $w_i$.</p>
<p>The output $y$ of a single output unit in the network is determined by:</p>
<p>$$<br>y &#x3D; f(net)<br>$$</p>
<p>Where:</p>
<ul>
<li>$net &#x3D; \sum_{i} w_i x_i + b$ is the weighted sum of inputs, </li>
<li>$f(\cdot)$ is the activation function applied to the weighted sum (in this case, we’ll focus on the <strong>Sigmoid</strong> function).</li>
</ul>
<p>To update the weights, we need the partial derivative of the error $E$ with respect to each weight $w_i$. This is done using the chain rule:</p>
<p>$$<br>\frac{\partial E}{\partial w_i} &#x3D; \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial w_i}<br>$$</p>
<h4 id="Compute-frac-partial-E-partial-y"><a href="#Compute-frac-partial-E-partial-y" class="headerlink" title="Compute $\frac{\partial E}{\partial y}$"></a>Compute $\frac{\partial E}{\partial y}$</h4><p>The first term we need is the derivative of the error with respect to the output $y$. Since $E$ is the squared error, we can differentiate:</p>
<p>$$<br>\frac{\partial E}{\partial y} &#x3D; -(t - y)<br>$$</p>
<p>This represents how much the error changes with respect to the output $y$.</p>
<h4 id="Compute-frac-partial-y-partial-w-i"><a href="#Compute-frac-partial-y-partial-w-i" class="headerlink" title="Compute $\frac{\partial y}{\partial w_i}$"></a>Compute $\frac{\partial y}{\partial w_i}$</h4><p>Next, we calculate the derivative of the output $y$ with respect to each weight $w_i$. The output $y$ is the result of applying the activation function $f$ to the weighted sum $net$:</p>
<p>$$<br>y &#x3D; f(net)<br>$$</p>
<p>Using the chain rule, we get:</p>
<p>$$<br>\frac{\partial y}{\partial w_i} &#x3D; \frac{\partial f(net)}{\partial net} \cdot \frac{\partial net}{\partial w_i}<br>$$</p>
<p>Where:</p>
<ul>
<li>$\frac{\partial f(net)}{\partial net} &#x3D; f’(net)$ is the derivative of the activation function with respect to the net input,</li>
<li>$\frac{\partial net}{\partial w_i} &#x3D; x_i$, since $net &#x3D; \sum w_i x_i + b$.</li>
</ul>
<p>Thus:</p>
<p>$$<br>\frac{\partial y}{\partial w_i} &#x3D; f’(net) \cdot x_i<br>$$</p>
<h4 id="Combine-Terms-for-the-Gradient"><a href="#Combine-Terms-for-the-Gradient" class="headerlink" title="Combine Terms for the Gradient"></a>Combine Terms for the Gradient</h4><p>Now, we combine the terms to compute the gradient of the error with respect to the weight $w_i$:</p>
<p>$$<br>\frac{\partial E}{\partial w_i} &#x3D; -(t - y) \cdot f’(net) \cdot x_i<br>$$</p>
<p>This expression tells us how much to adjust each weight $w_i$ to minimize the error.</p>
<h4 id="Derivative-of-the-Sigmoid-Activation-Function"><a href="#Derivative-of-the-Sigmoid-Activation-Function" class="headerlink" title="Derivative of the Sigmoid Activation Function"></a>Derivative of the Sigmoid Activation Function</h4><p>For the <strong>Sigmoid activation function</strong>, the output $o$ is given by:</p>
<p>$$<br>o &#x3D; f(net) &#x3D; \frac{1}{1 + e^{-net}}<br>$$</p>
<p>The derivative of the Sigmoid function with respect to the net input $net$ is:</p>
<p>$$<br>f’(net) &#x3D; o(1 - o)<br>$$</p>
<p>Where $o$ is the output of the Sigmoid function.</p>
<h4 id="The-Final-Weight-Update-Rule"><a href="#The-Final-Weight-Update-Rule" class="headerlink" title="The Final Weight Update Rule"></a>The Final Weight Update Rule</h4><p>We can now substitute the derivative of the Sigmoid function into the weight update formula. The Delta Rule for updating weights is:</p>
<p>$$<br>\Delta w_i &#x3D; \eta (t - y) \cdot o \cdot (1 - o) \cdot x_i<br>$$</p>
<p>Where:</p>
<ul>
<li>$\eta$ is the learning rate, which controls how much the weights are adjusted at each step,</li>
<li>$(t - y)$ is the error between the target and predicted output,</li>
<li>$o(1 - o)$ is the derivative of the Sigmoid activation function,</li>
<li>$x_i$ is the input corresponding to the weight $w_i$.</li>
</ul>
<p>Finally, the weights are updated as follows:</p>
<p>$$<br>w_i \leftarrow w_i + \Delta w_i<br>$$</p>
<p>This update ensures that the weights move in the direction that minimizes the error.</p>
<h2 id="The-Difference-in-the-Calculation-of-delta-k-for-Output-and-Hidden-Layers"><a href="#The-Difference-in-the-Calculation-of-delta-k-for-Output-and-Hidden-Layers" class="headerlink" title="The Difference in the Calculation of $\delta_k$ for Output and Hidden Layers"></a>The Difference in the Calculation of $\delta_k$ for Output and Hidden Layers</h2><p>The calculation of the error signal $\delta_k$ is different in the <strong>output layer</strong> and the <strong>hidden layer</strong> because:</p>
<ul>
<li><strong>Output layer</strong> error is directly related to the target error, and we can compute the gradient directly.</li>
<li><strong>Hidden layer</strong> error is not directly related to the target, so we need to <strong>propagate the error backwards</strong> from downstream layers (closer to the output layer).</li>
</ul>
<h3 id="Output-Layer’s-delta-k-Direct-Calculation-from-Error"><a href="#Output-Layer’s-delta-k-Direct-Calculation-from-Error" class="headerlink" title="Output Layer’s $\delta_k$: Direct Calculation from Error"></a>Output Layer’s $\delta_k$: Direct Calculation from Error</h3><p>In the <strong>output layer</strong>, the error can be directly calculated because the output neurons compare their output values $o_k$ directly with the target values $y_k$. Thus, the error signal $\delta_k$ is <strong>calculated directly based on the loss function</strong>.</p>
<p>For the <strong>Mean Squared Error (MSE)</strong> loss function:</p>
<p>$$<br>E &#x3D; \frac{1}{2} \sum_k (y_k - o_k)^2<br>$$</p>
<p>We take the partial derivative with respect to $net_k$:</p>
<p>$$<br>\delta_k &#x3D; \frac{\partial E}{\partial net_k} &#x3D; \frac{\partial E}{\partial o_k} \cdot \frac{\partial o_k}{\partial net_k}<br>$$</p>
<p>Where:</p>
<ul>
<li>$\frac{\partial E}{\partial o_k} &#x3D; -(y_k - o_k)$ (the error term),</li>
<li>$\frac{\partial o_k}{\partial net_k}$ depends on the activation function (e.g., Sigmoid: $o_k(1 - o_k)$).</li>
</ul>
<p>Thus, for the <strong>Sigmoid activation function</strong>:</p>
<p>$$<br>\delta_k &#x3D; -(y_k - o_k) \cdot o_k (1 - o_k)<br>$$</p>
<p>This calculation is <strong>specific to the output layer</strong> because the error term $y_k - o_k$ is directly available.</p>
<h3 id="Hidden-Layer’s-delta-h-Backpropagating-Error-from-Downstream"><a href="#Hidden-Layer’s-delta-h-Backpropagating-Error-from-Downstream" class="headerlink" title="Hidden Layer’s $\delta_h$: Backpropagating Error from Downstream"></a>Hidden Layer’s $\delta_h$: Backpropagating Error from Downstream</h3><p>In the <strong>hidden layer</strong>, the error cannot be directly calculated because the hidden neurons do not directly compare their outputs with target values. So, how do we know how much a hidden neuron contributes to the final error?</p>
<p><strong>The answer is: The error signal propagates backward from downstream layers!</strong></p>
<h4 id="What-are-downstream-layers"><a href="#What-are-downstream-layers" class="headerlink" title="What are downstream layers?"></a>What are downstream layers?</h4><ul>
<li><strong>Neural networks perform forward propagation</strong> for computing outputs, but the error is propagated <strong>backward</strong>.</li>
<li><strong>Hidden neurons influence multiple output neurons</strong>, so their error needs to be propagated back from those output neurons.</li>
<li>“Downstream” refers to layers closer to the <strong>output layer</strong>, and “upstream” refers to layers closer to the <strong>input layer</strong>.</li>
</ul>
<h4 id="Calculating-the-Hidden-Layer’s-Error-Signal-delta-h"><a href="#Calculating-the-Hidden-Layer’s-Error-Signal-delta-h" class="headerlink" title="Calculating the Hidden Layer’s Error Signal $\delta_h$"></a>Calculating the Hidden Layer’s Error Signal $\delta_h$</h4><p>For a hidden layer neuron $h$, there is no direct error, so its gradient comes from <strong>downstream layers</strong> (the output layer or deeper hidden layers).</p>
<p>Using <strong>the Chain Rule</strong>, we calculate:</p>
<p>$$<br>\delta_h &#x3D; \sum_k \left( \delta_k \cdot \omega_{kh} \right) \cdot o_h (1 - o_h)<br>$$</p>
<p>Where:</p>
<ul>
<li>$\delta_k$ is the downstream (output layer) error signal,</li>
<li>$\omega_{kh}$ is the weight from the hidden layer neuron $h$ to the output layer neuron $k$,</li>
<li>$o_h(1 - o_h)$ is the derivative of the activation function for the hidden layer neuron.</li>
<li>$\sum_k (\delta_k \cdot \omega_{kh})$: If the hidden layer neuron $h$ is connected to multiple output neurons $k$, its error is the <strong>weighted sum of all these error signals</strong>.</li>
</ul>
<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><p>Backpropagation is the core algorithm behind training <strong>multi-layer neural networks</strong>. It efficiently computes the <strong>gradient of the loss function</strong> with respect to the network’s weights, enabling the network to <strong>learn</strong> from data through gradient descent.</p>
<h3 id="Backpropagation-Algorithm"><a href="#Backpropagation-Algorithm" class="headerlink" title="Backpropagation Algorithm"></a>Backpropagation Algorithm</h3><p><strong>Step 1: Initialize the network</strong></p>
<ul>
<li>Create a <strong>feed-forward network</strong> with:<ul>
<li>$n_{in}$ input neurons</li>
<li>$n_h$ hidden neurons</li>
<li>$n_{out}$ output neurons</li>
</ul>
</li>
<li>Assign <strong>random small weights</strong> (e.g., between $-0.05$ and $0.05$) to break symmetry.</li>
</ul>
<p><strong>Step 2: Forward Propagation</strong><br>For each training example $\mathbf{x}$:</p>
<ol>
<li>Compute the weighted sum of inputs for each neuron.</li>
<li>Apply an <strong>activation function</strong> (e.g., Sigmoid) to get the output.</li>
</ol>
<p><strong>Step 3: Compute Errors</strong></p>
<ol>
<li><p>Compute the <strong>error at the output layer</strong>:<br>$$<br>\delta_j &#x3D; \sigma_j (1 - \sigma_j) (t_j - out_j)<br>$$<br>where:</p>
<ul>
<li>$\sigma_j$ is the output of the neuron</li>
<li>$t_j$ is the target value</li>
<li>$out_j$ is the actual output</li>
</ul>
</li>
<li><p>Compute the <strong>error at the hidden layers</strong> by propagating errors backward:<br> $$<br> \delta_j &#x3D; \sigma_j (1 - \sigma_j) \sum_{k \in \text{downstream}} w_{kj} \delta_k<br> $$</p>
</li>
</ol>
<p><strong>Step 4: Update Weights</strong><br>Each weight $w_{ij}$ is updated using gradient descent:<br>$$<br>w_{ij} \leftarrow w_{ij} + \eta \delta_j x_i<br>$$<br>where $\eta$ is the <strong>learning rate</strong>.</p>
<p><img src="/blog/./img/ML7-2.png" alt="https://www.science.org/doi/10.1126/sciadv.ado8999"></p>
<h3 id="Numerical-Example-of-Backpropagation"><a href="#Numerical-Example-of-Backpropagation" class="headerlink" title="Numerical Example of Backpropagation"></a>Numerical Example of Backpropagation</h3><p>Let’s go through an example using a <strong>small network</strong>.</p>
<h4 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a><strong>Network Structure</strong></h4><ul>
<li><strong>Input layer:</strong> 2 neurons ($x_1, x_2$)</li>
<li><strong>Hidden layer:</strong> 2 neurons ($h_1, h_2$)</li>
<li><strong>Output layer:</strong> 1 neuron ($o$)</li>
<li>Activation function: <strong>Sigmoid</strong></li>
</ul>
<h4 id="Given-Initial-Values"><a href="#Given-Initial-Values" class="headerlink" title="Given Initial Values"></a><strong>Given Initial Values</strong></h4><ul>
<li><strong>Inputs:</strong> $x_1 &#x3D; 0.05, x_2 &#x3D; 0.10$</li>
<li><strong>Targets:</strong> $t &#x3D; 0.01$</li>
<li><strong>Weights:</strong><ul>
<li>Input to Hidden:<ul>
<li>$w_{1,1} &#x3D; 0.15$, $w_{1,2} &#x3D; 0.20$</li>
<li>$w_{2,1} &#x3D; 0.25$, $w_{2,2} &#x3D; 0.30$</li>
</ul>
</li>
<li>Hidden to Output:<ul>
<li>$w_{h1,o} &#x3D; 0.40$, $w_{h2,o} &#x3D; 0.45$</li>
</ul>
</li>
</ul>
</li>
<li><strong>Biases:</strong> Assume <strong>0</strong> for simplicity.</li>
<li><strong>Learning Rate:</strong> $\eta &#x3D; 0.5$</li>
</ul>
<h4 id="Step-1-Forward-Pass"><a href="#Step-1-Forward-Pass" class="headerlink" title="Step 1: Forward Pass"></a><strong>Step 1: Forward Pass</strong></h4><p>Compute the net input and output of the hidden neurons:</p>
<p>$$<br>net_{h1} &#x3D; w_{1,1}x_1 + w_{2,1}x_2 &#x3D; (0.15)(0.05) + (0.25)(0.10) &#x3D; 0.0125<br>$$</p>
<p>$$<br>\sigma_{h1} &#x3D; \frac{1}{1 + e^{-net_{h1}}} &#x3D; \frac{1}{1 + e^{-0.0125}} \approx 0.5031<br>$$</p>
<p>Similarly, for $h_2$:</p>
<p>$$<br>net_{h2} &#x3D; (0.20)(0.05) + (0.30)(0.10) &#x3D; 0.0175<br>$$</p>
<p>$$<br>\sigma_{h2} &#x3D; \frac{1}{1 + e^{-0.0175}} \approx 0.5044<br>$$</p>
<p>For the output neuron:</p>
<p>$$<br>net_o &#x3D; w_{h1,o} \sigma_{h1} + w_{h2,o} \sigma_{h2} &#x3D; (0.40)(0.5031) + (0.45)(0.5044) &#x3D; 0.4009<br>$$</p>
<p>$$<br>out_o &#x3D; \frac{1}{1 + e^{-net_o}} &#x3D; \frac{1}{1 + e^{-0.4009}} \approx 0.5988<br>$$</p>
<h4 id="Step-2-Compute-Error"><a href="#Step-2-Compute-Error" class="headerlink" title="Step 2: Compute Error"></a><strong>Step 2: Compute Error</strong></h4><p>$$<br>E &#x3D; \frac{1}{2} (t - out_o)^2 &#x3D; \frac{1}{2} (0.01 - 0.5988)^2 &#x3D; 0.174<br>$$</p>
<h4 id="Step-3-Backpropagation"><a href="#Step-3-Backpropagation" class="headerlink" title="Step 3: Backpropagation"></a><strong>Step 3: Backpropagation</strong></h4><p><strong>Error at Output Layer</strong><br>$$<br>\delta_o &#x3D; out_o(1 - out_o)(t - out_o)<br>$$<br>$$<br>\delta_o &#x3D; (0.5988)(1 - 0.5988)(0.01 - 0.5988) &#x3D; -0.1432<br>$$</p>
<p><strong>Error at Hidden Layer</strong><br>For $h_1$:</p>
<p>$$<br>\delta_{h1} &#x3D; \sigma_{h1} (1 - \sigma_{h1}) (w_{h1,o} \delta_o)<br>$$<br>$$<br>\delta_{h1} &#x3D; (0.5031)(1 - 0.5031)(0.40)(-0.1432) &#x3D; -0.0143<br>$$</p>
<p>Similarly, for $h_2$:</p>
<p>$$<br>\delta_{h2} &#x3D; (0.5044)(1 - 0.5044)(0.45)(-0.1432) &#x3D; -0.0161<br>$$</p>
<h4 id="Step-4-Weight-Updates"><a href="#Step-4-Weight-Updates" class="headerlink" title="Step 4: Weight Updates"></a><strong>Step 4: Weight Updates</strong></h4><p>$$<br>w_{h1,o} \leftarrow w_{h1,o} + \eta \delta_o \sigma_{h1}<br>$$<br>$$<br>&#x3D; 0.40 + (0.5)(-0.1432)(0.5031) &#x3D; 0.364<br>$$</p>
<p>Similarly, other weights are updated.</p>
<h3 id="The-Exploding-and-Vanishing-Gradient-Problem"><a href="#The-Exploding-and-Vanishing-Gradient-Problem" class="headerlink" title="The Exploding and Vanishing Gradient Problem"></a>The Exploding and Vanishing Gradient Problem</h3><p>Backpropagation works well for shallow networks, but <strong>deep networks</strong> suffer from two major problems:</p>
<p><strong>Vanishing Gradient</strong></p>
<ul>
<li>In deep networks, gradients become <strong>exponentially smaller</strong> as they propagate backward.</li>
<li>Since weights are updated using these gradients, <strong>early layers stop learning</strong>.</li>
<li>Happens when using <strong>Sigmoid or Tanh</strong> activations because their derivatives are between <strong>0 and 1</strong>.</li>
</ul>
<p><strong>Exploding Gradient</strong></p>
<ul>
<li>If weights are large, gradients <strong>explode</strong>, leading to <strong>unstable training</strong>.</li>
<li><strong>Weight updates become extremely large</strong>, causing the model to diverge.</li>
</ul>
<p><strong>Solutions</strong></p>
<ol>
<li><strong>ReLU Activation Function</strong>: Unlike Sigmoid, ReLU has a derivative of <strong>1</strong> for positive inputs, preventing vanishing gradients.</li>
<li><strong>Batch Normalization</strong>: Normalizes activations, keeping them in a stable range.</li>
<li><strong>Gradient Clipping</strong>: Limits the gradient value to prevent explosion.</li>
<li><strong>Xavier&#x2F;He Initialization</strong>: Properly initializes weights to keep gradients stable.</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>About Machine Learning ( Part 7: Artificial Neural Network )</p><p><a href="https://kongchenglc.github.io/blog/2025/02/06/Machine-Learning-7/">https://kongchenglc.github.io/blog/2025/02/06/Machine-Learning-7/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Lich</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2025-02-06</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2025-02-16</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Machine-Learning/">Machine Learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Artificial-Neural-Network-ANN/">Artificial Neural Network (ANN)</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Bayes%E2%80%99-Theorem/">Bayes’ Theorem</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Delta-Rule/">Delta Rule</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Backpropagation/">Backpropagation</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2025/02/09/Transformer-1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Transformer ( Part 1: Word Embedding )</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2025/02/02/Machine-Learning-6/"><span class="level-item">About Machine Learning ( Part 6: KNN vs. K-means )</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><script src="https://utteranc.es/client.js" repo="kongchenglc/blog" issue-term="pathname" label="comment" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/blog/img/profile-pic.jpg" alt="Lich"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lich</p><p class="is-size-6 is-block">Software Engineer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Canada</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">20</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">29</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/kongchenglc" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Defunct Chinese Blog" href="https://kongchenglc.github.io/blog/"><i class="fa-solid fa-link"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Bayes’-theorem"><span class="level-left"><span class="level-item">1</span><span class="level-item">Bayes’ theorem</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Bayes-Network-Bayesian-Network-BN"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Bayes Network (Bayesian Network, BN)</span></span></a></li><li><a class="level is-mobile" href="#Bayesian-Inference-in-BN"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Bayesian Inference in BN</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Artificial-Neural-Network-ANN"><span class="level-left"><span class="level-item">2</span><span class="level-item">Artificial Neural Network (ANN)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#The-Perceptron"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">The Perceptron</span></span></a></li><li><a class="level is-mobile" href="#Learning-in-Perceptrons"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Learning in Perceptrons</span></span></a></li><li><a class="level is-mobile" href="#Delta-Rule"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Delta Rule</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Derivation-of-the-Delta-Rule"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">Derivation of the Delta Rule</span></span></a></li></ul></li><li><a class="level is-mobile" href="#The-Difference-in-the-Calculation-of-delta-k-for-Output-and-Hidden-Layers"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">The Difference in the Calculation of $\delta_k$ for Output and Hidden Layers</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Output-Layer’s-delta-k-Direct-Calculation-from-Error"><span class="level-left"><span class="level-item">2.4.1</span><span class="level-item">Output Layer’s $\delta_k$: Direct Calculation from Error</span></span></a></li><li><a class="level is-mobile" href="#Hidden-Layer’s-delta-h-Backpropagating-Error-from-Downstream"><span class="level-left"><span class="level-item">2.4.2</span><span class="level-item">Hidden Layer’s $\delta_h$: Backpropagating Error from Downstream</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Backpropagation"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">Backpropagation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Backpropagation-Algorithm"><span class="level-left"><span class="level-item">2.5.1</span><span class="level-item">Backpropagation Algorithm</span></span></a></li><li><a class="level is-mobile" href="#Numerical-Example-of-Backpropagation"><span class="level-left"><span class="level-item">2.5.2</span><span class="level-item">Numerical Example of Backpropagation</span></span></a></li><li><a class="level is-mobile" href="#The-Exploding-and-Vanishing-Gradient-Problem"><span class="level-left"><span class="level-item">2.5.3</span><span class="level-item">The Exploding and Vanishing Gradient Problem</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/blog/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/">Lich&#039;s Blog</a><p class="is-size-7"><span>&copy; 2025 Lich</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2024</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/kongchenglc"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/blog/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/blog/js/pjax.js"></script><!--!--><script data-pjax src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><!-- hexo injector body_end start --><script src="/blog/js/custom-css.js"></script><!-- hexo injector body_end end --></body></html>