{"posts":[{"title":"About Project Management ( Part 1 )","text":"ProjectWhat Is a Project?Project Defined (according to PMI): A temporary endeavor undertaken to create a unique product, service, or result. Major Characteristics of a Project: Has an established objective. Has a defined lifespan with a beginning and an end. Involves several departments and professionals. Involves doing something never done before. Has specific time, cost, and performancerequirements. Program versus ProjectProgram Defined: A group of related projects designed to accomplish acommon goal over an extended period of time. Program Management Defined: A process of managing a group of ongoing, interdependent, related projects in a coordinated way to achieve strategic objectives. Examples: Project: completion of a required course in projectmanagement. Program: completion of all courses required for a businessmajor. StrategyTwo main reasons project managers need to understand their organization’s mission and strategy: So they can make appropriate decisions and adjustments. How a project manager would respond to a suggestion to modify the design of a product or to delays may vary depending upon strategic concerns So they can be effective project advocates. They have to be able to: Demonstrate to senior management how their project contributes to the firm’s mission in order to garner the continued support of management. Explain to stakeholders why certain project objectives and priorities are critical in order to secure buy-in. Explain why the project is important to motivate and empower the project team Organization and ScopeThree different project management structures are: Functional organization Dedicated project teams Matrix structure Weak matrix Balanced matrix Strong matrix Matrix StructuresWeak matrix This form is very similar to a functional approach with the exception that there is a formally designed project manager responsible for coordinating project activities. Functional managers are responsible for managing their segment of the project. The project manager acts as a staff assistant who draws the schedules and checklists, collects information on the status of the work, and facilitates project completion. Balanced matrix The project manager is responsible for defining what needs to be accomplished. The project manager establishes the overall plan for completing the project, integrates the contribution of the different disciplines, set schedules, and monitors progress. The functional managers are concerned with how it will be accomplished. The functional managers are responsible for assigning personnel and executing their segment of the project according to the standards and schedules set by the project manager. Strong matrix The project manager controls most aspects of the project, including scope trade-offs and assignment of functional personnel. The project manager controls when and what specialists do and has final say on major project decisions. The functional managers have title over their people and are consulted on a need basis. The functional managers serve as subcontractors for the project. Project Management Offices(PMOs) Is a centralized unit within an organization or a department that oversees and supports the execution of projects. Plays a critical role in helping matrix systems mature into more effective project delivery platforms. Can be characterized in different kinds: Weather station—tracks and monitors project performance. Control tower—improves project execution. Resource pool—provides the organization with a cadre of trained project managers and professionals. Command and control center—has direct authority over the project. Organizational Culture Is a system of shared norms, beliefs, values, and assumptions that blinds people together, thereby creating shared meanings. Reflects the “personality” of the organization. Performs several important functions in organizations. Provides a sense of identity for its members Helps legitimize the management system Clarifies and reinforces standards of behavior Helps create social order","link":"/blog/2024/10/24/About-Project-Management-Part-1/"},{"title":"About Project Management ( Part 2 )","text":"Cost and Time EstimationIs a trade-off, balancing the benefits of better accuracy against the costs of secured increased accuracy. Types of EstimatesTop-down (macro) estimates Analogy Group consensus Mathematical relationships Bottom-up (micro) estimates based on estimates of elements found in the work breakdown structure Why Estimating Time and Cost Is Important To support good decisions. To schedule work. To determine how long the project should take and its cost. To determine whether the project is worth doing. To develop cash flow needs. To determine how well the project is progressing. different aspects of estimating Range Accuracy Precision Confidence Factors Influencing the Quality of Estimates Planning Horizon: cost estimates for a party you are organizing this weekend should be much more accurate than the estimates for a party that will take place in six months. Project Complexity People: How familiar are they with the task they are estimating? Project Structure and Organization: In a matrix environment may take longer, since attention is divided and coordination demands. Padding Estimates: Most of us are inclined to add a little padding to reduce the risk of being late Organizational Culture Others: Equipment downtime, National holidays, vacations, etc. Estimating Guidelines for Times, Costs, and Resources Responsibility: estimates should be made by the person(s) most familiar with the task. The use of several people to estimate: leads to consensus and eliminate extreme estimate errors Normal conditions: based on certain assumptions. Estimates should be based on normal conditions, efficient methods, and a normal level of resources Time units: All task time estimates need consistent time units. Eg: calendar days, workdays, workweeks, person days, single shift, hours, minutes, etc. Independence: treat each task as independent of other tasks. To avoid some rough “guesstimate” of the total time for the whole path Contingencies: Work package estimates should not include allowances for contingencies. Risk assessment: to avoid surprises to stakeholders. Simply identifying the degree of risk Top-Down versus Bottom-Up EstimatingTop-Down Estimates Are usually derived from someone who uses experience and/or information to determine the project duration and total cost. Are sometimes made by top managers who have very little knowledge of the component activities used to complete the project. Bottom-Up Estimates Can take place after the project has been defined in detail. Can serve as a check on cost elements in the WBS by rolling up the work packages and associated cost accounts to major deliverables. Provide the customer with an opportunity to see various trade-offs in different project scenarios, such as time, cost, resources, and technical performance. The Preferred Approach in Defining the Project Make rough top-down estimates Develop the WBS/OBS Make bottom-up estimates Develop schedules and budgets Reconcile differences between top-down and bottom-up estimates Methods for Estimating Project Times and CostsTop-Down Approaches Consensus Method: use experience of senior and/or middle managers to estimate Ratio Method: use number of square feet to estimate the cost and time to build a house Apportion Method: an extension to the ratio method. Foundation might represent 3% of the total loan, framing 25%, plumbing and heating 15%, etc. Function Point Methods for Software and System Projects: using a regression formula derived from data of past projects Learning Curves: The time to perform a task improves with repetition Bottom-Up Approaches Template Method: If the project is similar to past projects. Parametric Procedures Applied to Specific Tasks: a cost of $7 per square yard of wallpaper. Range Estimating: Require three time estimates—low, average, and high (probability distributions). Get risk level from (high - low) A Hybrid: Phase Estimating Level of DetailA frequent rule of thumb used by practicing project managers says that a task duration should not exceed 5 workdays or at the most 10 workdays, if workdays are the time units used for the project. Types of Costs Direct costs Labor Materials Equipment Other Direct project overhead costs salary of the project manager temporary rental space for the project team supplies specialized machinery General and administrative (G&amp;A) overhead costs Advertising accounting salary of senior management above the project level Refining EstimatesReasons for adjusting estimates Interaction costs are hidden in estimates: each task estimate is supposed to be done independently. However, tasks are rarely completed in a vacuum. Normal conditions do not apply: availability of resources. Resource shortages, whether in the form of people, equipment, or materials. Things go wrong on projects: extreme weather conditions occur, accidents happen Project scope and plans change. People are overly optimistic. People engage in strategic misrepresentation: promoters underestimate the costs of projects and overestimate project benefits in order to win approval. Creating a Database for EstimatingCollect and archive data on past project estimates and actuals Mega Projects: A Special CaseA “white elephant” suggests a valuable, but burdensome, possession, which its owner cannot easily dispose of and whose cost (particularly upkeep) is out of proportion with its usefulness. The Reference Class Forecasting (RCF)Three Major Steps: Select a reference class of projects similar to your potential project. Collect and arrange outcome data as a distribution. Create a distribution of cost overruns as a percentage of the original project estimate (low to high). Use the distribution data to arrive at a realistic forecast. Compare the original cost estimate for the project with the reference class projects Benefits: Outside empirical data mitigates human bias. Politics, strategic, and promoter forces have difficulty ignoring outside RCF information. RCF serves as a reality check for funding large projects. RCF helps executives avoid unsound optimism. RCF leads to improved accountability. RCF provides a basis for project contingency funds. Developing a Project ScheduleDeveloping the Project Network Is a graphic flow chart depicting the project activities that must be completed, the logical sequences, the interdependencies of the activities to be completed, and the times for the activities to start and finish along with the longest path(s) through the network—the critical path. Provides the basis for scheduling labor and equipment. Enhances communication among project stakeholders. Provides an estimate of project duration. Provides the basis for budgeting the cash flow. Identifies which activities are “critical” and should not be delayed. Highlights which activities to consider for compressing the project duration. Helps managers get and stay on the project plan. From Work Package to NetworkProject networks are developed from the WBS. The project network is a visual flow diagram of the sequence, interrelationships, and dependencies of all the activities that must be accomplished to complete the project. Constructing a Project NetworkTerminology Activity: an element of the project that requires time but may not require resources Parallel activities: activities that can take place at the same time, if desired. Burst activity: an activity that has more than one activity immediately following it (more that one dependency arrow flowing from it) Merge activity: an activity that has more than one activity immediately preceding it (more than one dependency arrow flowing to it) Path: a sequence of connected, dependent activities Critical path: the path with the longest duration through the network Two approaches Activity-on-Node (AON) uses a node to depict an activity. Activity-on-Arrow (AOA) uses an arrow to depict an activity. Basic Rules to Follow in Developing Project Networks Networks flow typically from left to right. An activity cannot begin until all preceding connected activities have been completed. Arrows on networks indicate precedent and flow and can cross over each other. Each activity should have a unique identification number. An activity identification number must be greater than that of any activities that precede it. Looping is not allowed. Conditional statements are not allowed. Where there are multiple starts, a common start node can be used to indicate a clear project beginning on the network. Similarly, a single project end node can be used to indicate a clear ending. Activity-on-Node (AON) Fundamentals Which activities must be completed immediately before this activity? These activities are called predecessor activities. Which activities must immediately follow this activity? These activities are called successor activities. Which activities can occur while this activity is taking place? This is known as a concurrent or parallel relationship. Network Computation ProcessForward Pass—Earliest Times How soon can the activity start? (early start—ES) How soon can the activity finish? (early finish—EF) How soon can the project finish? (expected time—TE) Backward Pass—Latest Times How late can the activity start? (late start—LS) How late can the activity finish? (late finish—LF) Which activities represent the critical path? (critical path—CP) How long can the activity be delayed? (slack or float—SL) Forward Pass Computation Add activity times along each path in the network (ES + Duration = EF). Carry the early finish (EF) to the next activity where it becomes its early start (ES) unless… The next succeeding activity is a merge activity, in which case the largest early finish (EF) number of all its immediate predecessor activities is selected. Backward Pass Computation Subtract activity times along each path starting with the project end activity (LF – Duration = LS). Carry the late start (LS) to the next preceding activity where it becomes its late finish (LF) unless… The next succeeding activity is a burst activity, in which case the smallest late start (LS) number of all its immediate successor activities is selected. Determining Slack (or Float) Total Slack Tells us the amount of time an activity can be delayed and not delayed the project. Is how long an activity can exceed its early finish date without affecting the project end date or an imposed completion date. Is simply the difference between the LS and ES (LS – ES = SL) or between LF and EF (LF – EF = SL) Free Slack (Float) Is the amount of time an activity can be delayed without delaying any immediately following (successor) activity. Is how long an activity can exceed its early finish date without affecting the early start dates of any successor(s). Allows flexibility in scheduling scarce resources. Occurs only activity at the end of a chain of activities, where you have a merge activity The Critical Path Is the network path(s) that has (have) the least slack in common. Is the longest path through the activity network. Is the shortest expected time in which the entire project can be completed. Is important because it impacts completion time. Is where you put best people on. Is where you pay extra attention when doing risk assessment. Is where you don’t look when other managers are asking to ‘borrow’ people or equipment. Is where you look when you don’t have time to monitor all activities Sensitivity Network sensitivity is the likelihood the original critical path(s) will change once the project is initiated. A network schedule that has only one critical path and noncritical activities that enjoy significant slack would be labeled ‘insensitive’. Practical Considerations Network Logic Errors: no Looping, no conditional statements. Activity Numbering: biger and biger, no repeat Use of Computers to Develop Networks (and Gantt Chart) Calendar Dates Multiple Starts and Multiple Projects: using a common start and end node helps to identify the total planning period of all projects Extended Network Techniques to Come Closer to RealityLadderingActivities are broken into segments so the following activity can begin sooner and not delay the work. Use of Lags to Reduce Schedule Detail and Project DurationFinish-to-Start Relationship Start-to-Start Relationship Hammock Activity Spans over a segment of a project. Has a duration that is determined after the network plan is drawn. Is very useful in assigning and controlling indirect project costs. Is used to aggregate sections of the project to facilitate getting the right level of detail for specific sections of a project.","link":"/blog/2024/10/24/About-Project-Management-Part-2/"},{"title":"About Project Management ( Part 3 )","text":"Managing RiskRisk Management ProcessRisk Defined: An uncertain event or condition that if it occurs, has a positive or negative effect on project objectives. No amount of planning can overcome or control risk. Risk Management Defined: An attempt to recognize and manage potential and unforeseen trouble spots that may occur when the project is implemented. What can go wrong (risk event) How to minimize the risk event’s impact (consequences) What can be done before an event occurs (anticipation) What to do when an event occurs (contingency plans) Benefits of Risk Management A proactive rather than reactive approach Reduces surprises and negative consequences Prepares the project manager to take appropriate action Provides better control over the future Improves chances of reaching project objectives on time, within budget, and of meeting required performance. Risk Identification Generate a list of all the possible risks that could affect the project through brainstorming and other problem identifying techniques. Focus on the events that could produce consequences, not on project objectives. Use risk breakdown structure (RBS) in conjunction with work breakdown structure (WBS) to identify and analyze risks. Identify the macro risks first then specific areas can be checked. Use risk profile (a list of questions) to address traditional areas of uncertainty on a project. Risk Assessment Scenario analysis assesses the significance of each risk event in terms of probability and impact. Risk assessment form evaluates the severity, probability of risk events and its detection difficulty. Risk severity matrix prioritizes which risks to address. Failure Mode and Effects Analysis (FMEA) extends the risk severity matrix by including ease of detection in the equation: Risk Value = Impact x Probability x Detection Probability analysis uses statistical techniques in assessing project risk. Decision trees, net present value (NPV), program evaluation and review technique (PERT), PERT simulation Risk Response Development Mitigating Risk Reducing the likelihood that the event will occur Reducing the impact that the adverse event would have on the project Avoiding Risk Changing the project plan to eliminate the risk or condition Transferring Risk Passing risk to another party Examples: Fixed-price contracts, insurance, Build-Own-Operate-Transfer (BOOT) provisions Escalating Risk Notifying the appropriate people within the organization of the threat Retaining Risk Making a conscious decision to accept the risk of an event occurring Contingency Planning Contingency Plan Defined Is an alternative plan that will be used if a possible foreseen risk event becomes a reality. Is a plan of action that will reduce or mitigate the negative impact of the risk event. Is not a part of the initial implementation plan and only goes into effect after the risk is recognized. Risks of the absence of a contingency plan Cause a manager to delay or postpone the decision to implement a remedy Lead to panic and acceptance of the first remedy suggested Make the decision making under pressure which can be dangerous and costly Risk and Contingency Planning Technical Risks Backup strategies if chosen technology fails Assess whether technical uncertainties can be resolved Schedule Risks Expedite or “crash” the project to get it back on track Schedule activities in parallel or use start-to-start lag relationships Use the best people for high-risk tasks Cost Risks Review price to avoid the trap of using one lump sum to cover price risks Funding Risks Evaluate the risk of reductions in funding—a cut in the project Opportunity ManagementAn opportunity is an event that can have positive impact on project objectives. Exploit Seek to eliminate the uncertainty associated with an opportunity to ensure that it definitely happens Share Allocate some or all of the ownership of an opportunity to another party who is best able to capture the opportunity for the benefit of the project Enhance Take action to increase the probability and/or the positive impact of an opportunity Escalate Notify the appropriate people within the organization of the opportunity Accept Be willing to take advantage of the opportunity if it occurs, but not taking action to pursue it Contingency Funding and Time Buffers Contingency Funds Contingency reserves—cover identified risks Management reserves—cover unidentified risks Time Buffers: Are amounts of time used to cushion against potential delays in the project Add to activities with severe risks Add to merge activities that are prone to delays Add to noncritical activities to reduce the likelihood that they will create another critical path Add to activities that require scare resources Risk Response Control Risk Register: descriptions, category, probability of occurring, impact, responses, contingency plans, owners, and current status Risk Control Executing the risk response strategy Monitoring triggering events Initiating contingency plans Watching for new risks Establishing a Change Management System Monitoring, tracking, and reporting risk Fostering an open organization environment Repeating risk identification/assessment exercises Assigning and documenting responsibility for managing risk Change Control Management Sources of Change Project scope changes Implementation of contingency plans Improvement changes Change Management Systems Identify proposed changes. List expected effects of proposed change(s) on schedule and budget. Review, evaluate, and approve or disapprove changes formally. Negotiate and resolve conflicts of change, conditions, and cost. Communicate changes to the parties affected. Assign responsibility for implementing change. Adjust the master schedule and budget. Track all changes that are to be implemented Benefits of Change Control Systems Inconsequential changes are discouraged by the formal process. Costs of changes are maintained in a log. Integrity of the WBS and performance measures is maintained. Allocation and use of contingency and management reserves are tracked. Responsibility for implementation is clarified. Effect of changes is visible to all parties involved. Implementation of change is monitored. Scope changes will be quickly reflected in baseline and performance measures Scheduling Resources and CostsOverview of the Resource Scheduling ProblemResources and Priorities Project network times are not a schedule until resources have been assigned. There are always more project proposals than there are available resources. The project priority team will add a new project only if resources are available. Cost estimates are not a budget until they have been time-phased. Once resource assignments have been finalized, you are able to develop a baseline budget schedule for the project. The Resource Scheduling Problem Resource Smoothing: delaying non-critical activities (using slack). increase resource utilization. Resource-Constrained Scheduling: some activities must be delayed Types of Resource ConstraintsTechnical or Logical Constraints: Are related to the networked sequence in which project activities must occur. Resource Constraints: Occur when the absence, shortage, or unique interrelationship and interaction characteristics of resources require a particular sequencing of project activities. Note that the resource dependency takes priority over the technological dependency but does not violate the technological dependency Types of Resources Constraints: People Materials Equipment Classification of a Scheduling Problem Time-Constrained Project: resources can be added Resource-Constrained Project: If the resources are inadequate, it will be acceptable to delay the project. Resource Allocation Methods Limiting Assumptions Splitting activities will not be allowed. Level of resources used for an activity cannot be changed. Risk Assumptions Activities with the most slack pose the least risk. Reduction of flexibility does not increase risk. The nature of an activity (easy, complex) doesn’t increase risk. Time-Constrained Projects Must be completed by an imposed date. Focus on resource utilization. Require use of resource smoothing techniques that balance demand for a resource Smoothing Resource Techniques: Delay noncritical activities by using positive slack to reduce peak demand and fill in the valleys for the resources without delaying the entire project Goals Reduce the peak of demand for the resource Reduce the number of resources over the life of the project Minimize the fluctuation in resource demand Downside Loss of flexibility that occurs from reducing slack Creates more critical activities and/or near-critical activities because of slack reduction Resource-Constrained Projectspriority rules: Minimum slack: will not inflence others Smallest (least) duration: release resource early Lowest activity identification number: logically parallel method: when the resources needed exceed the resources available, retains activities first by the priority rules. The Impacts of Resource-Constrained Scheduling: Reduces slack; reduce flexibility Increases the number of critical and near-critical activities Increases scheduling complexity because resource constraints are added to technical constraints May make the traditional critical path no longer meaningful Can break the sequence and leave the network with a set of disjointed critical activities May cause parallel activities to become sequential Can change activities from critical to noncritical Computer Demonstration of ResourceConstrained SchedulingMS project Splitting ActivitiesSplitting Tasks Is a scheduling technique used to get a better project schedule and/or to increase resource utilization. Involves interrupting the work and sending the resource to another activity for a period of time and then having the resource resume work on the original activity. Can be useful if the work involved does not include large start-up or shut-down costs. Is considered a major reason why projects fail to meet schedule. Benefits of Scheduling Resources Leaves time for considering reasonable alternatives Cost-time tradeoffs Changes in priorities Provides the information needed to prepare time-phased work package budgets with dates To gauge the impact of unforeseen events To assess how much flexibility over certain resources Assigning Project Work Reasons why we should not always assign the best people the most difficult tasks Best people: resent to the fact that they are always given the toughest assignments Less experienced participants: resent to the fact that they are never given the opportunity to expand their skill/knowledge base Factors to be considered in deciding who should work together Minimize unnecessary tension; complement each other Experience: veterans team up with new hires Future needs: have people work together early on so that they can become familiar with each other Multiproject Resource SchedulesProblems: Delays in one project create delays for other projects Inefficient resource utilization: Different schedules and requirements by multiple projects create the peaks and valleys in overall resource demands Resource bottlenecks: Shortages of critical resources required by multiple projects cause delays and schedule extensions. Approach: Create project offices or departments to oversee the scheduling of resources across multiple projects Use a project priority queuing system—first come, first served for resources Treat individual projects as part of one big project and adapt the scheduling heuristics to this “mega project” Utilize project management software to prioritize resource allocation Outsource projects to reduce the number of projects managing internally Hire temporary workers to expedite certain activities that are falling behind schedule Contract project work during peak periods when there are insufficient internal resources to meet the demands of all project Using the Resource Schedule to Develop a Project Cost Baseline Why a Time-Phased Budget Baseline Is Needed To determine if the project is on, ahead, or behind schedule and over or under its budgeted costs To assess how much work has been accomplished for the allocated money spent—the project cost baseline (planned value, PV) Creating a Time-Phased Budget Assign each work package to one responsible person or department and deliverable Compare planned schedule and costs using an integrative system called earned value Generate cash flow statements and resource usage schedules Reducing Project DurationRationale for Reducing Project DurationCrash: shortening the duration of an activity or a project beyond when it normally can be done. Reasons for attempting to reduce the duration of a project are: Time-to-market pressures Unforeseen delays Incentive contracts (bonuses for early completion) Imposed deadlines and contract commitments Overhead costs Pressure to reassign resources to other projects Options for Accelerating Project CompletionResources Are Not Constrained Add resources Outsource project work Schedule overtime Establish a core project team Do it twice—fast and correctly Resources Are Constrained Improve project team efficiency Fast tracking Use critical-chain management Reduce project scope Compromise quality Project Cost-Duration GraphExplanation of Project Costs Project Indirect Costs Are costs that cannot be associated with any particular work package or activity ( overhead supervision, administration, consultants, and interest ). Are costs that vary directly with time. Project Direct Costs Are costs that assigned directly to a work package and activity ( labor, materials, equipment, subcontractors ). Represent normal costs (low-cost, efficient methods for a normal time). Constructing a Project Cost-Duration Graph Determining the Activities to ShortenWhich activities to shorten?Look for critical activities that can be shortened with the smallest increase in cost per unit of time. Assumptions: The cost-time relationship is linear. Normal time assumes low-cost, efficient methods to complete the activity. Crash time represents a limit—the greatest time reduction possible under realistic conditions. Slope represents cost per unit of time. All accelerations must occur within the normal and crash times. Cost-Duration Trade-off Example What If Cost, Not Time, Is the Issue?Commonly used options for cutting costs are: Reduce project scope Have owner take on more responsibility Outsource project activities or even the entire project Brainstorm cost savings options Being an Effective Project ManageManaging versus Leading a ProjectManaging—coping with complexity Formulate plans and objectives Monitor results Take corrective action Expedite activities Solve technical problems Serve as peacemaker Make tradeoffs among time, costs, and project scope Leading—coping with change Recognize the need to change to keep the project on track Initiate change Provide direction and motivation Innovate and adapt as necessary Integrate assigned resources Engaging Project StakeholdersStakeholders are people and organizations that are actively involved in the project or whose interests may be positively or negatively affected by the project. Project Management Maxims: You can’t do it all and get it all done. Projects usually involve a vast web of relationships. Hands-on work is not the same as leading. More pressure and more involvement can reduce your effectiveness as a leader. What’s important to you likely isn’t as important to someone else. Different groups have different stakes (responsibilities, agendas, and priorities) in the outcome of a project. Influence as ExchangeYou scratch my back, I’ll scratch yours Commonly Traded Organizational CurrenciesTask-related currencies Resources Lending or giving money, budget increases, personnel, etc. Assistance Helping with existing projects or undertaking unwanted tasks. Cooperation Giving task support, providing quicker response time, or aiding implementation. Information Providing organizational as well as technical knowledge. Position-related currencies Advancement Giving a task or assignment that can result in promotion. Recognition Acknowledging effort, accomplishments, or abilities. Visibility Providing a chance to be known by higher-ups or significant others in the organization. Network/contacts Providing opportunities for linking with others. Inspiration-related currencies Vision Being involved in a task that has larger significance for the unit, organization, customer, or society. Excellence Having a chance to do important things really well. Ethical correctness Doing what is “right” by a higher standard than efficiency. Relationship-related currencies Acceptance Providing closeness and friendship. Personal support Giving personal and emotional backing. Understanding Listening to others’ concerns and issues. Personal-related currencies Challenge/learning Sharing tasks that increase skills and abilities. Ownership/involvement Letting others have ownership and influence. Gratitude Expressing appreciation. Social Network BuildingMapping Stakeholder Dependencies Project team’s perspective Whose cooperation will we need? Whose agreement or approval will we need? Whose opposition would keep us from accomplishing the project? Stakeholder’s perspective What differences exist between the team and the people on whom the team depends? How do the stakeholders view the project? What is the current status of the relationship the team has with the stakeholders? What sources of influence does the team have relative to the stakeholders on whom the team depends? Management by Wandering Around (MBWA) Management by Wandering Around (MBWA) involves managers spending the majority of their time outside their offices in order to have face-to-face interactions with employees building cooperativerelationships. Relationships should be built before they are needed. Characteristics of Effective Project Managers Initiate contact with key stakeholders to keep abreast of developments Anticipate potential problems Provide encouragement Reinforce the objectives and vision of the project Intervene to resolve conflicts and prevent stalemates from occurring Managing Upward RelationsProject success is strongly affected by the degree to which a project has the support of top management. Top management must: Provide an appropriate budget Be responsive to unexpected needs Send a clear signal to others in the organization of the importance of the project and the need to cooperate Rescind unreasonable demand Provide additional resources Recognize the accomplishments of team members Ethics and Project ManagementEthical Dilemmas—situations where it is difficult to determine whether conduct is right or wrong Padding of cost and time estimations Exaggerating pay-offs of project proposals Falsely assuring customers that everything is on track Being pressured to alter status reports Falsifying cost accounts Compromising safety standards to accelerate progress Approving shoddy work Building Trust: The Key to Exercising Influence Trust Is an elusive concept. Is a function of character (personal motives) and competence (skills necessary to realize motives). Is sustained through frequent face-to-face contact. The core of highly effective people is a character ethic. Consistency — more predictable Openness — more receptive to others A sense of purpose — what is best for the organization and the project Qualities of an Effective Project Manager Summary Effective communication skills Systems thinking Personal integrity Proactivity High emotional intelligence (EQ) General business perspective Effective time management Optimism Contradictions of Project Management Innovate and maintain stability See the big picture while getting their hands dirty Encourage individuals but stress the team Be hands-off/hands-on Be flexible but firm Manage team versus organizational loyalties Managing Project TeamsThe Five-Stage Team Development Model Situational Factors Affecting Team DevelopmentConditions Favoring Development of High-Performing Project Teams There are 10 or fewer members per team. Members volunteer to serve on the project team. Members serve on the project from beginning to end. Members are assigned to the project full time. Members are part of an organization culture that fosters cooperation and trust. Members report solely to the project manager. All relevant functional areas are represented on the team. The project involves a compelling objective. Members are located within conversational distance of each other. Building High-Performance Project TeamsConsiderations that need to be factored into the recruitment process Problem-solving ability Availability Technological expertise Credibility Political connections Ambition, initiative, and energy Familiarity Conducting project meeting The first project team meeting—project kick-off meeting Establishing ground rules Planning decisions Tracking decisions Managing change decisions Relationship decisions Managing subsequent project meetings Establishing Team Norms Confidentiality is maintained; no information is shared outside the team unless all agree to it. It is acceptable to be in trouble, but it is not acceptable to surprise others. Tell others immediately when deadlines or milestones will not be reached. There is zero tolerance for bulling a way through a problem or an issue. Agree to disagree, but when a decision has been made, regardless of personal feelings, move forward. Respect outsiders, and do not flaunt one’s position on the project team. Hard work does not get in the way of having fun. Establishing a Team Identity Effective use of meetings Co-location of team members Creation of project name Get the team to build or do something together early on Team rituals Managing Project Reward Systems The reward system encourages team performance and extra effort. Most project managers advocate the use of group rewards. To increase the value of rewards, rewards need to have lasting significance. Some project managers have to use negative reinforcement to motivate project performance. There are times when we need to reward individual performance. Examples of this kind of rewards include: Letter of recommendation Public recognition for outstanding work Job assignments Flexibility Group Decision-Making Process: Identifying problems Generating alternatives Reaching a decision Following up Managing Conflict within the Project Encouraging Functional Conflict: obtaining a deeper understanding of the issues and coming up with the best decisions possible Managing Dysfunctional Conflict Mediate the conflict Arbitrate the conflict Control the conflict Accept the conflict Eliminate the conflict Managing Virtual Project TeamsTwo biggest challenges involved in managing a virtual project team are Developing trust Hold a face-to-face meeting at the beginning and orchestrate the exchange of social information Set clear roles for each team member Form teams with people who have already worked effectively together on projects, if possible Developing effective patterns of communication Don’t let team members vanish Establish a code of conduct to avoid delays Establish clear norms and protocols for surfacing assumptions and conflicts Use electronic video technology to verify work Share the pain Project Team Pitfalls Groupthink Illusion of invulnerability Whitewash of critical thinking Negative stereotypes of outsiders Direct pressure Bureaucratic bypass syndrome Team spirit becomes team infatuation","link":"/blog/2024/11/14/About-Project-Management-Part-3/"},{"title":"About Project Management ( Part 4 )","text":"OutsourcingOutsourcing Project WorkAdvantages of Outsourcing Cost reduction: Outsourcing can lead to significant cost savings, as it allows companies to leverage lower labor costs in other countries. Focus on Core Competencies: Outsourcing non-core activities allows companies to focus on their primary business functions. Access to Expertise: Outsourcing to specialized service providers can provide access to expertise that may not be readily available within the organization. Scalability: Outsourcing can facilitate scalability, as service providers can quickly increase or decrease resources as needed. Risk Management: Outsourcing can help manage risks associated with new or untested technologies or markets. Disadvantages of Outsourcing Coordination breakdown: Communication and coordination challenges can arise when working with offshore teams, leading to misunderstandings and delays. Loss of Control: Outsourcing involves transferring control over certain aspects of the project to an external provider. Conflict Security issues: Outsourcing sensitive data or intellectual property to foreign countries may raise security concerns. Political hot potato: Outsourcing can make a company a target for political or social unrest in the host country. Request for Proposal (RFP)Steps of Development of a Detailed RFP Summary of needs and request for action Statement of work (SOW) detailing the scope and major deliverables Deliverable specifications/requirements, features, and tasks Responsibilities—vendor and customer Project schedule Costs and payment schedule Type of contract Experience and staffing Evaluation criteria Best Practices in Outsourcing Project Work Well-defined requirements and procedures Extensive training and team-building activities Well-established conflict management processes in place Frequent review and status updates Co-location when needed Fair and incentive-laden contracts Long-term outsourcing relationships Four Strategies for Communicating with Outsourcers Recognize culture differences Choose the right words Confirm your requirements Set deadlines Advantages of a Long-Term Partnership Reduced administrative costs More efficient utilization of resources Improved communication Improved innovation Improved performance Principled negotiation Emphasizes developing win/win solutions while protecting yourself against those whowould take advantages of your forthrightness. Is based on four key points. Separate the people from the problem Focus on interests, not positions Invent options for mutual gains When possible, use objective criteria Dealing with Unreasonable People When the other person begins to push, don’t push back. Ask questions instead of making statements. Invite criticism and advice instead of defending your ideas. Use silence as a response to an unreasonable proposal. Have a strong best alternative to a negotiated agreement (BATNA). A strong BATNA gives you the power to walk away and say, “No deal unless we work toward a win/win scenario.” A Note on Managing Customer Relations Bad news travel faster and farther than good news. Project managers need to cultivate positive working relations with clients to preserve their reputations. Customer satisfaction is a function of the extent to which perceived performance (or outcome) exceeds expectations. The met-expectation model of customer satisfaction highlights the point that whether a client is dissatisfied or delighted with a project is not based on hard facts and objective data but on perceptions and expectations. Project managers must be skilled at managing customer expectations and perceptions. Managing Customer Expectations Avoid the temptation to oversell the virtues of a project to win approval. Lower customer expectations by underselling projects. Work closely with the client organization to develop a well-defined project scope statement. Share significant risks or potential problems that might disrupt project execution. Keep customers abreast of project progress. Handle customer interactions, unexpected problems and setbacks with a competent and professional manner. Speak with one voice. ( Avoiding Visible Internal Disputes ) Procurement Management Process Planning purchases and acquisitions Planning contracting Requesting seller responses Selecting sellers Administering the contract Closing the contract Fixed-Price Contracts The contractor agrees to perform all work specified in the contract at a fixed price. Fixed-price contracts are preferred by both owners and contractors when the scope of the project is well defined with predictable costs and low implementation risks. The disadvantage of a fixed-price contract for owners is that it is more difficult and more costly to prepare. The primary disadvantages of a fixed-price contract for contractors is that they run the risk of underestimating. Contracts with long lead times such as construction and production projects may include escalation provisions that protect the contractor against external cost increases in materials, labor rates, or overhead expenses. Cost-Plus Contracts The contractor is reimbursed for all direct allowable costs (materials, labor, travel) plus an additional fee to cover overhead and profit. Unlike fixed-price contracts, cost-plus contracts put the burden of risk on the client. The contract does not indicate what the project is going to cost until the end of the project. The inherent weakness of cost-plus contracts has been compensated for by a variety of incentive clauses directed at providing incentives to contractors to control costs, maintain performance, and avoid schedule overruns. Contract Change Control System Defines the process by which the contract may be modified. Includes the paperwork tracking systems dispute resolution procedures approval levels necessary for authorizing changes Monitoring ProgressStructure of a Project Monitoring Information SystemA project monitoring system involves Determining what data to collect Determining how, when, and who will collect the data Analysis of the data Reporting current progress What Data Are Collected?The data need to answer questions such as What is the current status of the project in terms of schedule and cost? How much will it cost to complete the project? When will the project be completed? Are there potential problems that need to be addressed now? What, who, and where are the causes for cost or schedule overruns? If there is a cost overrun midway in the project, can we forecast the overrun at completion? Collecting Data and Analysis Will the data be collected by the project team, contractor, independent cost engineers, project manager? Will the data be derived electronically from some form of surrogate data? Should the reporting period be one hour, one day, one week, or what? Is there a central repository for the data collected and is someone responsible for its dissemination? Reports and Reporting Who gets the progress reports? How will the reports be transmitted? When will the reports be distributed? A common topic format for progress reports: Progress since last report Current status of project: 1.schedule, 2.cost, 3.scope Cumulative trends Problems and issues since last report: 1. Actions and resolutions of earlier problems 2. New variances and problems identified Corrective action planned The Project Control ProcessControlIs the process of comparing actual performance against plan to identify deviations, evaluate possible alternative courses of actions, and take appropriate corrective action. Project control steps for measuring and evaluating project performance Setting a baseline plan Measuring progress and performance Comparing plan against actual Taking action Monitoring Time PerformanceTypical tools used for communicating project schedule status Gantt chart (bar chart) is the most favored, used, and understandable. It is commonly referred to as a tracking Gantt chart. Control chart is used to plot the difference between the scheduled and actual times on the critical path at a given point on the project. Milestone schedules are often used to keep more distal stakeholders informed on the progress of a project. Milestones are significant project events that mark major accomplishments. Earned Value Management (EVM) Is a methodology that combines scope, schedule, and resource measurement to assess project performance and progress. Was pioneered by the U.S. Department of Defense (DoD) in the 1960s. Uses several acronyms and equations for analysis. Uses data developed from the work breakdown structure, project network, and schedule. Starts with the time-phased costs that provide the project budget baseline, which is called the planned budgeted value of the work scheduled (PV). Then comparisons can be made with actual and planned schedule and costs. Term Definition EV Earned value for a task is the budgeted value of the work accomplished. Work accomplished is often measured in terms of percentages (e.g., 25% complete) in which case, EV is simply percent complete times its original budget. [The older acronym for this value was BCWP—budgeted cost of the work performed.] PV The planned time-phased baseline of the value of the work scheduled. An approved cost estimate of the resources scheduled in a time-phased cumulative baseline [BCWS—budgeted cost of the work scheduled]. AC Actual cost of the work completed. The sum of the costs incurred in accomplishing work [ACWP—actual cost of the work performed]. CV Cost variance is the difference between the earned value and the actual costs for the work completed to date where CV = EV − AC. SV Schedule variance is the difference between the earned value and the baseline to date where SV = EV − PV. BAC Budgeted cost at completion. The total budgeted cost of the baseline or project cost accounts. EAC Estimated cost at completion ETC Estimated cost to complete remaining work VAC Cost variance at completion. VAC indicates expected actual over- or underrun cost at completion. Developing an Integrated Cost/Schedule System Define the work using a WBS. Scope Work package Deliverables Organization units Resources Budgets for each work package Develop work and resource schedule. Schedule resources to activities Time-phase work packages into a network Develop a time-phased budget using work packages included in an activity called the planned budgeted cost of the work scheduled (PV). At the work package level, collect the actual costs for the work performed called the actual cost of the work completed (AC). Multiple percent complete with the original budget amount to be earned value (EV). Compute the schedule variance (SV = EV – PV) and cost variance (CV = EV – AC). Development of Project BaselinePurposes of a Baseline (PV) To measure and report progress To estimate cash flow Rules in Assigning Costs to the Baseline Costs are placed (time-phased) in the baseline exactly as managers expected them to be “earned.” Percent complete is the workhorse most commonly used. Someone familiar with each task estimates what percent of the task has been completed or how much of the task remains. What Costs Are Included in Baselines? Baseline is the sum of the cost accounts and each cost account is the sum of the work packages in the cost account. Three direct costs are typically included in baselines—labor, equipment, and materials Methods of Variance AnalysisComparing earned value with The expected schedule value The actual costs Assessing current status of a project requires three data elements Planned cost of the work scheduled (PV) Budgeted cost of the work completed (EV) Actual cost of the work completed (AC) Computing schedule variance (SV) and cost variance (CV) A positive variance indicates a desirable condition, while a negative variance suggests problems or changes that have taken place. VariancesCost variance (CV) = EV – AC Tells us if the work accomplished costs more or less than was planned at any point over the life of the project. Schedule variance (SV) = EV – PV Presents an overall assessment of all work packages in the project scheduled to date. Contains no critical path information. Measures progress in dollars rather than time units. Variance at completion (VAC) = BAC – EAC Suggests whether the costs at completion of the project will differ from what was planned. Developing a Status Report: A Hypothetical ExampleAssumptions Each cost account has only one work package, and each cost account will be represented as an activity on the network. The project network early start times will serve as the basis for assigning the baseline values. From the moment work on an activity task begins, some actual costs will be incurred each period until the activity is completed. Indexes to Monitor ProgressPerformance Indexes Cost performance index (CPI) = EV/AC Measures cost efficiency of the work accomplished to date Scheduling performance index (SPI) = EV/PV Measures scheduling efficiency to date Project Percent Complete Indexes Percent complete index budgeted costs (PCIB) = EV/BAC Percent complete index actual costs (PCIC) = AC/EAC Management reserve index (MRI) = CV/MR Is popular in the construction industry Reflects the amount of management reserves that has been absorbed by cost overruns. Additional Earned Value RulesRules applied to short-duration activities and/or small-cost activities 0/100 rule: Assumes 100% of the budget is earned when the work package is completed. 50/50 rule: Allows 50% of the value of the work package budget to be earned when it is started and 50% to be earned when the package is completed. Rule used gates before the total budgeted value of an activity can be claimed Percent complete with weighted monitoring gates: Uses subjective estimated percent complete in combination with hard, tangible monitoring points. Forecasting Final Project CostTwo methods used to revise estimates of future project costs Revised estimated cost at completion (EACre) Allows experts in the field to change original baseline durations and costs because new information tells them the original estimates are not accurate. Forecasted total cost at completion (EACf) Uses the actual costs to date plus an efficiency index (CPI=EV/AC) applied to the remaining project work. Forecasting Models: EACre and EACf Revised estimated cost at completion (EACre) = AC + ETCre AC = cumulative actual cost of work completed to date ETCre = revised estimated cost to complete remaining work Forecasted total cost at completion (EACf) = ETC + AC = Work remaining / CPI + AC = (BAC − EV)/(EV/AC) + AC where: ETC = estimated cost to complete remaining work AC = cumulative actual cost of work completed to date CPI = cumulative cost index to date BAC = total budget of the baseline EV = cumulative budgeted cost of work completed to date Another Forecasting IndexTo Complete Performance Index (TCPI) = (BAC − EV) / (BAC − AC) Used as a supplement to the estimate at completion (EACf) computation. Measures the amount of value each remaining dollar in the budget must earn to stay within the budget. A ratio less than 1.00 indicates an ability to complete the project without using all of the remaining budget. 13.8 Other Control Issues Technical performance measurement is as important as measuring schedule and cost performance. Scope creep causes problems because the “minor refinements” eventually build to be major scope changes. Baseline changes should be allowed only if it is clear that the project will fail without the change, the project will be improved significantly with the change, or the customer wants it and will pay for it. Data acquisition is time consuming and costly. AgileTraditional versus Agile Methods Traditional Project Management Approach Concentrates on thorough, up front planning of the entire project. Requires a high degree of predictability to be effective. Agile Project Management (Agile PM) Relies on iterative, incremental development (IID). Is ideal for exploratory projects in which requirements need to be discovered and new technology tested. Focuses on active collaboration between the project team and customers representatives, breaking projects into small, functional pieces and adapting to changing requirements. A Set of 12 Guiding Principles for Agile PM Our highest priority is to satisfy the customer through early and continuous delivery of valuable software. Welcome changing requirements, even late in development. Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale. Business people and developers must work together daily throughout the project. Build projects around motivated individuals. Give them the environment and support they need and trust them to get the job done. The most efficient and effective method of conveying information to and within a development team is face-to-face conversation. Working software is the primary measure of progress. Agile processes promote sustainable development. Continuous attention to technical excellence and good design enhances agility. Simplicity—the art of maximizing the amount of work not done—is essential. The best architectures, requirements, and designs emerge from self-organizing teams. At regular intervals, the team reflects on how to become more effective, then turns and adjusts its behavior accordingly. Agile PM Utilizes a rolling wave planning and scheduling project methodology. Is continuously developed through a series of incremental iterations over time. Iterations are short time frames (“time boxes”). The goal of each iteration is to develop a workable product that satisfies one or more desired product features to demonstrate to the customer and other key stakeholders. At the end of each iteration, stakeholders and customers review progress and re-evaluate priorities to ensure alignment with customer needs and company goals. Each new iteration subsumes the work of the previous iterations and adds new capabilities to the evolving product Advantages of Iterative Development Process Continuous integration, verification, and validation of the evolving product. Frequent demonstration of progress to increase the likelihood that the end product will satisfy customer needs. Early detection of defects and problems. Agile Principles Focus on customer value Iterative and incremental delivery Experimentation and adaptation Self-organization Servant leadership Continuous improvement Agile PM in Action: Scrum Is a holistic approach to developing new products, where the whole team “tries to go the distance as a unit, passing the ball back and forth.” Begins with a high-level scope definition and ballpark time and cost estimates for the project. Use product features as deliverables. A feature is defined as a piece of a product that delivers some useful functionality to a customer. The project team tackles the highest-priority feasible feature first. Priorities are re-evaluated after each iteration. Iterations are called sprints and should last no longer than four weeks. The goal of each sprint is to produce fully functional features. Specific features are created according to four distinct phases: analysis, design, build, and test. Key Roles and Responsibilities in the Scrum ProcessProduct Owner Acts on behalf of customers/end users to represent their interests. Works with the development team to refine features through stories and end users cases. Ensures that the development team focuses their efforts on developing a product that will fulfill the business objective of the project. Development Team Is responsible for delivering the product. Is typically made up of five to nine people with cross-functional skill sets. Scrum Master (Project Manager) Facilitates the scrum process and resolves impediments at the team and organization levels. Acts as buffer between the team and outside interference but not the leader of team (the team leads itself!) Helps the product owner with planning and try to keep the team energized. Scrum Artifacts Product Backlog Definition: The Product Backlog is a prioritized list of all the features, requirements, enhancements, and bug fixes that might be needed for the product. It is essentially a “wish list” of everything the team could work on. Ownership: Managed by the Product Owner, who ensures it reflects the product vision and priorities. Scope: Covers the entire project or product lifecycle. Content: Includes high-level features or user stories, detailed items, and technical improvements. Dynamic Nature: Continuously evolves and adapts based on changing customer needs, feedback, and business priorities. Purpose: Serves as the single source of truth for work to be done on the product. Sprint Backlog Definition: The Sprint Backlog is a subset of the Product Backlog, containing items that the team commits to completing during a specific sprint. Ownership: Managed by the Development Team, as they are responsible for planning and delivering the work. Scope: Focused on the current sprint, usually spanning 1-4 weeks. Content: Includes selected Product Backlog items, detailed tasks to complete them, and technical work like bug fixes or improvements. Static During Sprint: Unlike the Product Backlog, the Sprint Backlog is not supposed to change once the sprint starts (except in rare cases) Extreme Programming(XP) and KanbanExtreme Programming- Is a more aggressive form of Scrum that organizes people to produce higher-quality software more efficiently. - Considers change a natural, even desirable aspect of software development projects and should be planned for, instead of eliminated. - Are test-driven development and paired programming. - Is founded on five values: communication, simplicity, feedback, courage and respect. Kanban Is a lean management methodology that has been adapted by Agile practitioners to help manage project work flow. Consists of a whiteboard divided into three columns: Planned, Work in Progress, and Done. Is based on the idea of a pull system—signaling when the team is ready for more work. Helps the team visualize the work flow on the project and focus their attention on the most critical work. Applying Agile PM to Large ProjectsScaling Involves several teams working on different features at the same time. Needs to make sure that the different features being created work in harmony with each other—integration. Staging Requires significant up-front planning to manage the interdependences of different features that will be developed. Involves developing protocols and defining roles for coordinating efforts and assuring compatibility Limitations and Concerns Agile PM is not a simple methodology. Adoption tends to evolve over time. Many of the Agile principles, including self-organizing teams and intense collaboration, are incompatible with corporate cultures. Agile PM does not satisfy top management’s need for control. Agile skeptics warn that evolving requirements contribute to scope creep. Agile PM requires active customer involvement. Hybrid Models Agile PM is used up front to resolve key scope questions and define requirements. Then traditional PM is applied to complete the project. Incremental, experimentation is used to resolve technical issues, allowing for a formal implementation plan. Many companies use hybrid models on large projects that combine waterfall and Agile methods. Teams use Agile techniques on plan-driven projects. Teams use shorter iterations and retrospectives to get critical customer feedback. Kanban methods are used by traditional teams to visualize work and identify bottlenecks in the project schedule.","link":"/blog/2024/12/04/About-Project-Management-Part-4/"},{"title":"Chrome Extension Development","text":"This blog will walk you through how to develop a Chrome Extension. From concepts to practical examples, this guide will help you create your own Chrome Extension. What can Chrome Extension do?A Chrome extension is a small software program that customizes the Chrome browser. It can: Enhance user experience by adding new features. Interact with web pages. Automate repetitive tasks. Some popular examples include ad blockers, language translators ( Grammarly ), and password managers. Core Components of a Chrome ExtensionManifest.jsonIt is the core configuration file for your extension. It contains metadata such as the name, version, permissions, and entry points of the extension. PopupDefines the popup window that appears when the user clicks the extension’s icon in the browser toolbar. You can config the popup window HTML file ( The HTML file can reference JavaScript and CSS files ) in the manifest.json. 1234&quot;action&quot;: { &quot;default_popup&quot;: &quot;popup.html&quot;, &quot;default_icon&quot;: &quot;icons/icon48.png&quot;} Background ScriptDefines the background logic of the extension, handling long-running tasks or event listeners.The background.js script runs as a background service when the extension is loaded. 1234// manifest.json&quot;background&quot;: { &quot;service_worker&quot;: &quot;background.js&quot;} Content ScriptInjected into web pages to interact with their DOM or listen for user actions. 123456789// manifest.json&quot;content_scripts&quot;: [ { &quot;matches&quot;: [&quot;https://*/*&quot;], // content.js and styles.css are injected into the pages that match the matches pattern (e.g., all HTTPS pages in this case). &quot;js&quot;: [&quot;content.js&quot;], &quot;css&quot;: [&quot;styles.css&quot;] }] Options PageDefines a settings page where users can configure the extension. The user can access the settings page from the extension’s management page in Chrome. 12// manifest.json&quot;options_page&quot;: &quot;options.html&quot; PermissionsDeclares the permissions the extension needs to access specific browser features or resources. 12// mainfest.json&quot;permissions&quot;: [&quot;contextMenus&quot;, &quot;activeTab&quot;, &quot;storage&quot;, &quot;tabs&quot;] Context Menus (Right-Click Menu)Defines custom right-click menu items for the extension. This is handled in background.js, and you declare the necessary permissions in manifest.json. Dynamic Menu Creation in background.js: 1234567891011chrome.contextMenus.create({ id: 'exampleMenu', title: 'Do something cool', contexts: ['all'],})chrome.contextMenus.onClicked.addListener((info, tab) =&gt; { if (info.menuItemId === 'exampleMenu') { alert('Menu clicked!') }}) PracticeBuild ToolRecommenad using parcel to build the Chrome extension. SummaryAll right, I think you have know about the Chrome extension development. This is a demo of Chrome extension development, available in my GitHub repository. It includes both Frontend and Backend implementations.","link":"/blog/2024/10/20/Chrome-Extension/"},{"title":"About Machine Learning ( Part 1: Gradient Descent )","text":"Data ScienceTarget VariableThe target variable is the variable the model aims to predict or explain. It’s also called the dependent variable or label. AttributesAttributes are the features or variables that describe each instance in a dataset. They are also known as features, columns, or independent variables. InstancesInstances represent individual samples or data points in a dataset. They are also referred to as samples, rows, or observations. Design of ExperimentsStrategy of Experiments Best Guess Appraoch One-Factor-at-a-time: Standard practice but not efficient; Does not consider interactions. Factorial Design: Considers Interactions; Is more efficient. Principles Randomization: Conducting experiments in a random order to mitigate systematic bias. Replication: Repeat experiments to estimate error and improve precision. (* not the same as measurement error) Blocking: Include experimental factors to mitigate variance from nuisance factors. Public Data Repositories Federated Research Data Repository UCI Machine learning Repository OptimizationMaking the best or most effective use of a situation or resource. In terms of mathematics, we call this reducing a Cost Function (a.k.the objective function) J(θ) =? We can use optimization to minimize the overall error ( linear model ): $$J(m, b) = \\sum_{i=0}^{N} [x_i - (mx_i + b)]$$ A solution is referred to global or local maximum or minimum. Mean Squared Error: $$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$ Gradient Descent Guess the initial values of the problem parameters (x, y) Calculate the value of the objective function Determine the Gradient of the function Change the parameters of the objective function slightly in the direction of the gradient Repeat until the error is close to zero or some terminating condition is met. Examplehttps://github.com/kongchenglc/Machine-Learning-Examples Problems with Gradient Descent High dimensional Data is challenging Only good for Strictly Convex Objective Functions Requires a lot of memory occupancy Alternatives to Gradient DescentA solution is referred to global or local maximum or minimum ( Non linear methods… Non convex ) 1. Simulated AnnealingKey Features of Simulated Annealing: Global Search Capability: Simulated Annealing can escape local optima due to its ability to accept worse solutions $\\Delta f \\geq 0$ at high temperatures. As the temperature decreases, the algorithm becomes more “greedy,” eventually converging to a global or near-global optimum. Probabilistic Acceptance Rule: The acceptance of worse solutions is governed by the probability function $ P = e^{-\\Delta f / T} $. This allows the algorithm to explore the solution space freely during the initial stages, avoiding premature convergence. Wide Applicability: Simulated Annealing does not rely on specific properties of the objective function, such as differentiability or continuity. It is suitable for both discrete and continuous optimization problems. Advantages and Disadvantages of Simulated Annealing:Advantages: Simple to implement and widely applicable. Capable of avoiding local optima. Does not require the objective function to be differentiable or continuous. Disadvantages: Computationally intensive, especially for large-scale problems, as it may require many iterations. Convergence is slow, and performance heavily depends on parameters like initial temperature and cooling rate. In some cases, it may fail to find the true global optimum, instead settling on a near-optimal solution. 2. Particle Swarm OptimizationMain Features: Inspired by Nature: It simulates the social behavior of birds flocking or fish schooling, where each particle adjusts its position based on personal and collective experience. Velocity and Position Updates: Each particle updates its position based on its best solution and the best solution found by the group. Population-Based: PSO uses a group of particles (potential solutions) to explore the solution space. Advantages: Simple and Easy to Implement: PSO has fewer parameters compared to other algorithms like Genetic Algorithms. Global Search: PSO can escape local optima, helping it find a better global optimum. No Gradient Needed: It does not require derivative information, making it suitable for complex, non-differentiable problems. Flexible: It can be applied to both continuous and discrete optimization problems. Disadvantages: Slow Convergence: PSO can take a long time to converge, especially for complex problems. Parameter Sensitivity: The performance heavily depends on the selection of parameters like inertia weight and acceleration coefficients. Premature Convergence: In some cases, PSO may converge prematurely to a suboptimal solution. PSO is widely used in optimization problems where derivative information is unavailable or expensive to compute, with the trade-off being a potential slower convergence or suboptimal solutions in complex scenarios. 3. Genetic AlgorithmsKey Features: Population-Based Search: GA maintains a population of potential solutions, enhancing its ability to explore the solution space globally. Incorporates Evolutionary Concepts: Inspired by natural selection, it uses operators like selection, crossover, and mutation. Global Search Capability: Can escape local optima by introducing randomness through crossover and mutation. Fitness Evaluation: Solutions are evaluated using a fitness function, which guides the evolution toward optimal solutions. Flexible Objective Function: GA works on a wide range of optimization problems without requiring derivative information. Advantages: Global Optimization: Effective at finding global or near-global optima, especially in non-convex problems with multiple local optima. Flexible and Robust: Can handle complex, non-linear, and multi-modal objective functions. No Requirement for Gradient Information: Suitable for optimization problems where derivatives are unavailable or undefined. Adaptability: Easily adaptable to various problem domains, including discrete and continuous optimization. Diverse Exploration: Maintains a diverse population, reducing the risk of premature convergence. Disadvantages: High Computational Cost: Requires significant computational resources, especially for large populations or complex fitness evaluations. Parameter Sensitivity: Performance heavily depends on proper tuning of parameters like mutation rate, crossover rate, and population size. No Guarantee of Global Optimality: May converge to a suboptimal solution, particularly if not run for enough generations or with improper settings. Randomness Dependency: Relies on stochastic processes, leading to non-deterministic results. Slow Convergence: Compared to deterministic methods, GA can be slower, especially for problems with a clear gradient or simpler structure.","link":"/blog/2025/01/06/Machine-Learning-1/"},{"title":"Machine-Learning-10","text":"","link":"/blog/2025/02/24/Machine-Learning-10/"},{"title":"About Machine Learning ( Part 2: Linear Regression )","text":"DatasetIn prediction tasks, we often use independent features to predict a dependent variable. If we have a dataset: $${ x_d^{(i)}, t^{(i)} }$$ where: $x_d^{(i)}$: The $d$-th feature of the $i$-th instance in the dataset. $t^{(i)}$: The target value (dependent variable) for the $i$-th instance. $i = 1, \\dots, N$: $i$ indexes the instances, and $N$ is the total number of instances in the dataset. ( Here $i$ is not power ) $d = 1, \\dots, D$: $d$ indexes the features, and $D$ is the total number of independent features. Each feature in the dataset can be expressed as: $$x_d^{(i)}$$ For simplicity, the following focuses on a single feature $x$, meaning $D = 1$. PolynomialThis is a curve fitting problem, where we aim to fit a polynomial function to model the relationship between the independent variable $x$ and the dependent variable $t$. A polynomial model is expressed as: $$h(x, \\omega) = \\omega_0 + \\omega_1 x + \\omega_2 x^2 + \\cdots + \\omega_M x^M$$ $h(x, \\omega)$: The predicted output (dependent variable) for a given input $x$. $\\omega_0, \\omega_1, \\dots, \\omega_M$: The coefficients (parameters) of the polynomial. $M$: The order of the polynomial, which represents the highest power of $x$ used in the model. This expanded form explicitly shows all terms of the polynomial up to order $M$. It can also be written in a more compact form using summation: $$h(x, \\omega) = \\omega_0 + \\sum_{j=1}^{M} \\omega_j x^j$$ Here: The summation $\\sum_{j=1}^{M} \\omega_j x^j$ compactly represents all terms from $j = 1$ (first-order) to $j = M$ (highest-order). $\\omega_0$: The constant term (bias), which is excluded from the summation since it is independent of $x$. Linear RegressionFor a straight line, the model is a linear function of the form: $$f(x, \\omega) = \\omega_0 + \\omega_1 x$$ Where: $M = 1$, indicating that the polynomial is of degree 1 (a straight line). $f(x, \\omega) = \\omega_0 + \\omega_1 x$ is the equation of the line. $\\omega_1$ represents the slope of the line, and $\\omega_0$ represents the y-intercept in the equation. We can use optimization to minimize the overall error. The cost function $J(\\omega)$ is defined as: $$J(\\omega) = \\frac{1}{2} \\sum_{n=1}^{N} \\left(t_n - f(x_n, \\omega)\\right)^2$$ Where: $J(\\omega)$ is the cost function that we aim to minimize ( MSE ). $t_n$ is the target value (actual value) for the $n$-th data point. $f(x_n, \\omega)$ is the predicted value from the model for the $n$-th data point. $N$ is the total number of data points in the dataset. Gradient DescentGradient Descent is an optimization algorithm used to minimize the cost function. The idea is to adjust the parameters ($\\omega_0$, $\\omega_1$, etc.) in the direction of the negative gradient of the cost function to reduce the error. The general update rule is: $$\\omega \\leftarrow \\omega - \\lambda \\nabla J(\\omega)$$ Here: $\\omega$ represents the model parameters (e.g., $\\omega_0, \\omega_1$). $\\lambda$ is the learning rate, controlling the step size in each update. $\\nabla J(\\omega)$ is the gradient of the cost function with respect to $\\omega$. The cost function for linear regression is: $$J(\\omega) = \\frac{1}{2} \\sum_{n=1}^N \\left( (\\omega_0 + \\omega_1 x_n) - t_n \\right)^2$$ We compute the partial derivatives of $J(\\omega)$ with respect to each parameter: Gradient with respect to $\\omega_0$: $$\\frac{\\partial J(\\omega)}{\\partial \\omega_0} = \\sum_{n=1}^N \\left( (\\omega_0 + \\omega_1 x_n) - t_n \\right)$$ Gradient with respect to $\\omega_1$:$$\\frac{\\partial J(\\omega)}{\\partial \\omega_1} = \\sum_{n=1}^N \\left( (\\omega_0 + \\omega_1 x_n) - t_n \\right) x_n$$ Using the gradients, the parameters are updated as follows: For $\\omega_0$: $$\\omega_0 \\leftarrow \\omega_0 - \\lambda \\sum_{n=1}^N \\left( (\\omega_0 + \\omega_1 x_n) - t_n \\right)$$ For $\\omega_1$:$$\\omega_1 \\leftarrow \\omega_1 - \\lambda \\sum_{n=1}^N \\left( (\\omega_0 + \\omega_1 x_n) - t_n \\right) x_n$$ Initialize $\\omega_0$ and $\\omega_1$ with some random values (e.g., $0$). Compute the gradients $\\frac{\\partial J(\\omega)}{\\partial \\omega_0}$ and $\\frac{\\partial J(\\omega)}{\\partial \\omega_1}$. Update $\\omega_0$ and $\\omega_1$ using the update rules. Repeat the process until: The cost function $J(\\omega)$ converges to a minimum, or The number of iterations reaches a predefined limit. Demo Code Linear Regression with Multiple FeaturesThe model can be written as: $$\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_D x_D$$ Where: $D$ is the number of attributes (features) in the dataset. $x_1, x_2, \\dots, x_D$ are the features of the data. $\\theta_0$ is the intercept (bias term). $\\theta_1, \\theta_2, \\dots, \\theta_D$ are the weights (coefficients) corresponding to each feature. This equation can also be expressed in matrix form for computational efficiency. In matrix form, the prediction $\\hat{y}$ is expressed as: $$\\hat{y} = X \\theta$$ Where: $X$ is the design matrix of size $N \\times (D+1)$, where: $N$ is the number of instances (data points). The first column of $X$ is all ones, representing the bias term ($\\theta_0$). The remaining columns correspond to the feature values. For example, $X$ can look like this: $$X =\\begin{bmatrix}1 &amp; x_1^{(1)} &amp; x_2^{(1)} &amp; \\dots &amp; x_D^{(1)} \\newline1 &amp; x_1^{(2)} &amp; x_2^{(2)} &amp; \\dots &amp; x_D^{(2)} \\newline\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\newline1 &amp; x_1^{(N)} &amp; x_2^{(N)} &amp; \\dots &amp; x_D^{(N)}\\end{bmatrix}$$ $\\theta$ is the vector of coefficients:$$\\theta =\\begin{bmatrix}\\theta_0 \\newline\\theta_1 \\newline\\theta_2 \\newline\\vdots \\newline\\theta_D\\end{bmatrix}$$ To find the optimal values of $\\theta$, we minimize the cost function, which is typically the Mean Squared Error (MSE): $$J(\\theta) = \\frac{1}{2N} \\sum_{i=1}^N \\left( \\hat{y}^{(i)} - t^{(i)} \\right)^2$$ In matrix form, this is written as: $$J(\\theta) = \\frac{1}{2N} | X \\theta - t |^2$$ Where $t$ is the vector of true target values: $$t =\\begin{bmatrix}t^{(1)} \\newlinet^{(2)} \\newline\\vdots \\newlinet^{(N)}\\end{bmatrix}$$ By setting the gradient of $J(\\theta)$ with respect to $\\theta$ to zero, we derive the closed-form solution:$$\\hat{\\theta} = (X^T X)^{-1} X^T t$$ Where: $X^T$ is the transpose of the design matrix. $(X^T X)^{-1}$ is the inverse of the matrix product $X^T X$. Higher Order PolynomialsIn polynomial regression, we model the relationship between the input variable $x$ and output $f(x, \\omega)$ using a higher degree polynomial: $$f(x, \\omega) = \\omega_0 + \\omega_1 x + \\omega_2 x^2 + \\dots + \\omega_M x^M = \\sum_{j=0}^{M} \\omega_j x^j$$ $x$ is the input feature, and $\\omega_j$ are the coefficients. $M$ is the degree of the polynomial, which determines the complexity of the model. Choosing $M$ (Degree of Polynomial): Small $M$: Captures simple relationships; less prone to overfitting. Large $M$: Can overfit the data by capturing noise. Selection: Cross-validation is used to determine the best $M$ to balance fit and generalization. Overfitting &amp; RegularizationIn linear regression, overfitting occurs when the model becomes too complex and starts to fit noise in the training data. To prevent overfitting, we use regularization to penalize large coefficients and simplify the model. The regularized cost function is: $$E(\\omega) = \\frac{1}{2} \\sum_{n=1}^{N} (f(x_n, \\omega) - t_n)^2 + \\frac{\\lambda}{2} |\\omega|^2$$ Where: $f(x_n, \\omega)$ is the model’s prediction for the $n$-th data point. $t_n$ is the true target for the $n$-th data point. $\\lambda$ is the regularization parameter that controls the strength of the penalty. $|\\omega|^2$ is the squared L2 norm of the weights, i.e., the sum of the squares of the coefficients. The $\\lambda$ parameter allows you to control the trade-off between fitting the data well and keeping the model simple.","link":"/blog/2025/01/07/Machine-Learning-2/"},{"title":"About Machine Learning ( Part 3: Logistic Regression )","text":"Classification ProblemIn machine learning, when we are predicting a discrete label, such as determining whether an email is spam or not, we are dealing with a classification problem. Logistic regression is commonly used for binary classification tasks, where the goal is to predict one of two classes, typically represented as 0 or 1. The logistic function (also called the sigmoid function) is the core of logistic regression, as it maps input features to probabilities between 0 and 1. These probabilities represent the likelihood of the sample belonging to a particular class. The logistic function is defined as: $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$ Where $z = \\omega_0 + \\mathbf{\\omega}^T \\mathbf{x}$, the linear combination of the input features $\\mathbf{x}$ and the model’s parameters $\\mathbf{\\omega}$. Model RepresentationIn logistic regression, we aim to predict the probability that an observation $\\mathbf{x}$ belongs to class 1. The predicted probability is given by the following equation: $$p(C = 1|\\mathbf{x}) = \\sigma(\\omega_0 + \\mathbf{\\omega}^T \\mathbf{x}) = \\frac{1}{1 + e^{-(\\omega_0 + \\mathbf{\\omega}^T \\mathbf{x})}}$$ where: $p(C = 1|\\mathbf{x})$: The probability that the class label $C$ is 1, given the input features $\\mathbf{x}$. $\\omega_0$: The bias term, which helps adjust the output independently of the input features. $\\mathbf{\\omega}$: The weight vector that contains the coefficients for each feature. $\\mathbf{\\omega}^T \\mathbf{x}$: The dot product between the weight vector $\\mathbf{\\omega}$ and the feature vector $\\mathbf{x}$, representing the weighted sum of the input features. Decision BoundaryIn binary classification, the decision boundary is the point where the model predicts equal probabilities for both classes, meaning the probability of being in class 0 is 0.5 and the probability of being in class 1 is also 0.5. This boundary helps separate the two classes. We calculate this boundary by setting the predicted probability equal to 0.5: $$p(C = 1|\\mathbf{x}) = 0.5$$ This happens when the output of the logistic function equals 0.5. Solving for the decision boundary, we get: $$\\sigma(\\omega_0 + \\mathbf{\\omega}^T \\mathbf{x}) = 0.5$$ This implies: $$\\omega_0 + \\mathbf{\\omega}^T \\mathbf{x} = 0$$ This equation represents the decision boundary where the model will predict a 50% chance of the sample belonging to either class. Points on this boundary are classified as uncertain. Maximum Likelihood Estimation (MLE)In logistic regression, the goal is to find the parameters $\\mathbf{\\omega} = (\\omega_0, \\omega_1, …, \\omega_d)$ that maximize the likelihood of observing the training data. The likelihood function $L(\\mathbf{\\omega})$ is the probability of the observed labels given the feature vectors. If We assume that the data is independent andidentically distributed (IDD). The likelihood function will be: $$L(\\mathbf{\\omega}) = \\prod_{i=1}^{N} p(t_i | \\mathbf{x}_i; \\mathbf{\\omega})$$ Where: $N$: The number of training samples. $t_i$: The actual label for the $i$-th sample. $\\mathbf{x}_i$: The feature vector for the $i$-th sample. $p(t_i | \\mathbf{x}_i; \\mathbf{\\omega})$: The probability of observing label $t_i$ given the features $\\mathbf{x}_i$ and parameters $\\mathbf{\\omega}$. Maximizing this likelihood function helps us find the optimal values for the model’s parameters. Log-Likelihood FunctionHowever, when we have many samples ($N$ is large) and each probability $p(t_i | \\mathbf{x}_i; \\mathbf{\\omega})$ is a value less than 1, the product of these probabilities becomes very small. This leads to a problem called Numerical Underflow, where the computer cannot handle such small numbers. So, maximizing the likelihood function directly is difficult due to the product of probabilities. Instead, we take the log-likelihood, which simplifies the optimization by turning the product into a sum: $$\\ln(L(\\mathbf{\\omega})) = \\sum_{i=1}^{N} \\left[ t_i \\ln(p(t_i = 1|\\mathbf{x}_i; \\mathbf{\\omega})) + (1 - t_i) \\ln(1 - p(t_i = 1|\\mathbf{x}_i; \\mathbf{\\omega})) \\right]$$ This form assumes a binary classification scenario, where each label $t_i$ can only be either 0 or 1. In such a case: If $t_i = 1$, we calculate the log of the predicted probability for class 1: $\\ln(p(t_i = 1|\\mathbf{x}_i; \\mathbf{\\omega}))$. If $t_i = 0$, we calculate the log of the probability of class 0, which is $1 - p(t_i = 1|\\mathbf{x}_i; \\mathbf{\\omega})$: $\\ln(1 - p(t_i = 1|\\mathbf{x}_i; \\mathbf{\\omega}))$. This reflects the basic assumption of binary classification in logistic regression, where the goal is to predict the probability of an input sample belonging to class 1 (or class 0, which is just the complement of class 1). Gradient Descent for OptimizationWe use gradient descent to maximize the log-likelihood function. Gradient descent involves computing the gradient of the log-likelihood with respect to the parameters $\\mathbf{\\omega}$, and then updating the parameters in the direction that increases the log-likelihood. The gradient of the log-likelihood function with respect to each parameter $\\omega_d$ is: $$ \\frac{\\partial \\ln(L(\\mathbf{\\omega}))}{\\partial \\omega_d} = \\sum_{i=1}^{N} ( t_i - p(C = 1 \\mid \\mathbf{x}_i; \\mathbf{\\omega})) x_{i,d} $$ Where: $x_{i,d}$ is the $d$-th feature of the $i$-th sample. $p(C = 1|\\mathbf{x}_i; \\mathbf{\\omega})$ is the predicted probability of class 1 for the $i$-th sample. $t_i$ is the true label of the $i$-th sample, where $t_i = 1$ if the sample belongs to class 1 (positive class), and $t_i = 0$ if it belongs to class 0 (negative class). Explanation: The term $(t_i - p(C = 1|\\mathbf{x}_i; \\mathbf{\\omega}))$ represents the error between the true label and the predicted probability for the $i$-th sample. The product of this error and the corresponding feature $x_{i,d}$ allows us to adjust the weight $\\omega_d$ based on how the feature $x_{i,d}$ contributes to the error. By summing over all $N$ samples, the gradient is computed for each parameter $\\omega_d$. Using the gradient, we update the parameters $\\mathbf{\\omega}$ using the following rule: $$\\omega_d \\leftarrow \\omega_d - \\lambda \\frac{\\partial \\ln(L(\\mathbf{\\omega}))}{\\partial \\omega_d}$$ Where: $\\lambda$ is the learning rate, which controls the step size during optimization. Demo Code Confusion Matrix The confusion matrix is a table that summarizes the performance of a classifier on a set of test data for which the true values are known. Predicted Positive Predicted Negative Actual Positive True Positive (TP) False Negative (FN) Actual Negative False Positive (FP) True Negative (TN) True Positive (TP): Correctly predicted positive instances. True Negative (TN): Correctly predicted negative instances. False Positive (FP): Negative instances incorrectly predicted as positive. False Negative (FN): Positive instances incorrectly predicted as negative. AccuracyAccuracy measures the proportion of correctly classified instances (both positive and negative) out of all predictions. Formula: $$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}$$ When to use Accuracy: When the dataset is balanced, meaning the number of positive and negative instances is roughly equal. Precision (Positive Predictive Value)Precision quantifies the proportion of positive predictions that are correct. Formula: $$\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$ Use case for Precision: When false positives have a high cost (e.g., flagging legitimate emails as spam). Recall (Sensitivity or True Positive Rate)Recall measures the proportion of actual positives that are correctly identified. Formula: $$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$ Use case for Recall: When false negatives have a high cost (e.g., failing to detect a disease in medical testing). F1-Score (Harmonic Mean of Precision and Recall)The F1-Score combines Precision and Recall into a single metric, especially useful when you need to balance the trade-off between the two. Formula: $$F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$ Why use F1-Score? It is beneficial when dealing with imbalanced datasets, as it considers both false positives and false negatives. Key Insights Accuracy works well on balanced datasets but may be misleading when classes are imbalanced. Precision is crucial when false positives are costly. Recall is critical when false negatives are costly. F1-Score provides a balanced measure when both Precision and Recall are important. By carefully analyzing the confusion matrix and the derived metrics, you can fine-tune your model for optimal performance, depending on the specific requirements of your application.","link":"/blog/2025/01/16/Machine-Learning-3/"},{"title":"About Machine Learning ( Part 4: Decision Tree )","text":"A Decision Tree is a supervised learning algorithm used for both classification and regression tasks. It organizes data into a tree-like structure, where each internal node represents a decision based on a feature, and each leaf node provides a prediction. Decision trees are simple, interpretable, and capable of handling both categorical and numerical data. Classification TreeA Classification Tree is a decision tree used for classifying data into distinct categories or classes. The main objective of a classification tree is to predict the category or class to which a given input belongs based on various features. How Does a Classification Tree Work?The tree is constructed in the following steps: Select the best feature: The first step is to choose the feature that best splits the data. This is usually done by calculating the Entropy, such as Information Gain, or Gini Index. Split the data: The chosen feature is used to split the dataset into two or more subsets. The splitting process continues recursively until the stopping criteria are met (e.g., maximum depth reached or all data in a node belong to the same class). Predict the class: The leaf nodes represent the predicted class labels, which are determined based on the majority class in that node. EntropyEntropy measures the disorder or uncertainty in a dataset. It quantifies the impurity of a dataset. If the dataset is perfectly pure (i.e., all samples belong to the same class), the entropy is 0. If the dataset has an equal distribution of all possible classes, the entropy reaches its maximum value. The formula for entropy $H(S)$ of a set $S$ is: $$H(S) = - \\sum_{x \\in S} p(x) \\log_2 p(x)$$ Where: $S$ is the dataset. $p(x)$ is the proportion of instances in $S$ that belong to class $x$. For binary classification (i.e., two classes, say “Yes” and “No”), the entropy simplifies to: $$H(S) = - p(+) \\log_2 p(+) - p(-) \\log_2 p(-)$$ Where: $p(+)$ is the proportion of “Yes” labels in the dataset. $p(-)$ is the proportion of “No” labels in the dataset. Interpretation of Entropy: If the entire dataset belongs to one class (e.g., all “Yes” or all “No”), then the entropy is 0 because there is no uncertainty. If the dataset has an equal distribution of both classes (e.g., $p(+) = p(-) = 0.5$), the entropy is 1 because there is maximum uncertainty. For example, in the case of a Tennis Playing dataset, if the target variable (whether a person will play tennis or not) is evenly split between “Yes” and “No”, the entropy will be: $$H(S) = - 0.5 \\log_2 0.5 - 0.5 \\log_2 0.5 = 1$$ This means the data is maximally uncertain (a 50/50 chance of playing or not playing). Information GainInformation Gain (IG) measures how well an attribute (or feature) separates the dataset into distinct classes. It is based on the difference in entropy before and after the split. The goal is to reduce uncertainty or disorder in the data as much as possible by selecting the attribute. The formula for Information Gain when splitting a dataset $S$ based on an attribute $A$ is: $$IG(S, A) = H(S) - \\sum_{v \\in V(A)} \\frac{|S_v|}{|S|} H(S_v)$$ Where: $H(S)$ is the entropy of the dataset $S$ before the split. $H(S_v)$ is the entropy of the subset $S_v$. $V(A)$ is the set of all possible values for attribute $A$. $\\frac{|S_v|}{|S|}$ is the proportion of the data in subset $S_v$ relative to the entire dataset $S$. ( Weighted ) The higher the information gain, the better the attribute is at reducing uncertainty and distinguishing between different classes. A high information gain indicates that the attribute is good at separating the data into pure subsets. Code Demo Gini IndexGini Index is another measure used to evaluate the quality of a split in a decision tree. It measures the impurity or disorder of a dataset, with a lower Gini index indicating a purer dataset. The Gini index for a dataset ( S ) is calculated as: $$Gini(S) = 1 - \\sum_{i=1}^{C} p_i^2$$ Where: ( C ) is the number of classes in the target variable. ( p_i ) is the proportion of the samples in the dataset ( S ) that belong to class ( i ). Interpretation: If all the data points belong to a single class, the Gini index is 0, indicating a pure node. If the data points are evenly distributed among all classes, the Gini index is maximized (impure node). For binary classification, the maximum value is 0.5. OverfittingOverfitting occurs when a decision tree becomes too complex, capturing noise in the data instead of general patterns. It performs well on training data but poorly on new data. Given a hypothesis space $H$, a hypothesis $h \\in H$ is said to overfit the training data if there exists some alternative hypothesis $h’ \\in H$, such that $h$ has a smaller error than $h’$ over the training examples, but $h’$ has a smaller error than $h$ over the entire distribution of instances.– Tom Mitchell Causes: Noisy data or insufficient data can lead to overfitting. Solutions: Stop growing the tree once it reaches a certain depth. Prune the tree by removing branches with little importance. PruningPruning reduces tree complexity by removing unnecessary nodes. Process: Turn a node into a leaf with the most common value in that subset. Test the accuracy of the pruned tree. If accuracy improves, keep the change; if not, restore the node. Data Splits: Training set for building the tree. Testing set for evaluating performance. Pruning set for pruning decisions. Benefits: Simplifies the model. Reduces overfitting and improves generalization. Results in better test data performance. Regression TreeA Regression Tree is a type of decision tree used for predicting continuous target variables. Unlike classification trees that predict discrete labels, regression trees predict numerical values. Here’s how the process works: Choosing Features and Split Values The goal is to find the best feature and threshold to split the data. This is done by minimizing the variance or mean squared error (MSE) within each subset after the split. For example, given a feature $X$ and target $Y$, we want to find a threshold $t$ to split the data into two subsets: $X \\leq t$ and $X &gt; t$. The split that minimizes the variance within each subset is chosen. Splitting the Data Once the best feature and threshold are identified, the data is split into two subsets based on this threshold. This is a recursive process, where each subset is further split until a stopping condition (e.g., maximum depth or minimum sample size) is met. Recursive Splitting At each node, the algorithm continues splitting based on the feature that minimizes the variance. For example, a tree might first split the data based on $X = 5$, then further split the subset $X &gt; 5$ based on $X = 7$. Leaf Nodes and Predictions When the tree reaches the stopping condition, each leaf node represents a final prediction, which is the mean target value of the data points in that node. For instance, if a leaf node contains values $Y = 10, 12, 14$, the prediction for that leaf would be the average $12$. Prediction for New Data For new data, the tree traverses from the root to a leaf node, where the predicted value is the mean of the target values in that leaf. Bagging vs BoostingIn machine learning, Bagging and Boosting are two popular ensemble techniques used to improve the performance of models. These methods combine the predictions of multiple base learners to form a stronger model, but they approach this goal in different ways. Bagging (Bootstrap Aggregating)Bagging is an ensemble technique that reduces variance by training multiple base learners independently on different subsets of the data and then combining their predictions. 1. How Bagging Works Data Sampling: Multiple subsets of the training data are created by random sampling with replacement (bootstrap sampling). Train Multiple Models: Each subset is used to train a separate model, typically the same type of model (e.g., decision trees). Combine Predictions: For classification problems, the final prediction is the class that receives the most votes from all base learners (majority voting). For regression problems, the final prediction is the average of all base learner predictions. 2. Advantages Reduces overfitting, particularly with high-variance models (e.g., decision trees). Works well with unstable base learners. 3. Disadvantages Doesn’t perform as well when base learners are weak or the model complexity is too high. 4. Example Algorithm Random Forest: A popular implementation of Bagging, where base learners are decision trees trained on random subsets of features. BoostingBoosting is an ensemble technique that improves weak learners by iteratively training them on the data and adjusting the weights to focus on the mistakes of previous models. 1. How Boosting Works Train the First Model: Train a base learner on the training data. Calculate Error: Calculate the errors made by the first model. Adjust Weights: Increase the weights of the misclassified data points, so that the next model will focus more on them. Train Subsequent Models: Train the next model using the updated weights. Combine Predictions: The final prediction is a weighted average (regression) or a weighted vote (classification) of all base learners. 2. Advantages Reduces bias, improving model accuracy by focusing on hard-to-predict examples. Works well with weak learners that have high bias. 3. Disadvantages Can overfit if data is noisy or contains outliers. Computationally expensive since models are trained sequentially. 4. Example Algorithms AdaBoost: A widely used Boosting algorithm that adjusts sample weights based on misclassifications. Gradient Boosting: An improved version of Boosting that optimizes the model using gradient descent. XGBoost: A highly efficient implementation of Gradient Boosting, popular in machine learning competitions.","link":"/blog/2025/01/21/Machine-Learning-4/"},{"title":"About Machine Learning ( Part 5: Support Vector Machine )","text":"Support Vector Machine (SVM)Support Vector Machines (SVM) are one of the most powerful supervised learning algorithms used for classification and regression tasks. The HyperplaneIn a binary classification problem, the goal of SVM is to find a hyperplane that best separates two classes. Given a training dataset: $$D = { (\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\dots, (\\mathbf{x}_n, y_n) }, \\quad \\mathbf{x}_i \\in \\mathbb{R}^d, \\quad y_i \\in {-1, +1}$$ $\\mathbf{x}_i$: $d$-dimensional feature vector (e.g., pixel values in an image). $y_i$: Class label ($+1$ for “cat”, $-1$ for “dog”). The HyperplaneA hyperplane in $\\mathbb{R}^d$ is defined as: $$\\mathbf{w} \\cdot \\mathbf{x} + b = 0, \\quad \\mathbf{x} \\in \\mathbb{R}^d$$ $\\mathbf{w}$: Weight vector (normal to the hyperplane). $b$: Bias term (shifts the hyperplane away from the origin). $\\mathbf{x}$: Any point in the feature space. Example: 2D HyperplaneConsider a 2D hyperplane $2x_1 + 3x_2 - 12 = 0$: Normal Vector: $\\mathbf{w} = [2, 3]$. Bias: $b = -12$. The weight vector $\\mathbf{w}$ is perpendicular to the hyperplane. Margin MaximizationThe distance from a sample $\\mathbf{x}_i$ to the hyperplane is: $$\\text{Distance} = \\frac{|\\mathbf{w} \\cdot \\mathbf{x}_i + b|}{|\\mathbf{w}|}.$$ SVM seeks the hyperplane that maximizes the minimum margin between classes: $$\\max_{\\mathbf{w}, b} ( \\frac{2}{|\\mathbf{w}|} ) \\quad \\text{subject to} \\quad y_i(\\mathbf{w} \\cdot \\mathbf{x}_i + b) \\geq 1, , \\forall i.$$ This is equivalent to minimizing $|\\mathbf{w}|^2$, a convex optimization problem solvable via quadratic programming. OptimizeLinear Separation with Hard MarginWhen data is perfectly linearly separable, SVM seeks the hyperplane with maximum margin: $$\\min_{\\mathbf{w}, b} \\frac{1}{2}|\\mathbf{w}|^2 \\quad \\text{subject to} \\quad y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\geq 1, , \\forall i$$ Geometric Interpretation:The margin width is $\\frac{2}{|\\mathbf{w}|}$. Maximizing margin = minimizing $|\\mathbf{w}|$. The Limitation: Fails catastrophically when: Data has noise/outliers Classes are inherently non-separable Soft Margin SVMAllow controlled violations using slack variables $\\xi_i$: $$\\begin{aligned}\\min_{\\mathbf{w}, b, \\xi} &amp;\\quad \\frac{1}{2}|\\mathbf{w}|^2 + C\\sum_{i=1}^n \\xi_i \\\\text{s.t.} &amp;\\quad y_i(\\mathbf{w}^T\\mathbf{x}_i + b) \\geq 1 - \\xi_i \\&amp;\\quad \\xi_i \\geq 0, \\quad \\forall i\\end{aligned}$$ $C$: Penalty weight (Large $C$ ≈ Hard Margin) $\\xi_i$: How much the $i$-th sample violates the margin Lagrangian FormulationConvert constraints into the objective function: $$ \\mathcal{L} = \\frac{1}{2}\\|\\mathbf{w}\\|^2 + C\\sum_{i=1}^n \\xi_i - \\sum_{i=1}^n \\alpha_i[y_i(\\mathbf{w}^T\\mathbf{x}_i + b) - 1 + \\xi_i] - \\sum_{i=1}^n \\mu_i\\xi_i $$ Key Derivations: Primal Variables $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} = 0 \\Rightarrow \\mathbf{w} = \\sum \\alpha_i y_i \\mathbf{x}_i$ $\\frac{\\partial \\mathcal{L}}{\\partial b} = 0 \\Rightarrow \\sum \\alpha_i y_i = 0$ $\\frac{\\partial \\mathcal{L}}{\\partial \\xi_i} = 0 \\Rightarrow \\alpha_i + \\mu_i = C$ Dual ProblemSubstitute back to get: $$\\max_{\\alpha} \\sum_{i=1}^n \\alpha_i - \\frac{1}{2}\\sum_{i,j} \\alpha_i \\alpha_j y_i y_j \\mathbf{x}_i^T \\mathbf{x}_j \\\\text{s.t.} \\quad 0 \\leq \\alpha_i \\leq C, \\quad \\sum \\alpha_i y_i = 0$$ Interpretation of $\\alpha_i$ $\\alpha_i$ Range Sample Status $\\xi_i$ Value $=0$ Outside margin 0 $(0, C)$ On margin 0 $=C$ Inside margin $&gt;0$ Decision Function: $$f(\\mathbf{x}) = \\text{sign}( \\sum_{\\alpha_i &gt; 0} \\alpha_i y_i \\mathbf{x}_i^T \\mathbf{x} + b)$$ Nonlinear Classification with Kernel TrickThe Fundamental IdeaProblem: Many datasets require nonlinear boundaries.Solution: Map data to higher dimension $\\phi(\\mathbf{x})$ where linear separation becomes possible. Example Transformation:For $\\mathbf{x} = [x_1, x_2]$, use $\\phi(\\mathbf{x}) = [x_1, x_2, x_1^2 + x_2^2]$ The Computational ChallengeDirect computation of $\\phi(\\mathbf{x}_i)^T \\phi(\\mathbf{x}_j)$ in high dimensions is intractable. Key Insight: Many ML algorithms (like SVM) only need inner products, not explicit coordinates. Kernel Functions to the RescueReplace $\\phi(\\mathbf{x}_i)^T \\phi(\\mathbf{x}_j)$ with kernel $K(\\mathbf{x}_i, \\mathbf{x}_j)$: Updated Dual Problem: $$\\max_{\\alpha} \\sum_{i=1}^n \\alpha_i - \\frac{1}{2}\\sum_{i,j} \\alpha_i \\alpha_j y_i y_j K(\\mathbf{x}_i, \\mathbf{x}_j)$$ Common Kernels: Kernel Formula Characteristics Linear $K(\\mathbf{x}, \\mathbf{z}) = \\mathbf{x}^T\\mathbf{z}$ No transformation Polynomial $(\\mathbf{x}^T\\mathbf{z} + c)^d$ Captures polynomial interactions RBF $\\exp(-\\gamma |\\mathbf{x}-\\mathbf{z}|^2)$ Infinite-dimensional mapping Sigmoid $\\tanh(\\alpha \\mathbf{x}^T\\mathbf{z} + c)$ Mimics neural networks 3.4 Why Kernels Work: Mercer’s TheoremA valid kernel must: Be symmetric: $K(\\mathbf{x}, \\mathbf{z}) = K(\\mathbf{z}, \\mathbf{x})$ Produce positive semi-definite Gram matrix Practical Check: If SVM training converges, your kernel is valid.","link":"/blog/2025/02/02/Machine-Learning-5/"},{"title":"About Machine Learning ( Part 6: KNN vs. K-means )","text":"In machine learning, K-Nearest Neighbors (KNN) and K-means Clustering are two commonly used algorithms. Despite their similar names, they serve different purposes and have distinct working principles. KNN (K-Nearest Neighbors)KNN is a supervised learning algorithm used for classification and regression tasks. The core idea of KNN is: Given a new data point, find the K most similar instances in the training dataset (neighbors) and use them to predict the output. KNN is a lazy learning algorithm, meaning it does not require a training phase. Instead, it directly classifies or predicts based on stored data. KNN follows these steps: Compute the distance between the new data point and all training samples (e.g., using Euclidean distance). Select the K nearest neighbors. Predict the result: For classification: Use a majority vote among the K neighbors. For regression: Take the average of the K neighbors. Mathematical FormulationFor two points $A(x_1, y_1)$ and $B(x_2, y_2)$, the Euclidean distance is: $$d(A, B) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$ In n-dimensional space, it generalizes to: $$d(A, B) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$ where: $x_i$ and $y_i$ are the coordinates of points $A$ and $B$ in dimension $i$. If the K nearest neighbors have labels $y_1, y_2, …, y_K$, then the predicted label $\\hat{y}$ is: $$\\hat{y} = \\arg\\max_{c} \\sum_{i=1}^{K} \\mathbb{I}(y_i = c)$$ where: $\\mathbb{I}(\\cdot)$ is an indicator function, returning 1 if $y_i = c$ and 0 otherwise. The class with the most occurrences is chosen. Pros and Cons of KNNAdvantages: Simple and easy to implement. Effective for non-linear decision boundaries. No need for training (lazy learning). Disadvantages: Computationally expensive (slow for large datasets). Sensitive to noise and irrelevant features. Suffers from the curse of dimensionality. Applications of KNN Text classification (e.g., spam detection) Recommendation systems (e.g., movie or product recommendations) Medical diagnosis (e.g., predicting diseases based on similar cases) K-means ClusteringK-means is an unsupervised learning algorithm used for clustering. The core idea of K-means is: Partition the dataset into K clusters such that data points in the same cluster are similar to each other. It is an iterative optimization algorithm that minimizes intra-cluster distances. How K-means Works: Initialize K cluster centroids (randomly selected). Assign each data point to the nearest centroid. Update centroids by computing the mean of all points in each cluster. Repeat until centroids no longer change or a stopping criterion is met. Mathematical FormulationObjective Function (Loss Function): K-means minimizes the sum of squared distances between points and their assigned cluster centers: $$J = \\sum_{i=1}^{K} \\sum_{x_j \\in C_i} ||x_j - \\mu_i||^2$$ where: $K$ = number of clusters $C_i$ = the $i$-th cluster $x_j$ = a data point in cluster $C_i$ $\\mu_i$ = centroid of cluster $C_i$ Updating Cluster Centers: The new centroid $\\mu_i$ is computed as: $$\\mu_i = \\frac{1}{|C_i|} \\sum_{x_j \\in C_i} x_j$$ i.e., the mean of all points in the cluster. Pros and Cons of K-meansAdvantages: Simple and computationally efficient. Works well on large datasets. Produces interpretable results. Disadvantages: Requires manually setting K. Sensitive to initialization (may converge to local optima). Struggles with non-convex cluster shapes. Applications of K-means Customer segmentation (e.g., marketing analytics) Image segmentation (e.g., clustering colors in an image) Anomaly detection (e.g., identifying outliers) KNN vs. K-means: Key Differences Feature KNN (K-Nearest Neighbors) K-means Clustering Type Supervised learning Unsupervised learning Purpose Classification &amp; Regression Clustering Training No training required (lazy learning) Requires iterative training Prediction Based on K nearest neighbors Based on cluster centroids Distance metric Used to find nearest neighbors Used to compute cluster assignments Computation cost High for large datasets Lower after convergence Applications Spam detection, recommendation systems Market segmentation, image compression","link":"/blog/2025/02/02/Machine-Learning-6/"},{"title":"About Machine Learning ( Part 7: Artificial Neural Network )","text":"Bayes’ theorem$$P(y|X) = \\frac{P(X|y) P(y)}{P(X)}$$ where: $P(y|X)$: Posterior probability of class $y$ given input $X$. $P(X|y)$: Likelihood of seeing $X$ if the class is $y$. $P(y)$: Prior probability of class $y$. $P(X)$: Total probability of $X$ (normalization factor). Bayes Network (Bayesian Network, BN)A Bayesian network (BN) is a graphical model representing probabilistic dependencies between variables. It consists of: Nodes: Represent variables (e.g., symptoms, diseases). Edges: Represent conditional dependencies. Bayesian Inference in BNUsing Bayes’ rule, we can infer probabilities, such as: $$P(F|T, C) = \\frac{P(T, C | F) P(F)}{P(T, C)}$$ Bayesian networks are widely used in medical diagnosis, fraud detection, and AI decision-making. Artificial Neural Network (ANN)The PerceptronA perceptron is a simple artificial neuron that performs binary classification. It computes a weighted sum of inputs and applies an activation function: $$y = \\begin{cases}1, &amp; \\text{if } w \\cdot X + b &gt; 0 \\newline0, &amp; \\text{otherwise}\\end{cases}$$ where: $X$ is the input vector. $w$ is the weight vector. $b$ is the bias term. Learning in PerceptronsThe perceptron updates its weights using a simple rule: $$w \\leftarrow w + \\Delta w$$ where: $$\\Delta w = \\eta (y_{\\text{true}} - y_{\\text{pred}}) X$$ $\\eta$ is the learning rate. The perceptron adjusts weights only when it makes an error. Limitations of the Perceptron: Can only solve linearly separable problems (e.g., AND, OR gates). Fails for XOR problems, motivating more advanced learning rules. So activation funtion are usually used. Delta RuleThe Delta Rule is a gradient descent learning rule used in single-layer perceptrons and neural networks to minimize error and update weights. The main idea behind this rule is to adjust the weights based on the gradient of the error to minimize the loss function (often the Mean Squared Error, MSE). The Delta Rule is a specific case of the Gradient Descent method. Assume the output of a perceptron is calculated by the following formula: $$y = f(w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b)$$ Where: $x_i$ is the input value, $w_i$ is the corresponding weight, $b$ is the bias, $f(\\cdot)$ is the activation function (usually a linear or Sigmoid function), $y$ is the output, $t$ is the target label (the true value), $e = t - y$ is the error (difference between predicted and true output). The Delta Rule updates the weights as follows: $$\\Delta w_i = \\eta (t - y) x_i$$ Where: $\\eta$ is the learning rate that controls the step size of the updates, $(t - y)$ is the error, $x_i$ is the input used to adjust the corresponding weight. The weight update rule becomes: $$w_i \\leftarrow w_i + \\Delta w_i$$ Derivation of the Delta RuleThe Error Function (Mean Squared Error)To understand how the Delta Rule works, we first need to define the error function. The Mean Squared Error (MSE) is commonly used as the error metric in neural networks, especially for regression tasks. It measures the difference between the target output $t$ and the predicted output $y$: $$E = \\frac{1}{2} (t - y)^2$$ Where: $t$ is the target value (the true label), $y$ is the predicted output from the neural network. The reason we use a factor of $\\frac{1}{2}$ is to simplify the derivative when we apply the chain rule during weight updates. The Goal: Weight UpdateThe goal of the Delta Rule is to update the weights so that the error $E$ is minimized. We do this by adjusting the weights in the direction that reduces the error. To achieve this, we compute the gradient (partial derivative) of the error function with respect to the weights $w_i$. The output $y$ of a single output unit in the network is determined by: $$y = f(net)$$ Where: $net = \\sum_{i} w_i x_i + b$ is the weighted sum of inputs, $f(\\cdot)$ is the activation function applied to the weighted sum (in this case, we’ll focus on the Sigmoid function). To update the weights, we need the partial derivative of the error $E$ with respect to each weight $w_i$. This is done using the chain rule: $$\\frac{\\partial E}{\\partial w_i} = \\frac{\\partial E}{\\partial y} \\cdot \\frac{\\partial y}{\\partial w_i}$$ Compute $\\frac{\\partial E}{\\partial y}$The first term we need is the derivative of the error with respect to the output $y$. Since $E$ is the squared error, we can differentiate: $$\\frac{\\partial E}{\\partial y} = -(t - y)$$ This represents how much the error changes with respect to the output $y$. Compute $\\frac{\\partial y}{\\partial w_i}$Next, we calculate the derivative of the output $y$ with respect to each weight $w_i$. The output $y$ is the result of applying the activation function $f$ to the weighted sum $net$: $$y = f(net)$$ Using the chain rule, we get: $$\\frac{\\partial y}{\\partial w_i} = \\frac{\\partial f(net)}{\\partial net} \\cdot \\frac{\\partial net}{\\partial w_i}$$ Where: $\\frac{\\partial f(net)}{\\partial net} = f’(net)$ is the derivative of the activation function with respect to the net input, $\\frac{\\partial net}{\\partial w_i} = x_i$, since $net = \\sum w_i x_i + b$. Thus: $$\\frac{\\partial y}{\\partial w_i} = f’(net) \\cdot x_i$$ Combine Terms for the GradientNow, we combine the terms to compute the gradient of the error with respect to the weight $w_i$: $$\\frac{\\partial E}{\\partial w_i} = -(t - y) \\cdot f’(net) \\cdot x_i$$ This expression tells us how much to adjust each weight $w_i$ to minimize the error. Derivative of the Sigmoid Activation FunctionFor the Sigmoid activation function, the output $o$ is given by: $$o = f(net) = \\frac{1}{1 + e^{-net}}$$ The derivative of the Sigmoid function with respect to the net input $net$ is: $$f’(net) = o(1 - o)$$ Where $o$ is the output of the Sigmoid function. The Final Weight Update RuleWe can now substitute the derivative of the Sigmoid function into the weight update formula. The Delta Rule for updating weights is: $$\\Delta w_i = \\eta (t - y) \\cdot o \\cdot (1 - o) \\cdot x_i$$ Where: $\\eta$ is the learning rate, which controls how much the weights are adjusted at each step, $(t - y)$ is the error between the target and predicted output, $o(1 - o)$ is the derivative of the Sigmoid activation function, $x_i$ is the input corresponding to the weight $w_i$. Finally, the weights are updated as follows: $$w_i \\leftarrow w_i + \\Delta w_i$$ This update ensures that the weights move in the direction that minimizes the error. The Difference in the Calculation of $\\delta_k$ for Output and Hidden LayersThe calculation of the error signal $\\delta_k$ is different in the output layer and the hidden layer because: Output layer error is directly related to the target error, and we can compute the gradient directly. Hidden layer error is not directly related to the target, so we need to propagate the error backwards from downstream layers (closer to the output layer). Output Layer’s $\\delta_k$: Direct Calculation from ErrorIn the output layer, the error can be directly calculated because the output neurons compare their output values $o_k$ directly with the target values $y_k$. Thus, the error signal $\\delta_k$ is calculated directly based on the loss function. For the Mean Squared Error (MSE) loss function: $$E = \\frac{1}{2} \\sum_k (y_k - o_k)^2$$ We take the partial derivative with respect to $net_k$: $$\\delta_k = \\frac{\\partial E}{\\partial net_k} = \\frac{\\partial E}{\\partial o_k} \\cdot \\frac{\\partial o_k}{\\partial net_k}$$ Where: $\\frac{\\partial E}{\\partial o_k} = -(y_k - o_k)$ (the error term), $\\frac{\\partial o_k}{\\partial net_k}$ depends on the activation function (e.g., Sigmoid: $o_k(1 - o_k)$). Thus, for the Sigmoid activation function: $$\\delta_k = -(y_k - o_k) \\cdot o_k (1 - o_k)$$ This calculation is specific to the output layer because the error term $y_k - o_k$ is directly available. Hidden Layer’s $\\delta_h$: Backpropagating Error from DownstreamIn the hidden layer, the error cannot be directly calculated because the hidden neurons do not directly compare their outputs with target values. So, how do we know how much a hidden neuron contributes to the final error? The answer is: The error signal propagates backward from downstream layers! What are downstream layers? Neural networks perform forward propagation for computing outputs, but the error is propagated backward. Hidden neurons influence multiple output neurons, so their error needs to be propagated back from those output neurons. “Downstream” refers to layers closer to the output layer, and “upstream” refers to layers closer to the input layer. Calculating the Hidden Layer’s Error Signal $\\delta_h$For a hidden layer neuron $h$, there is no direct error, so its gradient comes from downstream layers (the output layer or deeper hidden layers). Using the Chain Rule, we calculate: $$\\delta_h = \\sum_k \\left( \\delta_k \\cdot \\omega_{kh} \\right) \\cdot o_h (1 - o_h)$$ Where: $\\delta_k$ is the downstream (output layer) error signal, $\\omega_{kh}$ is the weight from the hidden layer neuron $h$ to the output layer neuron $k$, $o_h(1 - o_h)$ is the derivative of the activation function for the hidden layer neuron. $\\sum_k (\\delta_k \\cdot \\omega_{kh})$: If the hidden layer neuron $h$ is connected to multiple output neurons $k$, its error is the weighted sum of all these error signals. BackpropagationBackpropagation is the core algorithm behind training multi-layer neural networks. It efficiently computes the gradient of the loss function with respect to the network’s weights, enabling the network to learn from data through gradient descent. Backpropagation AlgorithmStep 1: Initialize the network Create a feed-forward network with: $n_{in}$ input neurons $n_h$ hidden neurons $n_{out}$ output neurons Assign random small weights (e.g., between $-0.05$ and $0.05$) to break symmetry. Step 2: Forward PropagationFor each training example $\\mathbf{x}$: Compute the weighted sum of inputs for each neuron. Apply an activation function (e.g., Sigmoid) to get the output. Step 3: Compute Errors Compute the error at the output layer:$$\\delta_j = \\sigma_j (1 - \\sigma_j) (t_j - out_j)$$where: $\\sigma_j$ is the output of the neuron $t_j$ is the target value $out_j$ is the actual output Compute the error at the hidden layers by propagating errors backward: $$ \\delta_j = \\sigma_j (1 - \\sigma_j) \\sum_{k \\in \\text{downstream}} w_{kj} \\delta_k $$ Step 4: Update WeightsEach weight $w_{ij}$ is updated using gradient descent:$$w_{ij} \\leftarrow w_{ij} + \\eta \\delta_j x_i$$where $\\eta$ is the learning rate. Numerical Example of BackpropagationLet’s go through an example using a small network. Network Structure Input layer: 2 neurons ($x_1, x_2$) Hidden layer: 2 neurons ($h_1, h_2$) Output layer: 1 neuron ($o$) Activation function: Sigmoid Given Initial Values Inputs: $x_1 = 0.05, x_2 = 0.10$ Targets: $t = 0.01$ Weights: Input to Hidden: $w_{1,1} = 0.15$, $w_{1,2} = 0.20$ $w_{2,1} = 0.25$, $w_{2,2} = 0.30$ Hidden to Output: $w_{h1,o} = 0.40$, $w_{h2,o} = 0.45$ Biases: Assume 0 for simplicity. Learning Rate: $\\eta = 0.5$ Step 1: Forward PassCompute the net input and output of the hidden neurons: $$net_{h1} = w_{1,1}x_1 + w_{2,1}x_2 = (0.15)(0.05) + (0.25)(0.10) = 0.0125$$ $$\\sigma_{h1} = \\frac{1}{1 + e^{-net_{h1}}} = \\frac{1}{1 + e^{-0.0125}} \\approx 0.5031$$ Similarly, for $h_2$: $$net_{h2} = (0.20)(0.05) + (0.30)(0.10) = 0.0175$$ $$\\sigma_{h2} = \\frac{1}{1 + e^{-0.0175}} \\approx 0.5044$$ For the output neuron: $$net_o = w_{h1,o} \\sigma_{h1} + w_{h2,o} \\sigma_{h2} = (0.40)(0.5031) + (0.45)(0.5044) = 0.4009$$ $$out_o = \\frac{1}{1 + e^{-net_o}} = \\frac{1}{1 + e^{-0.4009}} \\approx 0.5988$$ Step 2: Compute Error$$E = \\frac{1}{2} (t - out_o)^2 = \\frac{1}{2} (0.01 - 0.5988)^2 = 0.174$$ Step 3: BackpropagationError at Output Layer$$\\delta_o = out_o(1 - out_o)(t - out_o)$$$$\\delta_o = (0.5988)(1 - 0.5988)(0.01 - 0.5988) = -0.1432$$ Error at Hidden LayerFor $h_1$: $$\\delta_{h1} = \\sigma_{h1} (1 - \\sigma_{h1}) (w_{h1,o} \\delta_o)$$$$\\delta_{h1} = (0.5031)(1 - 0.5031)(0.40)(-0.1432) = -0.0143$$ Similarly, for $h_2$: $$\\delta_{h2} = (0.5044)(1 - 0.5044)(0.45)(-0.1432) = -0.0161$$ Step 4: Weight Updates$$w_{h1,o} \\leftarrow w_{h1,o} + \\eta \\delta_o \\sigma_{h1}$$$$= 0.40 + (0.5)(-0.1432)(0.5031) = 0.364$$ Similarly, other weights are updated. The Exploding and Vanishing Gradient ProblemBackpropagation works well for shallow networks, but deep networks suffer from two major problems: Vanishing Gradient In deep networks, gradients become exponentially smaller as they propagate backward. Since weights are updated using these gradients, early layers stop learning. Happens when using Sigmoid or Tanh activations because their derivatives are between 0 and 1. Exploding Gradient If weights are large, gradients explode, leading to unstable training. Weight updates become extremely large, causing the model to diverge. Solutions ReLU Activation Function: Unlike Sigmoid, ReLU has a derivative of 1 for positive inputs, preventing vanishing gradients. Batch Normalization: Normalizes activations, keeping them in a stable range. Gradient Clipping: Limits the gradient value to prevent explosion. Xavier/He Initialization: Properly initializes weights to keep gradients stable.","link":"/blog/2025/02/06/Machine-Learning-7/"},{"title":"About Machine Learning ( Part 8: Convolution Neural Networks )","text":"Convolutional Neural Networks (CNNs) have revolutionized the field of computer vision, enabling significant advancements in image recognition, object detection, and segmentation tasks. This blog will explore the key concepts behind CNNs and their working principles. What is a CNN?A Convolutional Neural Network (CNN) is a type of deep learning model specifically designed for processing structured grid data, such as images. Unlike traditional fully connected neural networks, CNNs leverage convolutional layers to capture spatial hierarchies in the data. Architecture of a CNNA typical CNN consists of the following layers: Convolutional LayerThe convolutional layer applies a set of learnable filters to the input image, extracting important features like edges, textures, and patterns. Mathematically, the convolution operation is defined as: $$ (I * K)(x, y) = \\sum_{m}\\sum_{n} I(m, n)K(x - m, y - n) $$ where: $I$ is the input image, $K$ is the filter (kernel), $(x, y)$ represents spatial coordinates. Activation Function (ReLU)The Rectified Linear Unit (ReLU) introduces non-linearity into the model by applying: $$ f(x) = \\max(0, x) $$ This helps the network learn complex patterns. Pooling LayerThe pooling layer reduces the spatial dimensions of the feature maps, helping to decrease computational complexity. The most common type is max pooling: $$ P(x, y) = \\max_{i, j} F(x+i, y+j) $$ where $F(x, y)$ represents the feature map values. Fully Connected LayerAfter several convolutional and pooling layers, the output is flattened and passed through fully connected layers to make final predictions. Training a CNNTraining a CNN involves minimizing a loss function using an optimization algorithm like stochastic gradient descent (SGD). The loss function, often cross-entropy loss, is given by: $$ L = -\\sum_{i} y_i \\log(\\hat{y_i}) $$ where: $y_i$ is the true label, $\\hat{y_i}$ is the predicted probability. Backpropagation and gradient descent adjust the weights to minimize this loss iteratively. Applications of CNNsCNNs have a wide range of applications, including: Image Classification (e.g., recognizing objects in images) Object Detection (e.g., detecting pedestrians in autonomous driving) Medical Image Analysis (e.g., detecting tumors in X-rays) Facial Recognition (e.g., biometric authentication)","link":"/blog/2025/02/12/Machine-Learning-8/"},{"title":"About Machine Learning ( Part 9: Recurrent Neural Network )","text":"Recurrent Neural Networks (RNNs) are a class of neural networks designed for sequential data, making them highly effective for tasks like natural language processing (NLP), time series prediction, and speech recognition. Unlike traditional feedforward networks, RNNs maintain a hidden state that captures temporal dependencies. How RNNs WorkA traditional feedforward neural network processes inputs independently. However, for sequential tasks, the order of the data is crucial. RNNs address this by maintaining a memory of previous inputs through hidden states. Mathematical RepresentationAt each time step $t$, an RNN takes the current input $x_t$ and the previous hidden state $h_{t-1}$ to compute the new hidden state $h_t$: $$h_t = f(W_h h_{t-1} + W_x x_t + b_h)$$ where: $W_h$ and $W_x$ are weight matrices, $b_h$ is the bias term, $f$ is usually a non-linear activation function like $ \\tanh $, $h_t$ represents the memory of past computations. Finally, the output $o_t$ is computed as: $$o_t = g(W_y h_t + b_y)$$ where $g$ is often a softmax function for classification tasks. The Vanishing Gradient ProblemA major challenge in training RNNs is the vanishing gradient problem.During backpropagation, gradients can shrink exponentially when passing through many time steps, making it difficult to learn long-range dependencies. To address this issue, LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units) were introduced. Long Short-Term Memory (LSTM)LSTMs introduce gates to control how much past information should be retained or discarded. This helps preserve long-term dependencies. Each LSTM unit has: Forget Gate: Decides what information to discard$$f_t = \\sigma(W_f h_{t-1} + U_f x_t + b_f)$$ Input Gate: Determines new information to store$$i_t = \\sigma(W_i h_{t-1} + U_i x_t + b_i)$$ Cell State Update: Computes the candidate memory $$\\tilde{C_t} = \\tanh(W_c h_{t-1} + U_c x_t + b_c)$$ Then updates the cell state: $$C_t = f_t C_{t-1} + i_t \\tilde{C}_t$$ Output Gate: Determines the final hidden state$$o_t = \\sigma(W_o h_{t-1} + U_o x_t + b_o)$$$$h_t = o_t \\tanh(C_t)$$ LSTMs ensure that important past information remains accessible over long sequences. Cell State $C_t$The cell state can be considered as the “memory” of the LSTM network. It carries information across time steps, and it’s responsible for helping the network preserve long-term dependencies. The cell state is essentially the backbone of an LSTM that allows it to remember information over long sequences. Update Mechanism of Cell StateThe cell state is updated through two important gates in the LSTM: Forget Gate ($f_t$) - Decides what information should be discarded. Input Gate ($i_t$) - Determines what new information should be added to the memory. The cell state $C_t$ is updated as follows: $$C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t$$ Where: $C_{t-1}$ is the previous cell state. $f_t$ is the forget gate’s output, which decides how much of the previous cell state should be remembered. $i_t$ is the input gate’s output, which decides how much new information should be stored in the cell state. $\\tilde{C}_t$ is the candidate cell state, which represents the new potential memory. Hidden State $h_t$The hidden state is the network’s short-term memory. It represents the output of the LSTM at each time step and carries information relevant to the current time step’s computation. The hidden state is the value that is passed to the next time step and is typically used to generate predictions or outputs. Update Mechanism of Hidden StateThe hidden state $h_t$ is derived from the current cell state $C_t$ using the output gate ($o_t$). The output gate decides how much of the current cell state should be exposed as the hidden state: $$h_t = o_t \\cdot \\tanh(C_t)$$ Where: $o_t$ is the output gate, which determines how much of the cell state should be visible in the hidden state. $\\tanh(C_t)$ is the cell state passed through the $\\tanh$ activation function. Differences Between $C_t$ and $h_t$While both cell state ($C_t$) and hidden state ($h_t$) are crucial in LSTM networks, they serve distinct roles: $C_t$ (Cell State): Acts as the long-term memory of the network. It is designed to carry information over long time periods, ensuring the network remembers relevant data from earlier time steps. The cell state is passed through the time steps with minimal changes unless explicitly modified by the forget and input gates. $h_t$ (Hidden State): Acts as the short-term memory. It contains information that is relevant to the current time step and is used to generate the output of the LSTM at each time step. The hidden state is passed to the next time step as the updated memory, which is used for prediction or classification. Gated Recurrent Unit (GRU)GRUs are another variant of RNNs introduced to improve the learning of long-range dependencies. GRUs are simpler than LSTMs, as they use fewer gates, which can lead to faster training times while still addressing the vanishing gradient problem. A GRU unit consists of two main gates: Update Gate: This gate decides how much of the past information should be carried forward.$$z_t = \\sigma(W_z h_{t-1} + U_z x_t + b_z)$$ $z_t = 0$: The model keeps the previous hidden state $h_{t-1}$ and does not update with new information. $z_t = 1$: The model fully updates the hidden state with the new candidate hidden state $\\tilde{h}_t$. Reset Gate: This gate determines how much of the past hidden state should be forgotten.$$r_t = \\sigma(W_r h_{t-1} + U_r x_t + b_r)$$ $r_t = 0$: Forget the previous hidden state. $r_t = 1$: Use the previous hidden state fully. The candidate hidden state $\\tilde{h}_t$ is computed as: $$\\tilde{h_t} = \\tanh(W_h (r_t \\cdot h_{t-1}) + U_h x_t + b_h)$$ Finally, the hidden state $h_t$ is updated as a combination of the previous hidden state and the candidate hidden state: $$h_t = (1 - z_t) \\cdot h_{t-1} + z_t \\cdot \\tilde{h}_t$$ The update gate controls how much of the previous hidden state is kept, while the reset gate determines how much of the past information is discarded. GRUs are computationally more efficient than LSTMs because they have fewer parameters to train, yet often perform comparably in many tasks. LSTM vs. GRU: Key DifferencesWhile both LSTMs and GRUs address the vanishing gradient problem, their architecture and gate structure differ: Number of Gates: LSTM has three gates: Forget gate, Input gate, and Output gate. GRU has only two gates: Update gate and Reset gate. Complexity: LSTM is generally more complex and has more parameters due to the extra gates and the cell state. GRU is simpler with fewer parameters, making it computationally more efficient. Performance: LSTM might perform better on some tasks due to its ability to separately maintain the cell state and hidden state, but it may require more data and computational resources. GRU, being simpler, can often match or even outperform LSTM on smaller datasets or simpler tasks. Use Cases: LSTM is typically used when the task requires more complex learning of long-term dependencies. GRU is useful for faster training and can be an effective choice for tasks where slightly fewer gates might still work well. In many practical scenarios, both LSTM and GRU can give similar results. The choice between the two often comes down to the specific task, available computational resources, and performance requirements. Applications of RNNsRNNs and their variants (LSTM, GRU) are widely used in: Natural Language Processing (NLP) Sentiment analysis Machine translation (Google Translate) Chatbots &amp; conversational AI Time Series Forecasting Stock price prediction Weather forecasting Speech Recognition Voice assistants like Siri &amp; Google Assistant Music Generation AI-generated compositions","link":"/blog/2025/02/12/Machine-Learning-9/"},{"title":"About My Previous Blog","text":"For those who have followed my previous blog hosted at kongchenglc.github.io, I would like to let you know that it is no longer actively maintained. While that blog holds many of my earlier writings and thoughts, I have decided to move on and start fresh with this new blog. Here, I aim to share more up-to-date and diverse content, reflecting my current interests and ideas. Thank you for your continued support, and I hope you enjoy the new content here!","link":"/blog/2024/09/15/Previous-Blog/"},{"title":"Shuffle-Some-Blues","text":"Blues has this casual, laid-back vibe that’s so fun to play. Maybe you’re into it too! In this post, I’m going to share a bit about the magic of blues piano. Notes Within the HarmonyLately, I’ve been practicing blues piano in E, and as I started learning the C-based twelve-bar blues, I discovered something cool: the intervals between notes in the blues scale follow a pattern of 3-2-1-1-3-2 (in terms of semitones). For example, in C blues, the notes are C, Eb, F, Gb, G, Bb, C. In E blues, the notes are E, G, A, Bb, C, D, E. If you look at the intervals between these notes, they follow that 3-2-1-1-3-2 pattern. It’s a simple yet powerful way to understand the blues scale. The RhythmBlues rhythm is often described as a “shuffle”: Dividing each beat into triplets. Emphasizing the first and third notes of each triplet, creating a ‘long-short’ feel that bounces. When you play, you can really feel that swing. And for the right hand, you can use cool techniques like glissando, trills, repeated notes, and others to add even more flavor to the music. Twelve-bar BluesThe twelve-bar blues is a classic and super important part of blues music. It’s a chord progression that follows a specific pattern. Here’s the typical twelve-bar blues progression in C: 123C | C | C | CF | F | C | CG | F | C | C Have fun!","link":"/blog/2025/01/10/Shuffle-Some-Blues/"},{"title":"Transformer ( Part 1: Word Embedding )","text":"Word Embedding is one of the most fundamental techniques in Natural Language Processing (NLP). It represents words as continuous vectors in a high-dimensional space, capturing semantic relationships between them. Why Do We Need Word Embeddings?Before word embeddings, one common method to represent words was One-Hot Encoding. In this approach, each word is represented as a high-dimensional sparse vector. For example, if our vocabulary has 10,000 words, we encode each word as:$$\\text{dog} = [0, 1, 0, 0, \\dots, 0]$$However, this method has significant drawbacks: High dimensionality – A large vocabulary results in enormous vectors. No semantic similarity – “dog” and “cat” are conceptually related, but their one-hot vectors are completely different. Word embeddings solve these issues by learning low-dimensional, dense representations that encode semantic relationships between words. Word Embeddings and Dot Product: A Geometric PerspectiveWord embeddings map words into a vector space, where semantically similar words are placed close to each other. What is the Dot Product?For two vectors $\\mathbf{A}$ and $\\mathbf{B}$, the dot product is defined as:$$\\mathbf{A} \\cdot \\mathbf{B} = | \\mathbf{A} | | \\mathbf{B} | \\cos(\\theta)$$where: $| \\mathbf{A} |$ and $| \\mathbf{B} |$ are the magnitudes (lengths) of the vectors $| \\mathbf{A} |$ and $| \\mathbf{B} |$ are the magnitudes (lengths) of the vectors $\\theta$ is the angle between them Why is This Important in Word Embeddings? When $\\theta$ is small, $\\cos(\\theta)$ is large, meaning the words are similar. When $\\theta$ is large, $\\cos(\\theta)$ is small or negative, meaning the words are dissimilar. Thus, in Word2Vec, the similarity between two words is determined by their dot product, which aligns with how we measure relationships in a semantic space. Word2Vec: CBOW and Skip-GramWord2Vec is an algorithm for learning word embeddings. It has two main architectures: Continuous Bag of Words (CBOW) – Predicts a word given its surrounding context. Skip-Gram – Predicts context words given a target word. CBOW ModelGiven surrounding words, we predict the center word. The model uses:$$\\mathbf{h} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{x}_i$$where $\\mathbf{x}_i$ are the input word vectors. The probability of the target word $w_t$ is given by the Softmax function:$$P(w_t | \\text{context}) = \\frac{\\exp(\\mathbf{v_{w_t}} \\cdot \\mathbf{h})}{\\sum_{w \\in V} \\exp(\\mathbf{v_w} \\cdot \\mathbf{h})}$$ Skip-Gram ModelInstead of predicting a word from its context, Skip-Gram predicts the context words given a target word:$$P(w_c | w_t) = \\frac{\\exp(\\mathbf{v_{w_c}} \\cdot \\mathbf{v_{w_t}})}{\\sum_{w \\in V} \\exp(\\mathbf{v_w} \\cdot \\mathbf{v_{w_t}})}$$ The loss function for Skip-Gram is:$$L = -\\sum_{t} \\sum_{-n \\leq j \\leq n, j \\neq 0} \\log P(w_{t+j} | w_t)$$ Understanding Softmax and Exponential FunctionWhat is Softmax?Softmax converts raw scores into probabilities. Given a vector $\\mathbf{z}$, Softmax is defined as:$$\\text{Softmax}(z_i) = \\frac{\\exp(z_i)}{\\sum_{j} \\exp(z_j)}$$ This ensures: Non-negative outputs (since $\\exp(x) &gt; 0$ for all $x$). Probabilities sum to 1 (as a requirement for classification). The exponential function $\\exp(x) = e^x$ grows rapidly as $x$ increases. It is useful because: It ensures probabilities never become negative. It amplifies differences between scores, making classification more confident. Negative Sampling: Efficient TrainingSince computing Softmax over the entire vocabulary is expensive, we use Negative Sampling, which simplifies the loss function to:$$L = \\log \\sigma (\\mathbf{v_{w_t}} \\cdot \\mathbf{v_{w_c}}) + \\sum_{i=1}^{k} \\log \\sigma (-\\mathbf{v_{w_t}} \\cdot \\mathbf{v_{w_{\\text{neg}_i}}})$$where $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ is the Sigmoid function. Negative Sampling selects a few “negative examples” to contrast with positive word pairs, making training much faster.","link":"/blog/2025/02/09/Transformer-1/"},{"title":"Transformer ( Part 2: Multi-Head Attention )","text":"Before the Transformer, sequence models like RNNs and LSTMs suffered from long-term dependency issues and low parallelization efficiency. Self-Attention was introduced as an alternative, allowing for parallel computation and capturing long-range dependencies. However, a single-head Self-Attention mechanism has a limitation:It can only focus on one type of relationship or pattern in the data. Multi-Head Attention overcomes this by using multiple attention heads that capture different aspects of the input, improving the model’s expressiveness. Single-Head Self-AttentionBefore diving into Multi-Head Attention, let’s first understand how a single-head Self-Attention works. Query, Key, ValueIn Self-Attention, each input vector is mapped into three vectors: Query (Q): Represents the feature to search for. Key (K): Represents candidate features. Value (V): Represents the actual information to be aggregated. Each token in the input has a corresponding $(Q, K, V)$ triplet. Computing Attention ScoresFor a given Query $Q$ and Key $K$, we compute a similarity score using scaled dot-product attention: $$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V$$ where: $QK^T$ computes similarity between Query and Key. $\\sqrt{d_k}$ scales down the values to prevent large gradients. softmax ensures that attention weights sum to 1. The weights are applied to the Value $V$. Multi-Head Attention MechanismA single-head Self-Attention mechanism only captures one perspective of the input relationships. Multi-Head Attention uses multiple heads to process different aspects of the sequence in parallel. Computation Process of Multi-Head AttentionMulti-Head Attention follows these steps: Linear Projections: The input embedding $X$ has a dimension of $d_{\\text{model}}$ (e.g., 512). For each attention head, separate Query, Key, and Value vectors are computed using different linear transformations: $$Q_i = X W_i^Q, \\quad K_i = X W_i^K, \\quad V_i = X W_i^V$$ where $W_i^Q, W_i^K, W_i^V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$ are learnable parameters. Compute Attention for Each Head:Each attention head performs scaled dot-product attention: $$\\text{head}_i = \\text{Attention}(Q_i, K_i, V_i) = \\text{softmax}\\left(\\frac{Q_i K_i^T}{\\sqrt{d_k}}\\right) V_i$$ Concatenation &amp; Final Transformation:The outputs from all heads are concatenated and passed through a final linear transformation: $$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, …, \\text{head}_h) W^O$$ where $W^O \\in \\mathbb{R}^{h d_k \\times d_{\\text{model}}}$ is a trainable projection matrix. Trainable Projection Matrix $W^O$The final output of Multi-Head Attention is obtained by concatenating the outputs of all attention heads and applying a linear transformation using a projection matrix $W^O$. The matrix $W^O \\in \\mathbb{R}^{h d_k \\times d_{\\text{model}}}$ is a learnable parameter, meaning it is updated during training. Let’s break down what this means: $h$ represents the number of attention heads in the Multi-Head Attention mechanism. Each attention head processes the input in parallel, and having multiple heads allows the model to capture various relationships and features from the data. $d_k$ is the dimension of each attention head. Since the attention mechanism splits the model dimension ($d_{\\text{model}}$) evenly across all heads, $d_k = \\frac{d_{\\text{model}}}{h}$. $\\mathbb{R}$ refers to the set of real numbers. The notation $\\mathbb{R}^{h d_k \\times d_{\\text{model}}}$ indicates that $W^O$ is a matrix with dimensions $h d_k$ by $d_{\\text{model}}$, where the number of rows is the total dimension of all attention heads concatenated together, and the number of columns is the original model dimension. Why is this Computation Necessary? After the attention scores are computed and applied to the Values for each head, the outputs of all heads are concatenated. This concatenated output has a shape of $L \\times h d_k$, where $L$ is the sequence length and $h d_k$ is the combined dimension of all attention heads. However, we want the final output of Multi-Head Attention to have the same dimension as the original input, $d_{\\text{model}}$. To achieve this, we use the projection matrix $W^O$, which transforms the concatenated vector back to the desired $d_{\\text{model}}$ dimension. This ensures that the output from the Multi-Head Attention layer has the same dimension as the input, allowing it to be passed on to subsequent layers in the Transformer network without any dimension mismatch. In short, the projection matrix $W^O$ enables the transformation of the concatenated attention head outputs into a final output with the same dimensionality as the input, ensuring consistency throughout the model. Summary of Multi-Head Attention Formula$$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, …, \\text{head}_h) W^O$$ $$\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$ where: $h$ is the number of attention heads. $d_k = d_{\\text{model}} / h$ is the dimension of each head. $W^Q, W^K, W^V, W^O$ are learnable parameters.","link":"/blog/2025/03/01/Transformer-2/"},{"title":"Empowering Software with LLMs: Integration, Deployment, and Automation","text":"Large Language Models (LLMs) are revolutionizing industries. This blog walks you through integrating LLMs into a web application, deploying them to the cloud, and automating workflows. Follow along to kickstart LLMs in your projects effectively. What Are LLMs?LLMs (Large Language Models) like GPT-4, Llama, and others are powerful tools for generating human-like text, analyzing context, and solving complex problems. They can be used for a wide range of tasks such as chatbots, content creation, code generation, and more. In this guide, we will explore two key approaches for integrating LLMs into a software project: Deploying an LLM on your own infrastructure. Using third-party inference APIs. Approaches to LLM IntegrationDeploying LLMs YourselfIf you prefer full control over data privacy, customization, and cost, deploying LLMs on your infrastructure is the best option. Tools like Ollama and frameworks from Hugging Face make this feasible. Example: Deploying Ollama LocallyOllama allows you to run LLMs locally, providing a balance between performance and privacy. Installing Ollama: Go to the official website of Ollama. Follow the guide to install llama on your machine. Use ollama in your code. 123456import ollama# Load a model (e.g., Llama2)model = ollama.load_model(&quot;llama2&quot;)response = model.predict(&quot;Explain quantum mechanics in simple terms.&quot;)print(response) Using Third-Party Inference APIsThird-party APIs like Hugging Face Inference API or OpenAI offer pre-trained LLMs without the need to manage infrastructure. Example: Using Hugging Face APITo integrate with Hugging Face: Obtain an API token and store it securely (e.g., in an .env file). Use the provided SDK or HTTP requests to call the API. 12345678910import { HfInference } from '@huggingface/inference'const inference = new HfInference(process.env.HF_API_TOKEN)for await (const chunk of inference.chatCompletionStream({ model: 'meta-llama/Llama-3.2-1B-Instruct', messages, max_tokens: 2048,})) { // process chunk} Example: Streaming AI ResponsesReal-Time Response Streaming improves interactivity by delivering incremental responses to users. This is particularly useful for chatbots or applications where immediate feedback is crucial. 123456789101112131415161718192021222324// koa2 serverasync function query(messages, ctx) { ctx.set('Content-Type', 'text/plain; charset=utf-8') ctx.set('Transfer-Encoding', 'chunked') ctx.status = 200 ctx.res.writeHead(200, { 'Content-Type': 'text/plain; charset=utf-8', 'Transfer-Encoding': 'chunked', }) for await (const chunk of inference.chatCompletionStream({ model: 'meta-llama/Llama-3.2-1B-Instruct', messages, max_tokens: 2048, })) { const content = chunk.choices[0]?.delta?.content || '' if (content) { ctx.res.write(content) } } ctx.res.end()} Web Application DevelopmentBuilding a web application with LLMs involves a solid development and deployment strategy, including CI/CD pipelines, frontend hosting, backend servers, and database integration. CI/CD PipelineFrontend Deployment to AWS S3 Create an IAM user and grant S3 full access. Generate access keys and store them as GitHub repository secrets. Automate deployment with GitHub Actions. 12345678910111213141516171819202122232425262728293031name: GitHub Actions Build and Deploy Demoon: push: branches: - masterjobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Install dependencies uses: actions/setup-node@v3 - name: Build run: npm install &amp;&amp; npm run clean &amp;&amp; npm run build - name: Install AWS CLI run: | pip install awscli - name: Deploy to S3 run: | aws s3 sync ./dist s3://${{ secrets.AWS_S3_BUCKET }} --delete env: AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }} AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }} AWS_REGION: ${{ secrets.AWS_REGION }} AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }} Backend Deployment to EC2Use Amazon Linux for the instance, and install necessary tools. Database SetupMongoDB Integration Store your MongoDB connection string in a .env file to keep it secure. Whitelist the server’s IP in the MongoDB Atlas dashboard. SummaryBy following these steps, you can successfully integrate, deploy, and automate LLMs in your web application. Whether you choose to deploy an LLM yourself for greater control or use third-party APIs for convenience, this guide provides the foundation to get started. This is a demo of integrating LLM APIs, available in my GitHub repository. It includes both Backend and Frontend implementations.","link":"/blog/2024/10/17/hello-llm/"},{"title":"Automatically Post Your Blog","text":"This blog describes a quick and easy way to set up your own website and automate the process of posting new blogs. What is Hexo?Hexo is a fast, simple, and powerful blog framework built with Node.js. What is GitHub Pages?GitHub Pages is a static site hosting service provided by GitHub. It allows you to host your website directly from a GitHub repository. You can configure this feature in the repository’s Settings ➔ Pages section. What is GitHub Actions?GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that enables you to automate your build, test, and deployment workflows. You can set up workflows to automatically build and test every pull request or deploy merged pull requests to production. Automatically Post Your BlogBy using Hexo to generate static files from markdown, and deploying them with GitHub Actions, you can automate the process of publishing your blog to GitHub Pages. StepsDeployment Repository Create a public repository on GitHub and enable GitHub Pages in the Settings ➔ Pages section. Every time you push to the main branch, GitHub Pages will automatically deploy the static files from the root directory of the main branch to the website. Source Code Repository Create a new GitHub repository for your blog’s source code. You can keep this repository private. Initialize Hexo in this repository and start writing your blogs in markdown files. Set up GitHub Actions in the source code repository. I recommend using the public action JamesIves/github-pages-deploy-action@v4 to deploy the static files generated by Hexo. Here’s the YAML configuration for your workflow: 1234567891011121314151617181920212223242526name: GitHub Actions Build and Deployon: push: branches: - mainjobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Install dependencies uses: actions/setup-node@v3 - name: Build run: npm install &amp;&amp; npm run clean &amp;&amp; npm run build - name: Deploy to GitHub Pages uses: JamesIves/github-pages-deploy-action@v4 with: folder: public repository-name: github_username/development_repo_name branch: main token: ${{ secrets.BLOG_BUILD }} Create a fine-grained personal access token from your account’s Settings ➔ Developer settings ➔ Personal access tokens ➔ Tokens (classic). This token will be used to access the source code repository. In this source code repository’s Settings ➔ Secrets and variables ➔ Actions section, create a new secret named BLOG_BUILD and set its value to your personal access token. This will be used to deploy the static files to the deployment repository. Additional FeaturesCommentsHexo supports many comment plugins. I am using the Utterances plugin for this blog. Steps to Use Utterances Visit Utterances GitHub page. Click Install. Select the repository you want to use Utterances with. Go to Utterances site. Fill in the form with the necessary details. Add the following code to your post.ejs file. Note: If you don’t have a post.ejs file, you can create one in your theme’s layout directory. For example: themes/default/layout/post.ejs.","link":"/blog/2024/09/16/post-ur-blog-automaticly/"}],"tags":[{"name":"Project Management","slug":"Project-Management","link":"/blog/tags/Project-Management/"},{"name":"Chrome Extension","slug":"Chrome-Extension","link":"/blog/tags/Chrome-Extension/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/blog/tags/Machine-Learning/"},{"name":"Gradient Descent","slug":"Gradient-Descent","link":"/blog/tags/Gradient-Descent/"},{"name":"PCA","slug":"PCA","link":"/blog/tags/PCA/"},{"name":"Linear Regression","slug":"Linear-Regression","link":"/blog/tags/Linear-Regression/"},{"name":"Logistic Regression","slug":"Logistic-Regression","link":"/blog/tags/Logistic-Regression/"},{"name":"Decision Tree","slug":"Decision-Tree","link":"/blog/tags/Decision-Tree/"},{"name":"Support Vector Machine (SVM)","slug":"Support-Vector-Machine-SVM","link":"/blog/tags/Support-Vector-Machine-SVM/"},{"name":"K-Nearest Neighbors (KNN)","slug":"K-Nearest-Neighbors-KNN","link":"/blog/tags/K-Nearest-Neighbors-KNN/"},{"name":"K-means Clustering","slug":"K-means-Clustering","link":"/blog/tags/K-means-Clustering/"},{"name":"Unsupervised Learning","slug":"Unsupervised-Learning","link":"/blog/tags/Unsupervised-Learning/"},{"name":"Artificial Neural Network (ANN)","slug":"Artificial-Neural-Network-ANN","link":"/blog/tags/Artificial-Neural-Network-ANN/"},{"name":"Bayes’ Theorem","slug":"Bayes’-Theorem","link":"/blog/tags/Bayes%E2%80%99-Theorem/"},{"name":"Delta Rule","slug":"Delta-Rule","link":"/blog/tags/Delta-Rule/"},{"name":"Backpropagation","slug":"Backpropagation","link":"/blog/tags/Backpropagation/"},{"name":"Convolution Neural Networks (CNN)","slug":"Convolution-Neural-Networks-CNN","link":"/blog/tags/Convolution-Neural-Networks-CNN/"},{"name":"Recurrent Neural Network","slug":"Recurrent-Neural-Network","link":"/blog/tags/Recurrent-Neural-Network/"},{"name":"Blues","slug":"Blues","link":"/blog/tags/Blues/"},{"name":"Music","slug":"Music","link":"/blog/tags/Music/"},{"name":"LLM","slug":"LLM","link":"/blog/tags/LLM/"},{"name":"NLP","slug":"NLP","link":"/blog/tags/NLP/"},{"name":"Transformer","slug":"Transformer","link":"/blog/tags/Transformer/"},{"name":"Word Embedding","slug":"Word-Embedding","link":"/blog/tags/Word-Embedding/"},{"name":"Multi-Head Attention","slug":"Multi-Head-Attention","link":"/blog/tags/Multi-Head-Attention/"},{"name":"Hugging face","slug":"Hugging-face","link":"/blog/tags/Hugging-face/"},{"name":"Real-Time Response Streaming","slug":"Real-Time-Response-Streaming","link":"/blog/tags/Real-Time-Response-Streaming/"},{"name":"CI&#x2F;CD","slug":"CI-CD","link":"/blog/tags/CI-CD/"},{"name":"GitHub Pages","slug":"GitHub-Pages","link":"/blog/tags/GitHub-Pages/"},{"name":"GitHub Actions","slug":"GitHub-Actions","link":"/blog/tags/GitHub-Actions/"}],"categories":[{"name":"Learning Notes","slug":"Learning-Notes","link":"/blog/categories/Learning-Notes/"},{"name":"Technical Tutorials","slug":"Technical-Tutorials","link":"/blog/categories/Technical-Tutorials/"},{"name":"Music","slug":"Music","link":"/blog/categories/Music/"}],"pages":[{"title":"","text":"document.addEventListener('DOMContentLoaded', function () { var tocElement = document.querySelector('#toc'); if (tocElement) { tocElement.classList.add('is-sticky'); } });","link":"/blog/js/custom-css.js"}]}